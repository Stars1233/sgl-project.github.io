{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI APIs - Vision\n",
    "\n",
    "SGLang provides OpenAI-compatible APIs to enable a smooth transition from OpenAI services to self-hosted local models.\n",
    "A complete reference for the API is available in the [OpenAI API Reference](https://platform.openai.com/docs/guides/vision).\n",
    "This tutorial covers the vision APIs for vision language models.\n",
    "\n",
    "SGLang supports various vision language models such as Llama 3.2, LLaVA-OneVision, Qwen2.5-VL, Gemma3 and [more](../supported_models/multimodal_language_models.md).\n",
    "\n",
    "As an alternative to the OpenAI API, you can also use the [SGLang offline engine](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/offline_batch_inference_vlm.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch A Server\n",
    "\n",
    "Launch the server in your terminal and wait for it to initialize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T08:25:49.410753Z",
     "iopub.status.busy": "2025-10-06T08:25:49.410625Z",
     "iopub.status.idle": "2025-10-06T08:27:27.176194Z",
     "shell.execute_reply": "2025-10-06T08:27:27.175698Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "WARNING:transformers.configuration_utils:`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "WARNING:sglang.srt.server_args:\u001b[33m\n",
      "########################################################################\n",
      "# For contributors and developers:                                    #\n",
      "# Please move environment variable definitions to sglang.srt.environ  #\n",
      "# using the following pattern:                                        #\n",
      "#     SGLANG_XXX = EnvBool(False)                                     #\n",
      "#                                                                     #\n",
      "########################################################################\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-06 08:26:04] MOE_RUNNER_BACKEND is not initialized, using triton backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "[2025-10-06 08:26:14] `torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-06 08:26:18] MOE_RUNNER_BACKEND is not initialized, using triton backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:00<00:03,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:01<00:02,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:02<00:01,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:02<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:03<00:00,  1.73it/s]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:03<00:00,  1.53it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]\r",
      "Capturing batches (bs=4 avail_mem=28.91 GB):   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=4 avail_mem=28.91 GB):  33%|███▎      | 1/3 [00:49<01:39, 49.90s/it]\r",
      "Capturing batches (bs=2 avail_mem=60.81 GB):  33%|███▎      | 1/3 [00:49<01:39, 49.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=2 avail_mem=60.81 GB):  67%|██████▋   | 2/3 [00:54<00:23, 23.07s/it]\r",
      "Capturing batches (bs=1 avail_mem=60.78 GB):  67%|██████▋   | 2/3 [00:54<00:23, 23.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=1 avail_mem=60.78 GB): 100%|██████████| 3/3 [00:55<00:00, 13.32s/it]\r",
      "Capturing batches (bs=1 avail_mem=60.78 GB): 100%|██████████| 3/3 [00:55<00:00, 18.63s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'><br><br>                    NOTE: Typically, the server runs in a separate terminal.<br>                    In this notebook, we run the server and notebook code together, so their outputs are combined.<br>                    To improve clarity, the server logs are displayed in the original black color, while the notebook outputs are highlighted in blue.<br>                    To reduce the log length, we set the log level to warning for the server, the default log level is info.<br>                    We are running those notebooks in a CI environment, so the throughput is not representative of the actual performance.<br>                    </strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sglang.test.doc_patch import launch_server_cmd\n",
    "from sglang.utils import wait_for_server, print_highlight, terminate_process\n",
    "\n",
    "vision_process, port = launch_server_cmd(\n",
    "    \"\"\"\n",
    "python3 -m sglang.launch_server --model-path Qwen/Qwen2.5-VL-7B-Instruct --log-level warning\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "wait_for_server(f\"http://localhost:{port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cURL\n",
    "\n",
    "Once the server is up, you can send test requests using curl or requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T08:27:27.179754Z",
     "iopub.status.busy": "2025-10-06T08:27:27.179187Z",
     "iopub.status.idle": "2025-10-06T08:27:31.304078Z",
     "shell.execute_reply": "2025-10-06T08:27:31.303606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{\"id\":\"86d507ab2ac14766ad9a78847f3e2905\",\"object\":\"chat.completion\",\"created\":1759739248,\"model\":\"Qwen/Qwen2.5-VL-7B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"The image shows a person standing near the back of a taxi, performing an unusual task of placing an iron and clothes onto an improvised rack that resembles a drying line attached to the vehicle. The taxi appears to have a unique setup, indicating this is not a regular repair or cleaning routine. The background suggests an urban street environment with other taxis and buildings visible.\",\"reasoning_content\":null,\"tool_calls\":null},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":151645}],\"usage\":{\"prompt_tokens\":307,\"total_tokens\":379,\"completion_tokens\":72,\"prompt_tokens_details\":null,\"reasoning_tokens\":0},\"metadata\":{\"weight_version\":\"default\"}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{\"id\":\"32c35e17d38549138535134ebbcd1805\",\"object\":\"chat.completion\",\"created\":1759739251,\"model\":\"Qwen/Qwen2.5-VL-7B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"This image shows a man standing on the back doors of a yellow taxi parked on a city street. He is using an ironing board with clothes draped across it, suggesting that he might be performing an unusual job such as ironing clothes in the middle of the street. The man and the taxi are the main subjects, and the busy street in the background, including signs, trees, and possibly a few pedestrians or vehicles, adds a sense of urban context to the scene.\",\"reasoning_content\":null,\"tool_calls\":null},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":151645}],\"usage\":{\"prompt_tokens\":307,\"total_tokens\":403,\"completion_tokens\":96,\"prompt_tokens_details\":null,\"reasoning_tokens\":0},\"metadata\":{\"weight_version\":\"default\"}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "curl_command = f\"\"\"\n",
    "curl -s http://localhost:{port}/v1/chat/completions \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{{\n",
    "    \"model\": \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    \"messages\": [\n",
    "      {{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What’s in this image?\"\n",
    "          }},\n",
    "          {{\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {{\n",
    "              \"url\": \"https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true\"\n",
    "            }}\n",
    "          }}\n",
    "        ]\n",
    "      }}\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "  }}'\n",
    "\"\"\"\n",
    "\n",
    "response = subprocess.check_output(curl_command, shell=True).decode()\n",
    "print_highlight(response)\n",
    "\n",
    "\n",
    "response = subprocess.check_output(curl_command, shell=True).decode()\n",
    "print_highlight(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T08:27:31.305830Z",
     "iopub.status.busy": "2025-10-06T08:27:31.305681Z",
     "iopub.status.idle": "2025-10-06T08:27:32.381750Z",
     "shell.execute_reply": "2025-10-06T08:27:32.381275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{\"id\":\"35ae5442854848658165ca6b938cc6c0\",\"object\":\"chat.completion\",\"created\":1759739252,\"model\":\"Qwen/Qwen2.5-VL-7B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"The image depicts a man wearing a bright yellow shirt standing next to the rear hatch of a yellow taxi cab. He has an iron and an ironing board set up on the tailgate, and he appears to be ironing a blue shirt or fabric. The taxi is parked on a street surrounded by modern urban buildings, and there's another taxi and vehicles in the background.\",\"reasoning_content\":null,\"tool_calls\":null},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":151645}],\"usage\":{\"prompt_tokens\":307,\"total_tokens\":383,\"completion_tokens\":76,\"prompt_tokens_details\":null,\"reasoning_tokens\":0},\"metadata\":{\"weight_version\":\"default\"}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"http://localhost:{port}/v1/chat/completions\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print_highlight(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T08:27:32.383343Z",
     "iopub.status.busy": "2025-10-06T08:27:32.383193Z",
     "iopub.status.idle": "2025-10-06T08:27:33.317470Z",
     "shell.execute_reply": "2025-10-06T08:27:33.316925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>This image shows a man on the back of a taxi in a city street wearing an orange shirt, hanging makeshift clothespins with clothes on wires attached to a yellow SUV taxi. The scene depicts an unconventional and humorous visual, seemingly symbolic of scheduling, multitasking, or organization (\"hanging things up\").</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=f\"http://localhost:{port}/v1\", api_key=\"None\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What is in this image?\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print_highlight(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple-Image Inputs\n",
    "\n",
    "The server also supports multiple images and interleaved text and images if the model supports it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T08:27:33.319789Z",
     "iopub.status.busy": "2025-10-06T08:27:33.319627Z",
     "iopub.status.idle": "2025-10-06T08:27:34.677714Z",
     "shell.execute_reply": "2025-10-06T08:27:34.676969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>The first image shows a man ironing clothes on the back of a taxi in a busy urban street. The second image is a stylized logo featuring the letters \"SGL\" with a book and a computer icon incorporated into the design.</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=f\"http://localhost:{port}/v1\", api_key=\"None\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"I have two very different images. They are not related at all. \"\n",
    "                    \"Please describe the first image in one sentence, and then describe the second image in another sentence.\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print_highlight(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T08:27:34.679451Z",
     "iopub.status.busy": "2025-10-06T08:27:34.679282Z",
     "iopub.status.idle": "2025-10-06T08:27:34.723988Z",
     "shell.execute_reply": "2025-10-06T08:27:34.723406Z"
    }
   },
   "outputs": [],
   "source": [
    "terminate_process(vision_process)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
