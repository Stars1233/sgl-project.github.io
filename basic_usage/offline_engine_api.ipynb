{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Engine API\n",
    "\n",
    "SGLang provides a direct inference engine without the need for an HTTP server, especially for use cases where additional HTTP server adds unnecessary complexity or overhead. Here are two general use cases:\n",
    "\n",
    "- Offline Batch Inference\n",
    "- Custom Server on Top of the Engine\n",
    "\n",
    "This document focuses on the offline batch inference, demonstrating four different inference modes:\n",
    "\n",
    "- Non-streaming synchronous generation\n",
    "- Streaming synchronous generation\n",
    "- Non-streaming asynchronous generation\n",
    "- Streaming asynchronous generation\n",
    "\n",
    "Additionally, you can easily build a custom server on top of the SGLang offline engine. A detailed example working in a python script can be found in [custom_server](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/custom_server.py).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nest Asyncio\n",
    "Note that if you want to use **Offline Engine** in ipython or some other nested loop code, you need to add the following code:\n",
    "```python\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "\n",
    "The engine supports [vlm inference](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/offline_batch_inference_vlm.py) as well as [extracting hidden states](https://github.com/sgl-project/sglang/blob/main/examples/runtime/hidden_states). \n",
    "\n",
    "Please see [the examples](https://github.com/sgl-project/sglang/tree/main/examples/runtime/engine) for further use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Batch Inference\n",
    "\n",
    "SGLang offline engine supports batch inference with efficient scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T05:37:32.693248Z",
     "iopub.status.busy": "2025-10-17T05:37:32.693128Z",
     "iopub.status.idle": "2025-10-17T05:37:55.389784Z",
     "shell.execute_reply": "2025-10-17T05:37:55.388876Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.configuration_utils:`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "[2025-10-17 05:37:49] `torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.64it/s]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.63it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]\r",
      "Capturing batches (bs=128 avail_mem=72.82 GB):   0%|          | 0/20 [00:00<?, ?it/s]\r",
      "Capturing batches (bs=128 avail_mem=72.82 GB):   5%|▌         | 1/20 [00:00<00:03,  5.90it/s]\r",
      "Capturing batches (bs=120 avail_mem=72.71 GB):   5%|▌         | 1/20 [00:00<00:03,  5.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=112 avail_mem=72.71 GB):   5%|▌         | 1/20 [00:00<00:03,  5.90it/s]\r",
      "Capturing batches (bs=104 avail_mem=72.70 GB):   5%|▌         | 1/20 [00:00<00:03,  5.90it/s]\r",
      "Capturing batches (bs=104 avail_mem=72.70 GB):  20%|██        | 4/20 [00:00<00:01, 14.49it/s]\r",
      "Capturing batches (bs=96 avail_mem=72.69 GB):  20%|██        | 4/20 [00:00<00:01, 14.49it/s] \r",
      "Capturing batches (bs=88 avail_mem=72.69 GB):  20%|██        | 4/20 [00:00<00:01, 14.49it/s]\r",
      "Capturing batches (bs=80 avail_mem=72.68 GB):  20%|██        | 4/20 [00:00<00:01, 14.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=80 avail_mem=72.68 GB):  35%|███▌      | 7/20 [00:00<00:00, 17.82it/s]\r",
      "Capturing batches (bs=72 avail_mem=72.68 GB):  35%|███▌      | 7/20 [00:00<00:00, 17.82it/s]\r",
      "Capturing batches (bs=64 avail_mem=72.67 GB):  35%|███▌      | 7/20 [00:00<00:00, 17.82it/s]\r",
      "Capturing batches (bs=56 avail_mem=72.67 GB):  35%|███▌      | 7/20 [00:00<00:00, 17.82it/s]\r",
      "Capturing batches (bs=56 avail_mem=72.67 GB):  50%|█████     | 10/20 [00:00<00:00, 19.83it/s]\r",
      "Capturing batches (bs=48 avail_mem=72.66 GB):  50%|█████     | 10/20 [00:00<00:00, 19.83it/s]\r",
      "Capturing batches (bs=40 avail_mem=72.66 GB):  50%|█████     | 10/20 [00:00<00:00, 19.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=32 avail_mem=72.66 GB):  50%|█████     | 10/20 [00:00<00:00, 19.83it/s]\r",
      "Capturing batches (bs=32 avail_mem=72.66 GB):  65%|██████▌   | 13/20 [00:00<00:00, 21.17it/s]\r",
      "Capturing batches (bs=24 avail_mem=72.65 GB):  65%|██████▌   | 13/20 [00:00<00:00, 21.17it/s]\r",
      "Capturing batches (bs=16 avail_mem=72.65 GB):  65%|██████▌   | 13/20 [00:00<00:00, 21.17it/s]\r",
      "Capturing batches (bs=12 avail_mem=72.64 GB):  65%|██████▌   | 13/20 [00:00<00:00, 21.17it/s]\r",
      "Capturing batches (bs=12 avail_mem=72.64 GB):  80%|████████  | 16/20 [00:00<00:00, 20.45it/s]\r",
      "Capturing batches (bs=8 avail_mem=72.64 GB):  80%|████████  | 16/20 [00:00<00:00, 20.45it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=4 avail_mem=71.84 GB):  80%|████████  | 16/20 [00:00<00:00, 20.45it/s]\r",
      "Capturing batches (bs=2 avail_mem=71.74 GB):  80%|████████  | 16/20 [00:00<00:00, 20.45it/s]\r",
      "Capturing batches (bs=1 avail_mem=71.74 GB):  80%|████████  | 16/20 [00:00<00:00, 20.45it/s]\r",
      "Capturing batches (bs=1 avail_mem=71.74 GB): 100%|██████████| 20/20 [00:00<00:00, 23.78it/s]\r",
      "Capturing batches (bs=1 avail_mem=71.74 GB): 100%|██████████| 20/20 [00:00<00:00, 20.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# launch the offline engine\n",
    "import asyncio\n",
    "\n",
    "import sglang as sgl\n",
    "import sglang.test.doc_patch\n",
    "from sglang.utils import async_stream_and_merge, stream_and_merge\n",
    "\n",
    "llm = sgl.Engine(model_path=\"qwen/qwen2.5-0.5b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Synchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T05:37:55.392927Z",
     "iopub.status.busy": "2025-10-17T05:37:55.392474Z",
     "iopub.status.idle": "2025-10-17T05:37:56.186056Z",
     "shell.execute_reply": "2025-10-17T05:37:56.185243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: Hello, my name is\n",
      "Generated text:  Mary. I am a doctor. I have a very busy schedule, but I am always looking for problems that need solving. My schedule is much more active when my patients are feeling sick. I try to treat the patients first, and I get them to the doctor's office or hospital right away. I try to stay in touch with my patients. If I hear about a problem, I call them right away. I always try to find solutions to any problems that my patients have. I have a busy schedule but I try to make sure that my patients are getting the treatment they need and they are feeling better. Mary's schedule is very\n",
      "===============================\n",
      "Prompt: The president of the United States is\n",
      "Generated text:  from what country? The president of the United States is from the United States of America, which is a federal republic consisting of 50 states. The president is indirectly elected by the people through a presidential election, and the qualifications and procedures for the election are outlined in the Constitution of the United States. The United States is a federal republic, which means that the President is elected by the people and serves as the head of government and the commander-in-chief of the armed forces. The President is also the leader of the executive branch of the government, responsible for making decisions on behalf of the United States and executing the laws and policies of the\n",
      "===============================\n",
      "Prompt: The capital of France is\n",
      "Generated text: :\n",
      "\n",
      "A. Paris\n",
      "\n",
      "B. London\n",
      "\n",
      "C. Rome\n",
      "\n",
      "D. Brussels\n",
      "\n",
      "To determine the capital of France, we need to recall which European country has that name. The capital of France is Paris. \n",
      "\n",
      "So, the correct answer is: A. Paris. \n",
      "\n",
      "This question tests the recognition of European capitals, a basic knowledge point in geography and history. It is a straightforward and practical exercise that does not require any complex calculations. The capital of France is Paris, which is A. Paris. \n",
      "\n",
      "To ensure accuracy, we should verify that Paris is indeed the capital of France by providing a brief history or geographical reference. In this\n",
      "===============================\n",
      "Prompt: The future of AI is\n",
      "Generated text:  now. Digital transformation is one of the top trends of the year 2022. In 2022, the global AI market is estimated to be $23.3 billion, according to a report by market research firm Grand View Research. This growth in the industry is due to the significant advancements in AI, machine learning, and deep learning, which have led to the development of new applications and services. The growth of the industry will continue to drive the market growth in the coming years. Additionally, as the demand for AI solutions increases, the market will also continue to expand. \n",
      "\n",
      "As AI technology continues to evolve\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(f\"Prompt: {prompt}\\nGenerated text: {output['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Synchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T05:37:56.188013Z",
     "iopub.status.busy": "2025-10-17T05:37:56.187846Z",
     "iopub.status.idle": "2025-10-17T05:37:56.897103Z",
     "shell.execute_reply": "2025-10-17T05:37:56.896239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing synchronous streaming generation with overlap removal ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  [Name] and I am a [job title] at [company name]. I have been working here for [number of years] years and have always been passionate about [job title] and have always wanted to [job title] at [company name]. I am always looking for new challenges and opportunities to grow and learn. I am a team player and always strive to work with others to achieve our goals. I am always open to new ideas and have a positive attitude. I am excited to be a part of [company name] and contribute to the success of our team. Thank you for considering me for the position. [Name\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  Paris, the city known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. It is also home to the French Parliament, the French Academy of Sciences, and the French National Library. Paris is a bustling metropolis with a rich cultural heritage and is a major tourist destination. It is also known for its fashion industry and its role in the French economy. The city is home to many famous French artists and writers, and it is a popular destination for tourists and locals alike. Paris is a city of contrasts, with its modern architecture and historical landmarks blending seamlessly into one another. It\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  likely to be characterized by a number of trends that are expected to shape the way we live, work, and interact with technology. Here are some of the most likely future trends in AI:\n",
      "\n",
      "1. Increased automation: AI is expected to become more and more integrated into our daily lives, from manufacturing to customer service. We may see more automation in areas such as manufacturing, healthcare, and transportation.\n",
      "\n",
      "2. Personalization: AI is expected to become more personalized, with machines learning to understand and adapt to individual users' needs and preferences. This could lead to more efficient and effective use of resources.\n",
      "\n",
      "3. Ethical considerations: As AI becomes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "print(\"\\n=== Testing synchronous streaming generation with overlap removal ===\\n\")\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    merged_output = stream_and_merge(llm, prompt, sampling_params)\n",
    "    print(\"Generated text:\", merged_output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Asynchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T05:37:56.899001Z",
     "iopub.status.busy": "2025-10-17T05:37:56.898836Z",
     "iopub.status.idle": "2025-10-17T05:37:57.134356Z",
     "shell.execute_reply": "2025-10-17T05:37:57.133565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing asynchronous batch generation ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text:  [Name], and I'm an AI assistant. I'm programmed to assist users of all ages and backgrounds with a wide range of questions and information. I'm here to provide help, answer questions, and help people learn about the world around us. I'm here to provide you with a helpful and informative response to your queries. So, what's your name? Let's chat! [Name] [Your name] [What is your title or role]? Hello, my name is [Name], and I'm an AI assistant. I'm programmed to assist users of all ages and backgrounds with a wide range of questions and information. I\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text:  Paris, the city where the Eiffel Tower stands. To summarize in a concise statement: Paris is the largest city in France, known for its iconic Eiffel Tower, and is also the capital city of France. \n",
      "\n",
      "A shorter concise statement could be: \"Paris, the city with the Eiffel Tower, is the capital of France.\" \n",
      "\n",
      "This statement encapsulates the essential information in a single, clear sentence. However, a more concise alternative might be: \"Paris, the world's largest city, has an iconic Eiffel Tower and is the capital of France.\" This option leaves out the details of the Eiff\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text:  likely to be shaped by a number of trends that are currently being developed and will likely continue to develop in the coming years. Here are some of the key trends that are expected to shape the future of AI:\n",
      "\n",
      "1. Increased use of AI in healthcare: AI is already being used in a variety of healthcare applications, from diagnosis and treatment to patient care and monitoring. As the technology advances, it is likely that we will see even more widespread use of AI in healthcare in the coming years.\n",
      "\n",
      "2. Advancements in natural language processing: Natural language processing (NLP) is a critical component of AI that is used to enable machines to understand\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing asynchronous batch generation ===\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    outputs = await llm.async_generate(prompts, sampling_params)\n",
    "\n",
    "    for prompt, output in zip(prompts, outputs):\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(f\"Generated text: {output['text']}\")\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Asynchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T05:37:57.136019Z",
     "iopub.status.busy": "2025-10-17T05:37:57.135852Z",
     "iopub.status.idle": "2025-10-17T05:37:57.724829Z",
     "shell.execute_reply": "2025-10-17T05:37:57.724051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing asynchronous streaming generation (no repeats) ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ["
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Name"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ["
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " your"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " profession"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " or"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " role"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " here"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " like"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " doctor"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lawyer"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chef"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " etc"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " currently"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ["
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " your"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " age"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " occupation"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " any"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " notable"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accomplishments"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " here"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " like"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " being"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " captain"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " team"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " or"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " winning"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " major"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " competition"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " And"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hope"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " this"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " introduction"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " helpful"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " giving"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " general"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " idea"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " who"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " do"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " If"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " there"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anything"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " specific"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'d"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " like"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " know"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " me"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " please"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " don"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hesitate"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ask"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " world"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " please"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " feel"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " free"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ask"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " me"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anything"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'d"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " like"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " know"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " look"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " forward"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " meeting"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Good"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bye"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ["
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Open"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " January"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " capital"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " French"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kingdom"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Located"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " north"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " central"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " part"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " country"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " at"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " con"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluence"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Se"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ine"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ire"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rivers"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Famous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iconic"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iff"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tower"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lou"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vre"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Museum"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Notre"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ame"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cathedral"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Home"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " numerous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " world"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-ren"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owned"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " museums"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " art"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " galleries"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " concert"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " halls"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Str"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uck"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " by"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lightning"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " April"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " result"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lightning"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " strikes"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " across"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Known"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " diverse"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " culture"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cuisine"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " including"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " famous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ian"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bright"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trajectory"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " uncertain"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " While"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " we"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " can"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anticipate"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " some"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " broad"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trends"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " we"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " can"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predict"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " their"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " exact"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trajectory"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " However"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " we"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " can"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " observe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " some"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " emerging"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trends"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " that"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " are"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " likely"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " landscape"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coming"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " years"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " are"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " some"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " possible"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " future"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trends"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Integration"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " other"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " technologies"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " becoming"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " more"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " more"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " integrated"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " other"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " technologies"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " like"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sensors"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " connected"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " devices"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Internet"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Things"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Io"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " integration"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " will"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " likely"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " create"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " new"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " opportunities"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " challenges"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " researchers"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " developers"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Increased"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " use"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " autonomous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vehicles"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rise"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " self"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-driving"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cars"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " other"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " autonomous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vehicles"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " likely"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " drive"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " significant"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " growth"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing asynchronous streaming generation (no repeats) ===\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    for prompt in prompts:\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(\"Generated text: \", end=\"\", flush=True)\n",
    "\n",
    "        # Replace direct calls to async_generate with our custom overlap-aware version\n",
    "        async for cleaned_chunk in async_stream_and_merge(llm, prompt, sampling_params):\n",
    "            print(cleaned_chunk, end=\"\", flush=True)\n",
    "\n",
    "        print()  # New line after each prompt\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T05:37:57.726902Z",
     "iopub.status.busy": "2025-10-17T05:37:57.726740Z",
     "iopub.status.idle": "2025-10-17T05:37:57.758511Z",
     "shell.execute_reply": "2025-10-17T05:37:57.757684Z"
    }
   },
   "outputs": [],
   "source": [
    "llm.shutdown()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
