{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Engine API\n",
    "\n",
    "SGLang provides a direct inference engine without the need for an HTTP server, especially for use cases where additional HTTP server adds unnecessary complexity or overhead. Here are two general use cases:\n",
    "\n",
    "- Offline Batch Inference\n",
    "- Custom Server on Top of the Engine\n",
    "\n",
    "This document focuses on the offline batch inference, demonstrating four different inference modes:\n",
    "\n",
    "- Non-streaming synchronous generation\n",
    "- Streaming synchronous generation\n",
    "- Non-streaming asynchronous generation\n",
    "- Streaming asynchronous generation\n",
    "\n",
    "Additionally, you can easily build a custom server on top of the SGLang offline engine. A detailed example working in a python script can be found in [custom_server](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/custom_server.py).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nest Asyncio\n",
    "Note that if you want to use **Offline Engine** in ipython or some other nested loop code, you need to add the following code:\n",
    "```python\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "\n",
    "The engine supports [vlm inference](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/offline_batch_inference_vlm.py) as well as [extracting hidden states](https://github.com/sgl-project/sglang/blob/main/examples/runtime/hidden_states). \n",
    "\n",
    "Please see [the examples](https://github.com/sgl-project/sglang/tree/main/examples/runtime/engine) for further use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Batch Inference\n",
    "\n",
    "SGLang offline engine supports batch inference with efficient scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:43:34.087910Z",
     "iopub.status.busy": "2025-10-01T20:43:34.087795Z",
     "iopub.status.idle": "2025-10-01T20:43:57.385779Z",
     "shell.execute_reply": "2025-10-01T20:43:57.385169Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.configuration_utils:`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "[2025-10-01 20:43:50] `torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.19it/s]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.18it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]\r",
      "Capturing batches (bs=128 avail_mem=27.95 GB):   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=128 avail_mem=27.95 GB):   5%|▌         | 1/20 [00:00<00:11,  1.69it/s]\r",
      "Capturing batches (bs=120 avail_mem=27.84 GB):   5%|▌         | 1/20 [00:00<00:11,  1.69it/s]\r",
      "Capturing batches (bs=112 avail_mem=27.84 GB):   5%|▌         | 1/20 [00:00<00:11,  1.69it/s]\r",
      "Capturing batches (bs=112 avail_mem=27.84 GB):  15%|█▌        | 3/20 [00:00<00:03,  4.91it/s]\r",
      "Capturing batches (bs=104 avail_mem=27.34 GB):  15%|█▌        | 3/20 [00:00<00:03,  4.91it/s]\r",
      "Capturing batches (bs=96 avail_mem=27.34 GB):  15%|█▌        | 3/20 [00:00<00:03,  4.91it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=88 avail_mem=27.33 GB):  15%|█▌        | 3/20 [00:00<00:03,  4.91it/s]\r",
      "Capturing batches (bs=88 avail_mem=27.33 GB):  30%|███       | 6/20 [00:00<00:01,  9.20it/s]\r",
      "Capturing batches (bs=80 avail_mem=27.33 GB):  30%|███       | 6/20 [00:00<00:01,  9.20it/s]\r",
      "Capturing batches (bs=72 avail_mem=27.32 GB):  30%|███       | 6/20 [00:00<00:01,  9.20it/s]\r",
      "Capturing batches (bs=64 avail_mem=27.32 GB):  30%|███       | 6/20 [00:00<00:01,  9.20it/s]\r",
      "Capturing batches (bs=64 avail_mem=27.32 GB):  45%|████▌     | 9/20 [00:01<00:00, 12.60it/s]\r",
      "Capturing batches (bs=56 avail_mem=27.31 GB):  45%|████▌     | 9/20 [00:01<00:00, 12.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=48 avail_mem=27.31 GB):  45%|████▌     | 9/20 [00:01<00:00, 12.60it/s]\r",
      "Capturing batches (bs=40 avail_mem=27.30 GB):  45%|████▌     | 9/20 [00:01<00:00, 12.60it/s]\r",
      "Capturing batches (bs=40 avail_mem=27.30 GB):  60%|██████    | 12/20 [00:01<00:00, 15.16it/s]\r",
      "Capturing batches (bs=32 avail_mem=27.30 GB):  60%|██████    | 12/20 [00:01<00:00, 15.16it/s]\r",
      "Capturing batches (bs=24 avail_mem=27.29 GB):  60%|██████    | 12/20 [00:01<00:00, 15.16it/s]\r",
      "Capturing batches (bs=16 avail_mem=27.29 GB):  60%|██████    | 12/20 [00:01<00:00, 15.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=16 avail_mem=27.29 GB):  75%|███████▌  | 15/20 [00:01<00:00, 15.30it/s]\r",
      "Capturing batches (bs=12 avail_mem=27.29 GB):  75%|███████▌  | 15/20 [00:01<00:00, 15.30it/s]\r",
      "Capturing batches (bs=8 avail_mem=27.28 GB):  75%|███████▌  | 15/20 [00:01<00:00, 15.30it/s] \r",
      "Capturing batches (bs=8 avail_mem=27.28 GB):  85%|████████▌ | 17/20 [00:01<00:00, 13.51it/s]\r",
      "Capturing batches (bs=4 avail_mem=27.27 GB):  85%|████████▌ | 17/20 [00:01<00:00, 13.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=2 avail_mem=27.27 GB):  85%|████████▌ | 17/20 [00:01<00:00, 13.51it/s]\r",
      "Capturing batches (bs=2 avail_mem=27.27 GB):  95%|█████████▌| 19/20 [00:01<00:00, 12.66it/s]\r",
      "Capturing batches (bs=1 avail_mem=27.27 GB):  95%|█████████▌| 19/20 [00:01<00:00, 12.66it/s]\r",
      "Capturing batches (bs=1 avail_mem=27.27 GB): 100%|██████████| 20/20 [00:01<00:00, 11.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# launch the offline engine\n",
    "import asyncio\n",
    "\n",
    "import sglang as sgl\n",
    "import sglang.test.doc_patch\n",
    "from sglang.utils import async_stream_and_merge, stream_and_merge\n",
    "\n",
    "llm = sgl.Engine(model_path=\"qwen/qwen2.5-0.5b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Synchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:43:57.388681Z",
     "iopub.status.busy": "2025-10-01T20:43:57.388223Z",
     "iopub.status.idle": "2025-10-01T20:43:58.434898Z",
     "shell.execute_reply": "2025-10-01T20:43:58.434175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: Hello, my name is\n",
      "Generated text:  Shane, and I am a character from the popular Nintendo series Super Mario Bros. and the sequel Super Mario 64. In this post, I will be discussing my character, Shriek, and his various abilities and strategies in the game.\n",
      "The Super Mario Bros. Supercombo\n",
      "Shriek is the main character of the game, and he is a mysterious character known as \"The Shriek,\" as he is constantly making and shrieking. He is one of the few characters who do not have a special ability that makes him an enemy to Mario. He will not appear in the beginning, but he will appear and\n",
      "===============================\n",
      "Prompt: The president of the United States is\n",
      "Generated text:  a person. ( )\n",
      "A: Sufficient but not necessary condition\n",
      "B: Necessary but not sufficient condition\n",
      "C: Both sufficient and necessary condition\n",
      "D: Neither sufficient nor necessary condition\n",
      "To determine the relationship between the president of the United States and a person, let's analyze the given statement: \"The president of the United States is a person.\"\n",
      "\n",
      "1. **Identify the parts of the statement:**\n",
      "   - The president of the United States is a person.\n",
      "   - The president of the United States is a president.\n",
      "\n",
      "2. **Analyze the logical relationship:**\n",
      "   - If someone is a president of the United States\n",
      "===============================\n",
      "Prompt: The capital of France is\n",
      "Generated text:  Paris.\n",
      "A. True\n",
      "B. False\n",
      "Answer:\n",
      "A\n",
      "\n",
      "The functions of a microcomputer protection device include ____.\n",
      "A. Current differential protection, overcurrent protection\n",
      "B. Zero-sequence current protection\n",
      "C. Differential current protection\n",
      "D. Current differential protection, overcurrent protection, zero-sequence current protection, and differential current protection\n",
      "Answer:\n",
      "D\n",
      "\n",
      "The Smart Energy System Informationization (Seismicity) Emergency Response Plan should include ____. \n",
      "A. Emergency response procedure for seismic events\n",
      "B. Local public emergency response plan\n",
      "C. Local emergency management plan\n",
      "D. Provincial emergency management plan\n",
      "Answer:\n",
      "A\n",
      "\n",
      "\n",
      "===============================\n",
      "Prompt: The future of AI is\n",
      "Generated text:  here, but we are not where we want to be. In a recent Google I/O conference, CEO Sundar Pichai discussed the future of AI, and the path to a more efficient, effective, and ethical AI system. A few of the key points he made included:\n",
      "\n",
      "1. The drive to create an AI system that can understand, learn, and adapt to new data, without being heavily influenced by bias. It requires a lot of information and data to train the system.\n",
      "\n",
      "2. The current AI system is biased, and it is not aware of its bias. This is because the data used to train the system is mostly\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(f\"Prompt: {prompt}\\nGenerated text: {output['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Synchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:43:58.436907Z",
     "iopub.status.busy": "2025-10-01T20:43:58.436729Z",
     "iopub.status.idle": "2025-10-01T20:43:59.146591Z",
     "shell.execute_reply": "2025-10-01T20:43:59.146044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing synchronous streaming generation with overlap removal ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  [Name], and I'm a [Job Title] at [Company Name]. I'm excited to meet you and learn more about your career. What can I expect from our conversation? [Name] is looking for a [Type of Job] at [Company Name]. I'm excited to hear about your experience and what you can offer. What can I expect from our conversation? [Name] is looking for a [Type of Job] at [Company Name]. I'm excited to hear about your experience and what you can offer. What can I expect from our conversation? [Name] is looking for a [Type of Job] at\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  Paris, which is known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. It is also home to the French Parliament, the French Academy of Sciences, and the French National Library. Paris is a bustling city with a rich history and culture, and it is a popular tourist destination. It is also known for its fashion industry, with many famous designers and boutiques located in the city. Paris is a city that is constantly evolving and changing, with new developments and attractions being added to the city's skyline. It is a city that is full of life and energy, and it\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  likely to be characterized by several key trends:\n",
      "\n",
      "1. Increased automation: AI will continue to automate routine tasks, freeing up human workers to focus on more complex and creative work. This will lead to increased efficiency and productivity, but it will also lead to job displacement for some workers.\n",
      "\n",
      "2. AI will become more integrated with other technologies: AI will continue to be integrated with other technologies, such as machine learning, natural language processing, and computer vision. This will lead to new applications and opportunities for AI, such as autonomous vehicles, smart homes, and personalized medicine.\n",
      "\n",
      "3. AI will become more ethical and transparent: As AI becomes more integrated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "print(\"\\n=== Testing synchronous streaming generation with overlap removal ===\\n\")\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    merged_output = stream_and_merge(llm, prompt, sampling_params)\n",
    "    print(\"Generated text:\", merged_output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Asynchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:43:59.148040Z",
     "iopub.status.busy": "2025-10-01T20:43:59.147893Z",
     "iopub.status.idle": "2025-10-01T20:43:59.373130Z",
     "shell.execute_reply": "2025-10-01T20:43:59.372596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing asynchronous batch generation ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text:  [Name], and I'm a/an [Age] year old [Occupation] [Bios or Personal Details]. I'm passionate about [Your Passion, like music, books, sports, etc.]. I love [What you do best]. I'm a/an [Type of Person, like extroverted, introverted, etc.]. I love to [What you enjoy doing, like reading, writing, dancing, etc.]. My favorite hobby is [What your hobby is, like playing a sport, hiking, painting, etc.]. I'm a/an [Who you are, like a smart, kind, funny,\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text:  Paris.\n",
      "Paris is the capital city of France, located on the Île de la Cité and the right bank of the Seine River. It is home to the Eiffel Tower, Louvre Museum, Notre Dame Cathedral, and many other historical and cultural landmarks. The city is also a major transportation hub, with the Grand Canal and the Eiffel Tower as landmarks. Paris is known for its romantic and artistic culture, as well as its vibrant nightlife and fashion scene. Its rich history and diverse attractions make it a popular tourist destination. The city is also home to the European Parliament, the most powerful institution in France, and\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text:  likely to be a highly interconnected and dynamic field, with several key trends expected to shape the development of this technology in the coming years.\n",
      "\n",
      "One of the most significant trends is the increasing integration of AI into everyday life, from the devices we use every day to the decisions we make in our daily lives. We expect to see more seamless integration of AI into our homes, transportation, and other areas, as well as more widespread adoption of AI in healthcare, finance, and education.\n",
      "\n",
      "Another trend is the growth of machine learning, which will enable AI to learn and improve on its own as it processes data. As AI becomes more sophisticated, it will\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing asynchronous batch generation ===\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    outputs = await llm.async_generate(prompts, sampling_params)\n",
    "\n",
    "    for prompt, output in zip(prompts, outputs):\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(f\"Generated text: {output['text']}\")\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Asynchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:43:59.374512Z",
     "iopub.status.busy": "2025-10-01T20:43:59.374362Z",
     "iopub.status.idle": "2025-10-01T20:43:59.992494Z",
     "shell.execute_reply": "2025-10-01T20:43:59.991918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing asynchronous streaming generation (no repeats) ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ["
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Name"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ["
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " your"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " occupation"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " expert"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " passionate"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " learning"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " exploring"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " world"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " around"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " me"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " always"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " looking"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " new"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " exciting"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " experiences"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " believe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " power"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " resilience"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ready"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " take"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " whatever"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " life"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " throws"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " way"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " enjoy"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spending"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " time"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " outdoors"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reading"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " books"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " traveling"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " My"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dedication"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " craft"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " unw"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ering"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " committed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " making"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " world"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " better"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " place"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " through"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " work"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " world"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " let"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " make"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wonderful"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " one"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " together"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intro"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Career"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ience"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insp"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iration"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pod"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cast"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outdoor"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " capital"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " most"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " populous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " also"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " known"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ité"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " City"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " located"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Î"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " de"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gar"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onne"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " River"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " south"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " country"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " seat"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " government"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " most"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " important"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " political"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " economic"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cultural"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " center"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " known"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " art"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " music"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cuisine"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " famous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " medieval"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " architecture"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " including"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iff"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tower"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " annual"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cout"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ure"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " haute"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cout"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ure"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fashion"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shows"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " also"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " major"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tourist"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " destination"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rich cultural"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and artistic"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " heritage,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " home"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " expected"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " continue"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " evolve"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " become"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " more"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " diverse"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " efficient"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ethical"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " are"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " some"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " potential"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trends"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " field"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Increased"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Use"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Manufacturing"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " expected"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " play"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " larger"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " role"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " manufacturing"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " future"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " companies"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " seek"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reduce"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " costs"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " improve"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " efficiency"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " increase"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " productivity"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " will"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " likely"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " involve"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " use"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " machine"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " learning"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " algorithms"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " analyze"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " make"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " informed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " decisions"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " such"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adjusting"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " production"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processes"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " or"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " optimizing"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " supply"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chains"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Healthcare"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " also"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " expected"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " have"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " significant"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " impact"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " healthcare"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " use"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " machine"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " learning"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " algorithms"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " being"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " used"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " diagnose"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " diseases"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predict"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " patient"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " outcomes"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " develop"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " personalized"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " treatment"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing asynchronous streaming generation (no repeats) ===\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    for prompt in prompts:\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(\"Generated text: \", end=\"\", flush=True)\n",
    "\n",
    "        # Replace direct calls to async_generate with our custom overlap-aware version\n",
    "        async for cleaned_chunk in async_stream_and_merge(llm, prompt, sampling_params):\n",
    "            print(cleaned_chunk, end=\"\", flush=True)\n",
    "\n",
    "        print()  # New line after each prompt\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:43:59.995239Z",
     "iopub.status.busy": "2025-10-01T20:43:59.995081Z",
     "iopub.status.idle": "2025-10-01T20:44:00.050380Z",
     "shell.execute_reply": "2025-10-01T20:44:00.049640Z"
    }
   },
   "outputs": [],
   "source": [
    "llm.shutdown()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
