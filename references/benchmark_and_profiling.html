
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Benchmark and Profiling &#8212; SGLang</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9f3ce967"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'references/benchmark_and_profiling';</script>
    <link rel="icon" href="../_static/logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Measuring Model Accuracy in SGLang" href="accuracy_evaluation.html" />
    <link rel="prev" title="Performance Analysis &amp; Optimization" href="performance_analysis_and_optimization.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jun 27, 2025"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="SGLang - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="SGLang - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../start/install.html">Install SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Backend Tutorial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="deepseek.html">DeepSeek Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="llama4.html">Llama4 Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/send_request.html">Sending Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/openai_api_completions.html">OpenAI APIs - Completions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/openai_api_vision.html">OpenAI APIs - Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/openai_api_embeddings.html">OpenAI APIs - Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/native_api.html">SGLang Native APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/offline_engine_api.html">Offline Engine API</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Backend Configurations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../backend/server_arguments.html">Server Arguments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/sampling_params.html">Sampling Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/hyperparameter_tuning.html">Hyperparameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/attention_backend.html">Attention Backend</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supported Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../supported_models/generative_models.html">Large Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/multimodal_language_models.html">Multimodal Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/embedding_models.html">Embedding Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/reward_models.html">Reward Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/support_new_models.html">How to Support New Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/transformers_fallback.html">Transformers fallback in SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../backend/speculative_decoding.html">Speculative Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/function_calling.html">Tool and Function Calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/separate_reasoning.html">Reasoning Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/structured_outputs_for_reasoning_models.html">Structured Outputs For Reasoning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/custom_chat_template.html">Custom Chat Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/lora.html">LoRA Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/pd_disaggregation.html">PD Disaggregation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frontend Tutorial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../frontend/frontend.html">SGLang Frontend Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/choices_methods.html">Choices Methods in SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SGLang Router</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../router/router.html">Router for Data Parallelism</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="general.html">General Guidance</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware.html">Hardware Supports</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_deploy.html">Multi-Node Deployment</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="performance_analysis_and_optimization.html">Performance Analysis &amp; Optimization</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Benchmark and Profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="accuracy_evaluation.html">Measuring Model Accuracy in SGLang</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="developer.html">Developer Reference</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/blob/main/references/benchmark_and_profiling.md?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/edit/main/references/benchmark_and_profiling.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/issues/new?title=Issue%20on%20page%20%2Freferences/benchmark_and_profiling.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/references/benchmark_and_profiling.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Benchmark and Profiling</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#benchmark">Benchmark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#profile-with-pytorch-profiler">Profile with PyTorch Profiler</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#profile-with-nsight">Profile with Nsight</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-tips">Other tips</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="benchmark-and-profiling">
<h1>Benchmark and Profiling<a class="headerlink" href="#benchmark-and-profiling" title="Link to this heading">#</a></h1>
<section id="benchmark">
<h2>Benchmark<a class="headerlink" href="#benchmark" title="Link to this heading">#</a></h2>
<ul>
<li><p>Benchmark the latency of running a single static batch without a server. The arguments are the same as for <code class="docutils literal notranslate"><span class="pre">launch_server.py</span></code>.
Note that this is a simplified test script without a dynamic batching server, so it may run out of memory for a batch size that a real server can handle. A real server truncates the prefill into several batches, while this simplified script does not.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>sglang.bench_one_batch<span class="w"> </span>--model-path<span class="w"> </span>meta-llama/Meta-Llama-3.1-8B-Instruct<span class="w"> </span>--batch<span class="w"> </span><span class="m">32</span><span class="w"> </span>--input-len<span class="w"> </span><span class="m">256</span><span class="w"> </span>--output-len<span class="w"> </span><span class="m">32</span>
</pre></div>
</div>
</li>
<li><p>Benchmark offline processing. This script will start an offline engine and run the benchmark.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>sglang.bench_offline_throughput<span class="w"> </span>--model-path<span class="w"> </span>meta-llama/Meta-Llama-3.1-8B-Instruct<span class="w"> </span>--num-prompts<span class="w"> </span><span class="m">10</span>
</pre></div>
</div>
</li>
<li><p>Benchmark online serving. Please use <code class="docutils literal notranslate"><span class="pre">sglang.launch_server</span></code> to launch a server first and run the following command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>sglang.bench_serving<span class="w"> </span>--backend<span class="w"> </span>sglang<span class="w"> </span>--num-prompt<span class="w"> </span><span class="m">10</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="profile-with-pytorch-profiler">
<h2>Profile with PyTorch Profiler<a class="headerlink" href="#profile-with-pytorch-profiler" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html">Pytorch Profiler</a> is a convenient basic tool to inspect kernel execution time, call stack, and kernel overlap and occupancy.</p>
<ul>
<li><p>To profile a server</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># set trace path</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">SGLANG_TORCH_PROFILER_DIR</span><span class="o">=</span>/root/sglang/profile_log

<span class="c1"># start server</span>
python<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>meta-llama/Llama-3.1-8B-Instruct

<span class="c1"># send profiling request from client</span>
python<span class="w"> </span>-m<span class="w"> </span>sglang.bench_serving<span class="w"> </span>--backend<span class="w"> </span>sglang<span class="w"> </span>--model<span class="w"> </span>meta-llama/Llama-3.1-8B-Instruct<span class="w"> </span>--num-prompts<span class="w"> </span><span class="m">10</span><span class="w"> </span>--sharegpt-output-len<span class="w"> </span><span class="m">100</span><span class="w"> </span>--profile
</pre></div>
</div>
<p>Please make sure that the <code class="docutils literal notranslate"><span class="pre">SGLANG_TORCH_PROFILER_DIR</span></code> should be set at both server and client side, otherwise the trace file cannot be generated correctly . A secure way will be setting <code class="docutils literal notranslate"><span class="pre">SGLANG_TORCH_PROFILER_DIR</span></code> in the <code class="docutils literal notranslate"><span class="pre">.*rc</span></code> file of shell (e.g. <code class="docutils literal notranslate"><span class="pre">~/.bashrc</span></code> for bash shells).</p>
</li>
<li><p>To profile offline</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">SGLANG_TORCH_PROFILER_DIR</span><span class="o">=</span>/root/sglang/profile_log

<span class="c1"># profile one batch with bench_one_batch.py</span>
<span class="c1"># batch size can be controlled with --batch argument</span>
python3<span class="w"> </span>-m<span class="w"> </span>sglang.bench_one_batch<span class="w"> </span>--model-path<span class="w"> </span>meta-llama/Llama-3.1-8B-Instruct<span class="w"> </span>--batch<span class="w"> </span><span class="m">32</span><span class="w"> </span>--input-len<span class="w"> </span><span class="m">1024</span><span class="w"> </span>--output-len<span class="w"> </span><span class="m">10</span><span class="w"> </span>--profile

<span class="c1"># profile multiple batches with bench_offline_throughput.py</span>
python<span class="w"> </span>-m<span class="w"> </span>sglang.bench_offline_throughput<span class="w"> </span>--model-path<span class="w"> </span>meta-llama/Llama-3.1-8B-Instruct<span class="w"> </span>--dataset-name<span class="w"> </span>random<span class="w"> </span>--num-prompts<span class="w"> </span><span class="m">10</span><span class="w"> </span>--profile<span class="w"> </span>--mem-frac<span class="o">=</span><span class="m">0</span>.8
</pre></div>
</div>
</li>
<li><p>Possible PyTorch Bug
If in any cases you encounter the following error (for example, using qwen 2.5 VL):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>RuntimeError:<span class="w"> </span>!stack.empty<span class="o">()</span><span class="w"> </span>INTERNAL<span class="w"> </span>ASSERT<span class="w"> </span>FAILED<span class="w"> </span>at<span class="w"> </span><span class="s2">&quot;/pytorch/torch/csrc/autograd/profiler_python.cpp&quot;</span>:983,<span class="w"> </span>please<span class="w"> </span>report<span class="w"> </span>a<span class="w"> </span>bug<span class="w"> </span>to<span class="w"> </span>PyTorch.<span class="w"> </span>Python<span class="w"> </span>replay<span class="w"> </span>stack<span class="w"> </span>is<span class="w"> </span>empty.
</pre></div>
</div>
<p>This is likely a PyTorch Bug reported in <a class="reference external" href="https://github.com/vllm-project/vllm/issues/18240">Bug: vLLM Profiler</a> and <a class="reference external" href="https://github.com/pytorch/pytorch/issues/101632">Bug: torch.profiler.profile</a>. As a workaround, you may disable <code class="docutils literal notranslate"><span class="pre">with_stack</span></code> with an environment variable such as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">SGLANG_PROFILE_WITH_STACK</span><span class="o">=</span>False
python<span class="w"> </span>-m<span class="w"> </span>sglang.bench_offline_throughput<span class="w"> </span>--model-path<span class="w"> </span>meta-llama/Llama-3.1-8B-Instruct<span class="w"> </span>--dataset-name<span class="w"> </span>random<span class="w"> </span>--num-prompts<span class="w"> </span><span class="m">10</span><span class="w"> </span>--profile<span class="w"> </span>--mem-frac<span class="o">=</span><span class="m">0</span>.8
</pre></div>
</div>
</li>
<li><p>View Traces</p>
<p>Trace files can be loaded and visualized from:</p>
<ol class="arabic simple">
<li><p>https://ui.perfetto.dev/ (any browser)</p></li>
<li><p>chrome://tracing (Chrome browser only)</p></li>
</ol>
<p>If browser cannot open trace file due to its large size,
client can generate a small trace file (&lt;100MB) by controlling number of prompts and lengths of prompt outputs.
For example, when profiling a server,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>sglang.bench_serving<span class="w"> </span>--backend<span class="w"> </span>sglang<span class="w"> </span>--model<span class="w"> </span>meta-llama/Llama-3.1-8B-Instruct<span class="w"> </span>--num-prompts<span class="w"> </span><span class="m">2</span><span class="w"> </span>--sharegpt-output-len<span class="w"> </span><span class="m">100</span><span class="w"> </span>--profile
</pre></div>
</div>
<p>This command sets the number of prompts to 2 with <code class="docutils literal notranslate"><span class="pre">--num-prompts</span></code> argument and limits the length of output sequences to 100 with <code class="docutils literal notranslate"><span class="pre">--sharegpt-output-len</span></code> argument, which can generate a small trace file for browser to open smoothly.</p>
<p>Additionally, if you want to locate the SGLang Python source code through the cuda kernel in Trace, you need to disable CUDA Graph when starting the service. This can be done by using the <code class="docutils literal notranslate"><span class="pre">--disable-cuda-graph</span></code> parameter in the command to start the service.</p>
</li>
</ul>
</section>
<section id="profile-with-nsight">
<h2>Profile with Nsight<a class="headerlink" href="#profile-with-nsight" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://docs.nvidia.com/nsight-systems/">Nsight systems</a> is an advanced tool that exposes more profiling details, such as register and shared memory usage, annotated code regions and low-level CUDA APIs and events.</p>
<ol class="arabic">
<li><p>Prerequisite:</p>
<p>Install using apt, or run inside a <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags">NVIDIA Docker container</a> or <a class="reference external" href="https://github.com/sgl-project/sglang/tree/main/docker">SGLang Docker container</a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># install nsys</span>
<span class="c1"># https://docs.nvidia.com/nsight-systems/InstallationGuide/index.html</span>
apt<span class="w"> </span>update
apt<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>--no-install-recommends<span class="w"> </span>gnupg
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;deb http://developer.download.nvidia.com/devtools/repos/ubuntu</span><span class="k">$(</span><span class="nb">source</span><span class="w"> </span>/etc/lsb-release<span class="p">;</span><span class="w"> </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$DISTRIB_RELEASE</span><span class="s2">&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>tr<span class="w"> </span>-d<span class="w"> </span>.<span class="k">)</span><span class="s2">/</span><span class="k">$(</span>dpkg<span class="w"> </span>--print-architecture<span class="k">)</span><span class="s2"> /&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/nvidia-devtools.list
apt-key<span class="w"> </span>adv<span class="w"> </span>--fetch-keys<span class="w"> </span>http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub
apt<span class="w"> </span>update
apt<span class="w"> </span>install<span class="w"> </span>nsight-systems-cli
</pre></div>
</div>
</li>
<li><p>To profile a single batch, use</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nsys<span class="w"> </span>profile<span class="w"> </span>--trace-fork-before-exec<span class="o">=</span><span class="nb">true</span><span class="w"> </span>--cuda-graph-trace<span class="o">=</span>node<span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>sglang.bench_one_batch<span class="w"> </span>--model<span class="w"> </span>meta-llama/Meta-Llama-3-8B<span class="w"> </span>--batch-size<span class="w"> </span><span class="m">64</span><span class="w"> </span>--input-len<span class="w"> </span><span class="m">512</span>
</pre></div>
</div>
</li>
<li><p>To profile a server, e.g.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># launch the server, set the delay and duration times according to needs</span>
<span class="c1"># after the duration time has been used up, server will be killed by nsys</span>

nsys<span class="w"> </span>profile<span class="w"> </span>--trace-fork-before-exec<span class="o">=</span><span class="nb">true</span><span class="w"> </span>--cuda-graph-trace<span class="o">=</span>node<span class="w"> </span>-o<span class="w"> </span>sglang.out<span class="w"> </span>--delay<span class="w"> </span><span class="m">60</span><span class="w"> </span>--duration<span class="w"> </span><span class="m">70</span><span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>meta-llama/Llama-3.1-8B-Instruct<span class="w"> </span>--disable-radix-cache

<span class="c1"># client</span>
python3<span class="w"> </span>-m<span class="w"> </span>sglang.bench_serving<span class="w"> </span>--backend<span class="w"> </span>sglang<span class="w"> </span>--num-prompts<span class="w"> </span><span class="m">1000</span><span class="w"> </span>--dataset-name<span class="w"> </span>random<span class="w"> </span>--random-input<span class="w"> </span><span class="m">1024</span><span class="w"> </span>--random-output<span class="w"> </span><span class="m">512</span>
</pre></div>
</div>
<p>In practice, we recommend users to set <code class="docutils literal notranslate"><span class="pre">--duration</span></code> argument to a large value. Whenever user wants the server to stop profiling. Firstly run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nsys<span class="w"> </span>sessions<span class="w"> </span>list
</pre></div>
</div>
<p>to get the session id in the form of <code class="docutils literal notranslate"><span class="pre">profile-XXXXX</span></code>, then run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nsys<span class="w"> </span>stop<span class="w"> </span>--session<span class="o">=</span>profile-XXXXX
</pre></div>
</div>
<p>to manually kill the profiler and generate <code class="docutils literal notranslate"><span class="pre">nsys-rep</span></code> files instantly.</p>
</li>
<li><p>Use NVTX to annotate code regions, e.g. to see their execution time.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># install nvtx</span>
pip<span class="w"> </span>install<span class="w"> </span>nvtx
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># code snippets</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">nvtx</span>
<span class="k">with</span> <span class="n">nvtx</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;description&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;color&quot;</span><span class="p">):</span>
    <span class="c1"># some critical code</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="other-tips">
<h2>Other tips<a class="headerlink" href="#other-tips" title="Link to this heading">#</a></h2>
<ol class="arabic">
<li><p>You can benchmark a model using dummy weights by only providing the config.json file. This allows for quick testing of model variants without training. To do so, add <code class="docutils literal notranslate"><span class="pre">--load-format</span> <span class="pre">dummy</span></code> to the above commands and then you only need a correct <code class="docutils literal notranslate"><span class="pre">config.json</span></code> under the checkpoint folder.</p></li>
<li><p>You can benchmark a model with modified configs (e.g., less layers) by using <code class="docutils literal notranslate"><span class="pre">--json-model-override-args</span></code>. For example, you can benchmark a model with only 2 layers and 2 kv heads using:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>sglang.bench_one_batch<span class="w"> </span>--model-path<span class="w"> </span>meta-llama/Meta-Llama-3.1-8B-Instruct<span class="w"> </span>--batch<span class="w"> </span><span class="m">32</span><span class="w"> </span>--input-len<span class="w"> </span><span class="m">256</span><span class="w"> </span>--output-len<span class="w"> </span><span class="m">32</span><span class="w"> </span>--load-format<span class="w"> </span>dummy<span class="w"> </span>--json-model-override-args<span class="w"> </span><span class="s1">&#39;{&quot;num_hidden_layers&quot;: 1, &quot;num_key_value_heads&quot;: 1}&#39;</span>
</pre></div>
</div>
</li>
<li><p>You can use <code class="docutils literal notranslate"><span class="pre">--python-backtrace=cuda</span></code> to see python call stack for all CUDA kernels, as in PyTorch Profiler. (Caveat: this can cause inaccurately long kernel runtimes for CUDA event based timing)</p></li>
<li><p>For more arguments see <a class="reference external" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html">Nsight Systems User Guide</a>.</p></li>
</ol>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="performance_analysis_and_optimization.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Performance Analysis &amp; Optimization</p>
      </div>
    </a>
    <a class="right-next"
       href="accuracy_evaluation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Measuring Model Accuracy in SGLang</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#benchmark">Benchmark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#profile-with-pytorch-profiler">Profile with PyTorch Profiler</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#profile-with-nsight">Profile with Nsight</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-tips">Other tips</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By SGLang Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023-2025, SGLang.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Jun 27, 2025.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  
    <!-- RunLLM Widget Script -->
    <script type="module" id="runllm-widget-script" src="https://widget.runllm.com" crossorigin="true" version="stable" runllm-keyboard-shortcut="Mod+j" runllm-name="SGLang Chatbot" runllm-position="BOTTOM_RIGHT" runllm-assistant-id="629" async></script>
    
</body>
</html>