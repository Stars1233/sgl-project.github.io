{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI APIs - Vision\n",
    "\n",
    "SGLang provides OpenAI-compatible APIs to enable a smooth transition from OpenAI services to self-hosted local models.\n",
    "A complete reference for the API is available in the [OpenAI API Reference](https://platform.openai.com/docs/guides/vision).\n",
    "This tutorial covers the vision APIs for vision language models.\n",
    "\n",
    "SGLang supports various vision language models such as Llama 3.2, LLaVA-OneVision, Qwen2.5-VL, Gemma3 and [more](../supported_models/multimodal_language_models.md).\n",
    "\n",
    "As an alternative to the OpenAI API, you can also use the [SGLang offline engine](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/offline_batch_inference_vlm.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch A Server\n",
    "\n",
    "Launch the server in your terminal and wait for it to initialize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T22:00:10.913797Z",
     "iopub.status.busy": "2025-10-13T22:00:10.913670Z",
     "iopub.status.idle": "2025-10-13T22:01:05.636319Z",
     "shell.execute_reply": "2025-10-13T22:01:05.635790Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "WARNING:transformers.configuration_utils:`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-13 22:00:25] MOE_RUNNER_BACKEND is not initialized, the backend will be automatically selected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "[2025-10-13 22:00:34] `torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[2025-10-13 22:00:38] MOE_RUNNER_BACKEND is not initialized, the backend will be automatically selected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:00<00:03,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:01<00:02,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:02<00:01,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:03<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:03<00:00,  1.63it/s]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:03<00:00,  1.43it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]\r",
      "Capturing batches (bs=4 avail_mem=44.13 GB):   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=4 avail_mem=44.13 GB):  33%|███▎      | 1/3 [00:05<00:11,  5.65s/it]\r",
      "Capturing batches (bs=2 avail_mem=43.99 GB):  33%|███▎      | 1/3 [00:05<00:11,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=2 avail_mem=43.99 GB):  67%|██████▋   | 2/3 [00:10<00:04,  4.96s/it]\r",
      "Capturing batches (bs=1 avail_mem=60.79 GB):  67%|██████▋   | 2/3 [00:10<00:04,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=1 avail_mem=60.79 GB): 100%|██████████| 3/3 [00:11<00:00,  3.47s/it]\r",
      "Capturing batches (bs=1 avail_mem=60.79 GB): 100%|██████████| 3/3 [00:11<00:00,  3.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'><br><br>                    NOTE: Typically, the server runs in a separate terminal.<br>                    In this notebook, we run the server and notebook code together, so their outputs are combined.<br>                    To improve clarity, the server logs are displayed in the original black color, while the notebook outputs are highlighted in blue.<br>                    To reduce the log length, we set the log level to warning for the server, the default log level is info.<br>                    We are running those notebooks in a CI environment, so the throughput is not representative of the actual performance.<br>                    </strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sglang.test.doc_patch import launch_server_cmd\n",
    "from sglang.utils import wait_for_server, print_highlight, terminate_process\n",
    "\n",
    "vision_process, port = launch_server_cmd(\n",
    "    \"\"\"\n",
    "python3 -m sglang.launch_server --model-path Qwen/Qwen2.5-VL-7B-Instruct --log-level warning\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "wait_for_server(f\"http://localhost:{port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cURL\n",
    "\n",
    "Once the server is up, you can send test requests using curl or requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T22:01:05.639211Z",
     "iopub.status.busy": "2025-10-13T22:01:05.638838Z",
     "iopub.status.idle": "2025-10-13T22:01:10.340164Z",
     "shell.execute_reply": "2025-10-13T22:01:10.339629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{\"id\":\"c04d0ce901ba4450958d961dbe15d44f\",\"object\":\"chat.completion\",\"created\":1760392867,\"model\":\"Qwen/Qwen2.5-VL-7B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"The image shows a man standing on the back of a yellow taxi, using an iron to press or smooth out a pair of pants draped over an ironing board. The taxi is parked on a city street, and there are other taxis and buildings in the background. The man appears to be performing an unusual task, as ironing is typically done indoors.\",\"reasoning_content\":null,\"tool_calls\":null},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":151645}],\"usage\":{\"prompt_tokens\":307,\"total_tokens\":379,\"completion_tokens\":72,\"prompt_tokens_details\":null,\"reasoning_tokens\":0},\"metadata\":{\"weight_version\":\"default\"}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{\"id\":\"c6ad999d71fa4b98a574b6bd49ebfcd3\",\"object\":\"chat.completion\",\"created\":1760392870,\"model\":\"Qwen/Qwen2.5-VL-7B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"The image shows a man standing on the back of a yellow taxi, using an iron to press or smooth out a pair of pants draped over an ironing board. The taxi is parked on a city street, and there are other taxis and buildings in the background. The man appears to be performing an unusual task, as ironing is typically done indoors.\",\"reasoning_content\":null,\"tool_calls\":null},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":151645}],\"usage\":{\"prompt_tokens\":307,\"total_tokens\":379,\"completion_tokens\":72,\"prompt_tokens_details\":null,\"reasoning_tokens\":0},\"metadata\":{\"weight_version\":\"default\"}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "curl_command = f\"\"\"\n",
    "curl -s http://localhost:{port}/v1/chat/completions \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{{\n",
    "    \"model\": \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    \"messages\": [\n",
    "      {{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What’s in this image?\"\n",
    "          }},\n",
    "          {{\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {{\n",
    "              \"url\": \"https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true\"\n",
    "            }}\n",
    "          }}\n",
    "        ]\n",
    "      }}\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "  }}'\n",
    "\"\"\"\n",
    "\n",
    "response = subprocess.check_output(curl_command, shell=True).decode()\n",
    "print_highlight(response)\n",
    "\n",
    "\n",
    "response = subprocess.check_output(curl_command, shell=True).decode()\n",
    "print_highlight(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T22:01:10.341952Z",
     "iopub.status.busy": "2025-10-13T22:01:10.341767Z",
     "iopub.status.idle": "2025-10-13T22:01:11.564040Z",
     "shell.execute_reply": "2025-10-13T22:01:11.563444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{\"id\":\"56f2b7607e0946d5b15ef3a7892ffbf8\",\"object\":\"chat.completion\",\"created\":1760392871,\"model\":\"Qwen/Qwen2.5-VL-7B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"The image shows a man standing on the back of a yellow taxi, using an iron to press or smooth out a pair of pants draped over an ironing board. The taxi is parked on a city street, and there are other taxis and buildings in the background. The man appears to be performing an unusual task, as ironing is typically done indoors.\",\"reasoning_content\":null,\"tool_calls\":null},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":151645}],\"usage\":{\"prompt_tokens\":307,\"total_tokens\":379,\"completion_tokens\":72,\"prompt_tokens_details\":null,\"reasoning_tokens\":0},\"metadata\":{\"weight_version\":\"default\"}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"http://localhost:{port}/v1/chat/completions\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print_highlight(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T22:01:11.566121Z",
     "iopub.status.busy": "2025-10-13T22:01:11.565969Z",
     "iopub.status.idle": "2025-10-13T22:01:12.689944Z",
     "shell.execute_reply": "2025-10-13T22:01:12.689388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>The image shows a man standing on the back of a yellow taxi, using an iron to press or smooth out a pair of pants draped over an ironing board. The taxi is parked on a city street, and there are other taxis and buildings in the background. The man appears to be performing an unusual and unconventional task, as ironing is typically done indoors.</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=f\"http://localhost:{port}/v1\", api_key=\"None\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What is in this image?\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print_highlight(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple-Image Inputs\n",
    "\n",
    "The server also supports multiple images and interleaved text and images if the model supports it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T22:01:12.691562Z",
     "iopub.status.busy": "2025-10-13T22:01:12.691410Z",
     "iopub.status.idle": "2025-10-13T22:01:17.478633Z",
     "shell.execute_reply": "2025-10-13T22:01:17.477884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-13 22:01:15] Error in request: An exception occurred while loading multimodal data: Error while loading data ImageData(url='https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true', detail='auto'): HTTPSConnectionPool(host='github.com', port=443): Read timed out. (read timeout=3)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 468, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 463, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1303, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1159, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 644, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 802, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 716, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 470, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='github.com', port=443): Read timed out. (read timeout=3)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/public_sglang_ci/runner-l1b-gpu-0/_work/sglang/sglang/python/sglang/srt/multimodal/processors/base_processor.py\", line 314, in _load_single_item\n",
      "    img, _ = load_image(data)\n",
      "  File \"/public_sglang_ci/runner-l1b-gpu-0/_work/sglang/sglang/python/sglang/srt/utils/common.py\", line 811, in load_image\n",
      "    response = requests.get(image_file, stream=True, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 690, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='github.com', port=443): Read timed out. (read timeout=3)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/public_sglang_ci/runner-l1b-gpu-0/_work/sglang/sglang/python/sglang/srt/multimodal/processors/base_processor.py\", line 456, in load_mm_data\n",
      "    result = next(futures_iter).result()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/public_sglang_ci/runner-l1b-gpu-0/_work/sglang/sglang/python/sglang/srt/multimodal/processors/base_processor.py\", line 322, in _load_single_item\n",
      "    raise RuntimeError(f\"Error while loading data {data}: {e}\")\n",
      "RuntimeError: Error while loading data ImageData(url='https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true', detail='auto'): HTTPSConnectionPool(host='github.com', port=443): Read timed out. (read timeout=3)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/public_sglang_ci/runner-l1b-gpu-0/_work/sglang/sglang/python/sglang/srt/entrypoints/openai/serving_base.py\", line 59, in handle_request\n",
      "    return await self._handle_non_streaming_request(\n",
      "  File \"/public_sglang_ci/runner-l1b-gpu-0/_work/sglang/sglang/python/sglang/srt/entrypoints/openai/serving_chat.py\", line 660, in _handle_non_streaming_request\n",
      "    ret = await self.tokenizer_manager.generate_request(\n",
      "  File \"/public_sglang_ci/runner-l1b-gpu-0/_work/sglang/sglang/python/sglang/srt/managers/tokenizer_manager.py\", line 406, in generate_request\n",
      "    tokenized_obj = await self._tokenize_one_request(obj)\n",
      "  File \"/public_sglang_ci/runner-l1b-gpu-0/_work/sglang/sglang/python/sglang/srt/managers/tokenizer_manager.py\", line 594, in _tokenize_one_request\n",
      "    mm_inputs: Dict = await self.mm_processor.process_mm_data_async(\n",
      "  File \"/public_sglang_ci/runner-l1b-gpu-0/_work/sglang/sglang/python/sglang/srt/multimodal/processors/qwen_vl.py\", line 251, in process_mm_data_async\n",
      "    base_output = self.load_mm_data(\n",
      "  File \"/public_sglang_ci/runner-l1b-gpu-0/_work/sglang/sglang/python/sglang/srt/multimodal/processors/base_processor.py\", line 497, in load_mm_data\n",
      "    raise RuntimeError(\n",
      "RuntimeError: An exception occurred while loading multimodal data: Error while loading data ImageData(url='https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true', detail='auto'): HTTPSConnectionPool(host='github.com', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>The first image shows a man ironing clothes on the back of a taxi in a busy urban street. The second image is a stylized logo featuring the letters \"SGL\" with a book and a computer icon incorporated into the design.</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=f\"http://localhost:{port}/v1\", api_key=\"None\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"I have two very different images. They are not related at all. \"\n",
    "                    \"Please describe the first image in one sentence, and then describe the second image in another sentence.\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print_highlight(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T22:01:17.480549Z",
     "iopub.status.busy": "2025-10-13T22:01:17.480277Z",
     "iopub.status.idle": "2025-10-13T22:01:17.535977Z",
     "shell.execute_reply": "2025-10-13T22:01:17.535402Z"
    }
   },
   "outputs": [],
   "source": [
    "terminate_process(vision_process)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
