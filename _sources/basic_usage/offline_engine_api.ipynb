{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Engine API\n",
    "\n",
    "SGLang provides a direct inference engine without the need for an HTTP server, especially for use cases where additional HTTP server adds unnecessary complexity or overhead. Here are two general use cases:\n",
    "\n",
    "- Offline Batch Inference\n",
    "- Custom Server on Top of the Engine\n",
    "\n",
    "This document focuses on the offline batch inference, demonstrating four different inference modes:\n",
    "\n",
    "- Non-streaming synchronous generation\n",
    "- Streaming synchronous generation\n",
    "- Non-streaming asynchronous generation\n",
    "- Streaming asynchronous generation\n",
    "\n",
    "Additionally, you can easily build a custom server on top of the SGLang offline engine. A detailed example working in a python script can be found in [custom_server](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/custom_server.py).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nest Asyncio\n",
    "Note that if you want to use **Offline Engine** in ipython or some other nested loop code, you need to add the following code:\n",
    "```python\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "\n",
    "The engine supports [vlm inference](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/offline_batch_inference_vlm.py) as well as [extracting hidden states](https://github.com/sgl-project/sglang/blob/main/examples/runtime/hidden_states). \n",
    "\n",
    "Please see [the examples](https://github.com/sgl-project/sglang/tree/main/examples/runtime/engine) for further use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Batch Inference\n",
    "\n",
    "SGLang offline engine supports batch inference with efficient scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T05:48:19.340747Z",
     "iopub.status.busy": "2025-09-19T05:48:19.340619Z",
     "iopub.status.idle": "2025-09-19T05:48:41.177505Z",
     "shell.execute_reply": "2025-09-19T05:48:41.176862Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0919 05:48:26.670000 3162537 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "W0919 05:48:26.670000 3162537 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All deep_gemm operations loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.configuration_utils:`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0919 05:48:35.092000 3163064 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "W0919 05:48:35.092000 3163064 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n",
      "W0919 05:48:35.119000 3163065 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "W0919 05:48:35.119000 3163065 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "[2025-09-19 05:48:35] `torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All deep_gemm operations loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.87it/s]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.87it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]\r",
      "Capturing batches (bs=4 avail_mem=77.03 GB):   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=4 avail_mem=77.03 GB):  33%|███▎      | 1/3 [00:00<00:00,  4.52it/s]\r",
      "Capturing batches (bs=2 avail_mem=76.97 GB):  33%|███▎      | 1/3 [00:00<00:00,  4.52it/s]\r",
      "Capturing batches (bs=1 avail_mem=76.96 GB):  33%|███▎      | 1/3 [00:00<00:00,  4.52it/s]\r",
      "Capturing batches (bs=1 avail_mem=76.96 GB): 100%|██████████| 3/3 [00:00<00:00, 10.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# launch the offline engine\n",
    "import asyncio\n",
    "\n",
    "import sglang as sgl\n",
    "import sglang.test.doc_patch\n",
    "from sglang.utils import async_stream_and_merge, stream_and_merge\n",
    "\n",
    "llm = sgl.Engine(model_path=\"qwen/qwen2.5-0.5b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Synchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T05:48:41.179588Z",
     "iopub.status.busy": "2025-09-19T05:48:41.179168Z",
     "iopub.status.idle": "2025-09-19T05:48:42.067280Z",
     "shell.execute_reply": "2025-09-19T05:48:42.066510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: Hello, my name is\n",
      "Generated text:  Tom and I am 17 years old. I'm from Poland. I'm the president of the English club at school. I'm a little bit shy, but I want to be a leader. I like to talk about what I think. I like to share my ideas. I think I should learn more about what I want to be when I grow up. I want to go to a famous university to study English and go to Paris. I want to be a great language teacher. I have a strong interest in all kinds of things and I like to share my ideas. I will make a presentation to the whole school when I\n",
      "===============================\n",
      "Prompt: The president of the United States is\n",
      "Generated text:  50 years younger than his first president. If his first president was 70 years old when he became the president, and the two presidents worked together from 1901 to 1929, what is the age of both presidents together? To determine the total age of both presidents from 1901 to 1929, we need to follow these steps:\n",
      "\n",
      "1. Determine the age of the president from 1901 to 1929.\n",
      "2. Add the age of the president from 1901 to 1929 to the age of the\n",
      "===============================\n",
      "Prompt: The capital of France is\n",
      "Generated text: :\n",
      "\n",
      "A) Paris\n",
      "B) Lyon\n",
      "C) Bordeaux\n",
      "D) Marseille\n",
      "E) Nice\n",
      "\n",
      "To determine the capital of France, let's review the capital cities of France and compare them to the given options. The capital of France is Lyon, which is located in the central part of the country. Let's check the options:\n",
      "\n",
      "A) Paris - The capital of France is Paris, located in the south of the country.\n",
      "B) Lyon - This is the capital of Lyon, located in the south of France.\n",
      "C) Bordeaux - This is not a capital city of France.\n",
      "D) Marseille - This is the capital of Marseille\n",
      "===============================\n",
      "Prompt: The future of AI is\n",
      "Generated text:  here. The faster that you integrate AI, the more opportunities we have to shape the world, from the healthcare industry to the transportation sector, to the financial sector and beyond. The term Artificial Intelligence (AI) is a collection of technologies that enable machines to think like humans and learn from their mistakes. If you consider the term AI to be the future of technology, then it is safe to say that the future is here.\n",
      "This article discusses the various types of AI algorithms and how these algorithms are utilized by major AI companies.\n",
      "Anomaly Detection\n",
      "Anomaly Detection is one of the key uses of AI algorithms, and it is a type of\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(f\"Prompt: {prompt}\\nGenerated text: {output['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Synchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T05:48:42.068841Z",
     "iopub.status.busy": "2025-09-19T05:48:42.068659Z",
     "iopub.status.idle": "2025-09-19T05:48:42.815476Z",
     "shell.execute_reply": "2025-09-19T05:48:42.814806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing synchronous streaming generation with overlap removal ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  [Name], and I'm a [job title] at [company name]. I'm excited to meet you and learn more about you. What can you tell me about yourself? I'm a [insert a brief description of your job or experience]. I'm always looking for new challenges and opportunities to grow and learn. What do you do for a living? I'm always looking for new ways to improve myself and make a positive impact on the world. What do you enjoy doing? I enjoy learning new things, exploring new cultures, and trying new foods. What's your favorite hobby? I love to read and travel. What's your\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  Paris. \n",
      "\n",
      "The statement is concise and accurately describes the capital city of France. It provides the name of the city and its capital, which are both key facts about the city. The statement is clear and easy to understand, making it suitable for a brief introduction to the topic. It also includes the French name for the capital, which is Paris, which is a common and widely known fact about the city. Overall, the statement is a good representation of the factual information about the capital city of France. \n",
      "\n",
      "The statement is appropriate for use in a variety of contexts, such as a news article, a travel guide, or a brief introduction\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  likely to be characterized by a number of trends that are expected to shape the technology's direction and impact on society. Here are some of the most likely trends that are expected to shape the future of AI:\n",
      "\n",
      "1. Increased focus on ethical considerations: As AI becomes more integrated into our daily lives, there will be a growing emphasis on ethical considerations. This will include issues such as bias, transparency, accountability, and the impact of AI on society as a whole.\n",
      "\n",
      "2. Greater integration with human decision-making: AI is likely to become more integrated with human decision-making in the future, as AI systems are expected to be able to make decisions based\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "print(\"\\n=== Testing synchronous streaming generation with overlap removal ===\\n\")\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    merged_output = stream_and_merge(llm, prompt, sampling_params)\n",
    "    print(\"Generated text:\", merged_output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Asynchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T05:48:42.817006Z",
     "iopub.status.busy": "2025-09-19T05:48:42.816848Z",
     "iopub.status.idle": "2025-09-19T05:48:43.053598Z",
     "shell.execute_reply": "2025-09-19T05:48:43.052933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing asynchronous batch generation ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text:  [Name], and I'm a [Age] year old, [Gender] who enjoys [Your field of expertise or hobby]. I'm always looking for ways to [something specific you're passionate about or a challenge you're trying to overcome], and I love to [something you enjoy doing]. I've always been [something that's been a big part of my identity, like your interests, hobbies, or other traits]. What's your name, and how do you go about interacting with others? Hi there! I'm [Name], a [Gender] who enjoys [your field of expertise or hobby]. I'm always looking for ways\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text:  Paris.\n",
      "\n",
      "Paris, the city of love and art, is known as the \"City of Love\" and is the largest city in France. The city is home to many famous landmarks such as the Eiffel Tower, Notre Dame Cathedral, the Louvre Museum, and the Palace of Versailles. Paris is also famous for its architecture, particularly its architecture of the Renaissance and Baroque periods, which are reflected in its famous landmarks such as the Notre Dame Cathedral. It is also home to a diverse population of cultures and is a major commercial and cultural center in the country. Paris is one of the most visited cities in the world and is\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text:  likely to be characterized by a number of technological and societal advancements that will shape the way we live, work, and interact with technology. Here are some possible future trends in AI:\n",
      "\n",
      "1. Increased integration with other technologies: As AI becomes more integrated with other technologies, such as the Internet of Things (IoT), sensors, and cloud computing, it will become even more powerful and capable. This integration will allow AI to learn and adapt to new situations and environments, and will enable it to provide more efficient and effective solutions to complex problems.\n",
      "\n",
      "2. Improved ethical considerations: As AI becomes more integrated into our daily lives, there will be greater\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing asynchronous batch generation ===\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    outputs = await llm.async_generate(prompts, sampling_params)\n",
    "\n",
    "    for prompt, output in zip(prompts, outputs):\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(f\"Generated text: {output['text']}\")\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Asynchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T05:48:43.055129Z",
     "iopub.status.busy": "2025-09-19T05:48:43.054965Z",
     "iopub.status.idle": "2025-09-19T05:48:43.693113Z",
     "shell.execute_reply": "2025-09-19T05:48:43.692542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing asynchronous streaming generation (no repeats) ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ["
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ["
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occup"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ation"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " or"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Skill"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ["
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Years"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Experience"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hard"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " organized"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " responsible"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " individual"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " who"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " always"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ready"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " take"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " new"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " challenges"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " team"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " player"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " always"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " willing"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " help"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " others"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " work"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " towards"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " common"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " goal"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " confident"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " abilities"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " believe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " that"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hard"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " work"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dedication"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " can"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " achieve"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anything"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mind"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " passionate"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " helping"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " others"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " strive"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " good"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " example"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " others"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " follow"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " positive"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " encouraging"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " person"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " believe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " treating"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " people"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " respect"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kindness"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " am"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " always"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " learning"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " growing"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " known"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " largest"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " an"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " estimated"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " population"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " over"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " million"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " people"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " famous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " architecture"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " museums"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " food"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " famous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iff"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tower"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " located"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " one"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " most"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " recognizable"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " landmarks"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " world"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addition"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iconic"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " landmarks"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " home"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " numerous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " museums"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " theaters"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shopping"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " malls"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " also"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " known"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " music"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " scene"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " many"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " famous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " musicians"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bands"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " performing"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bustling"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " diverse"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " population"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rich"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cultural"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " heritage"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " French"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " government"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " has"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " worked"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " preserve"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " full"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " possibilities"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " will"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " interesting"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " see"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " how"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " these"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trends"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " develop"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " are"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " some"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " most"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " likely"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " future"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trends"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Increase"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " use"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " healthcare"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " With"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " doctors"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " will"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " able"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " better"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " diagnose"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " diseases"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " treat"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " patients"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " provide"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " personalized"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " treatment"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " plans"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " algorithms"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " will"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " also"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " used"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " analyze"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " medical"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " images"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " which"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " will"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " help"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " early"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " detection"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " diseases"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " improve"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " diagnoses"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Automation"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " customer"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " service"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-powered"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chat"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bots"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " will"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " able"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " handle"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " customer"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " service"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tasks"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " such"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " answering"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " questions"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " providing"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " recommendations"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " resolving"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " issues"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " will"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " make"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " customer"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " service"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " more"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " efficient"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " faster"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing asynchronous streaming generation (no repeats) ===\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    for prompt in prompts:\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(\"Generated text: \", end=\"\", flush=True)\n",
    "\n",
    "        # Replace direct calls to async_generate with our custom overlap-aware version\n",
    "        async for cleaned_chunk in async_stream_and_merge(llm, prompt, sampling_params):\n",
    "            print(cleaned_chunk, end=\"\", flush=True)\n",
    "\n",
    "        print()  # New line after each prompt\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T05:48:43.694903Z",
     "iopub.status.busy": "2025-09-19T05:48:43.694740Z",
     "iopub.status.idle": "2025-09-19T05:48:43.713424Z",
     "shell.execute_reply": "2025-09-19T05:48:43.712849Z"
    }
   },
   "outputs": [],
   "source": [
    "llm.shutdown()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
