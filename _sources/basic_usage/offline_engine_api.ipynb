{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Engine API\n",
    "\n",
    "SGLang provides a direct inference engine without the need for an HTTP server, especially for use cases where additional HTTP server adds unnecessary complexity or overhead. Here are two general use cases:\n",
    "\n",
    "- Offline Batch Inference\n",
    "- Custom Server on Top of the Engine\n",
    "\n",
    "This document focuses on the offline batch inference, demonstrating four different inference modes:\n",
    "\n",
    "- Non-streaming synchronous generation\n",
    "- Streaming synchronous generation\n",
    "- Non-streaming asynchronous generation\n",
    "- Streaming asynchronous generation\n",
    "\n",
    "Additionally, you can easily build a custom server on top of the SGLang offline engine. A detailed example working in a python script can be found in [custom_server](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/custom_server.py).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nest Asyncio\n",
    "Note that if you want to use **Offline Engine** in ipython or some other nested loop code, you need to add the following code:\n",
    "```python\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "\n",
    "The engine supports [vlm inference](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/offline_batch_inference_vlm.py) as well as [extracting hidden states](https://github.com/sgl-project/sglang/blob/main/examples/runtime/hidden_states). \n",
    "\n",
    "Please see [the examples](https://github.com/sgl-project/sglang/tree/main/examples/runtime/engine) for further use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Batch Inference\n",
    "\n",
    "SGLang offline engine supports batch inference with efficient scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T03:42:17.470909Z",
     "iopub.status.busy": "2025-10-07T03:42:17.470787Z",
     "iopub.status.idle": "2025-10-07T03:42:41.663137Z",
     "shell.execute_reply": "2025-10-07T03:42:41.662444Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.configuration_utils:`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "[2025-10-07 03:42:34] `torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.12it/s]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.11it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]\r",
      "Capturing batches (bs=128 avail_mem=76.92 GB):   0%|          | 0/20 [00:00<?, ?it/s]\r",
      "Capturing batches (bs=128 avail_mem=76.92 GB):   5%|▌         | 1/20 [00:00<00:03,  5.45it/s]\r",
      "Capturing batches (bs=120 avail_mem=76.81 GB):   5%|▌         | 1/20 [00:00<00:03,  5.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=112 avail_mem=76.81 GB):   5%|▌         | 1/20 [00:00<00:03,  5.45it/s]\r",
      "Capturing batches (bs=104 avail_mem=76.80 GB):   5%|▌         | 1/20 [00:00<00:03,  5.45it/s]\r",
      "Capturing batches (bs=104 avail_mem=76.80 GB):  20%|██        | 4/20 [00:00<00:01, 13.90it/s]\r",
      "Capturing batches (bs=96 avail_mem=76.80 GB):  20%|██        | 4/20 [00:00<00:01, 13.90it/s] \r",
      "Capturing batches (bs=88 avail_mem=76.79 GB):  20%|██        | 4/20 [00:00<00:01, 13.90it/s]\r",
      "Capturing batches (bs=80 avail_mem=76.79 GB):  20%|██        | 4/20 [00:00<00:01, 13.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=80 avail_mem=76.79 GB):  35%|███▌      | 7/20 [00:00<00:00, 17.24it/s]\r",
      "Capturing batches (bs=72 avail_mem=76.79 GB):  35%|███▌      | 7/20 [00:00<00:00, 17.24it/s]\r",
      "Capturing batches (bs=64 avail_mem=76.78 GB):  35%|███▌      | 7/20 [00:00<00:00, 17.24it/s]\r",
      "Capturing batches (bs=56 avail_mem=76.78 GB):  35%|███▌      | 7/20 [00:00<00:00, 17.24it/s]\r",
      "Capturing batches (bs=56 avail_mem=76.78 GB):  50%|█████     | 10/20 [00:00<00:00, 19.28it/s]\r",
      "Capturing batches (bs=48 avail_mem=76.77 GB):  50%|█████     | 10/20 [00:00<00:00, 19.28it/s]\r",
      "Capturing batches (bs=40 avail_mem=76.77 GB):  50%|█████     | 10/20 [00:00<00:00, 19.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=32 avail_mem=76.76 GB):  50%|█████     | 10/20 [00:00<00:00, 19.28it/s]\r",
      "Capturing batches (bs=32 avail_mem=76.76 GB):  65%|██████▌   | 13/20 [00:00<00:00, 20.72it/s]\r",
      "Capturing batches (bs=24 avail_mem=76.76 GB):  65%|██████▌   | 13/20 [00:00<00:00, 20.72it/s]\r",
      "Capturing batches (bs=16 avail_mem=76.75 GB):  65%|██████▌   | 13/20 [00:00<00:00, 20.72it/s]\r",
      "Capturing batches (bs=12 avail_mem=76.75 GB):  65%|██████▌   | 13/20 [00:00<00:00, 20.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=12 avail_mem=76.75 GB):  80%|████████  | 16/20 [00:00<00:00, 20.03it/s]\r",
      "Capturing batches (bs=8 avail_mem=76.74 GB):  80%|████████  | 16/20 [00:00<00:00, 20.03it/s] \r",
      "Capturing batches (bs=4 avail_mem=76.73 GB):  80%|████████  | 16/20 [00:00<00:00, 20.03it/s]\r",
      "Capturing batches (bs=2 avail_mem=76.73 GB):  80%|████████  | 16/20 [00:00<00:00, 20.03it/s]\r",
      "Capturing batches (bs=1 avail_mem=76.73 GB):  80%|████████  | 16/20 [00:00<00:00, 20.03it/s]\r",
      "Capturing batches (bs=1 avail_mem=76.73 GB): 100%|██████████| 20/20 [00:01<00:00, 23.37it/s]\r",
      "Capturing batches (bs=1 avail_mem=76.73 GB): 100%|██████████| 20/20 [00:01<00:00, 19.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# launch the offline engine\n",
    "import asyncio\n",
    "\n",
    "import sglang as sgl\n",
    "import sglang.test.doc_patch\n",
    "from sglang.utils import async_stream_and_merge, stream_and_merge\n",
    "\n",
    "llm = sgl.Engine(model_path=\"qwen/qwen2.5-0.5b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Synchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T03:42:41.665623Z",
     "iopub.status.busy": "2025-10-07T03:42:41.665176Z",
     "iopub.status.idle": "2025-10-07T03:42:42.510207Z",
     "shell.execute_reply": "2025-10-07T03:42:42.509674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: Hello, my name is\n",
      "Generated text:  Emily, and I'm a part-time student in a French class at my local community college. I'm trying to learn how to improve my French vocabulary. I've read some of the articles online and found that many of the articles also contain grammar. But I'm having trouble grasping the grammar and I'm not sure how to incorporate it into my own vocabulary.\n",
      "\n",
      "Could you provide me with some tips to help me learn vocabulary and improve my French grammar? I would like to start using these tips to improve my vocabulary while still focusing on the grammar.\n",
      "Certainly! Learning vocabulary and grammar is a great way to improve your French. Here are some\n",
      "===============================\n",
      "Prompt: The president of the United States is\n",
      "Generated text:  seeking to please his constituents. He is proposing a new tax on corporations, and the proposal is not well received by some of his constituents. This suggests that the president may be:\n",
      "\n",
      "a) Influential\n",
      "b) Lazy\n",
      "c) Lazy and manipulative\n",
      "d) Diligent and principled\n",
      "e) Cynical\n",
      "\n",
      "To solve this problem, we need to understand the relationship between the president's proposals and the feedback from his constituents. The president's proposal is seeking to increase corporate taxes, which is a significant issue for many constituents. If the proposal is not well received, it suggests that the president may be:\n",
      "\n",
      "c)\n",
      "===============================\n",
      "Prompt: The capital of France is\n",
      "Generated text:  ______.\n",
      "\n",
      "A: Paris  \n",
      "B: Lyon  \n",
      "C: Brussels  \n",
      "D: Strasbourg To determine the capital of France, we need to consider the geographical and historical context of France. Paris is indeed the capital of France, and it is known for its rich culture, history, and cityscape.\n",
      "\n",
      "Let's analyze the options given:\n",
      "\n",
      "A: Paris - This is correct.\n",
      "B: Lyon - Lyon is the capital of France but it is not a major city and is less famous than Paris.\n",
      "C: Brussels - Brussels is also the capital of France but it is not a major city and is not as famous as Paris.\n",
      "D: Str\n",
      "===============================\n",
      "Prompt: The future of AI is\n",
      "Generated text:  in the hands of leaders, not AI itself. This report offers a unique insight into the potential of the future of AI, and what leaders can do to prepare their organizations for the changing landscape.\n",
      "The future of AI is in the hands of leaders, not AI itself. This report offers a unique insight into the potential of the future of AI, and what leaders can do to prepare their organizations for the changing landscape.\n",
      "The Future of AI in 2023: How AI is Expected to Change the World and How Leaders Can Prepare for It\n",
      "By Bjarne Heinemann\n",
      "Special thanks to the organizers of the UNISR World\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(f\"Prompt: {prompt}\\nGenerated text: {output['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Synchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T03:42:42.511801Z",
     "iopub.status.busy": "2025-10-07T03:42:42.511641Z",
     "iopub.status.idle": "2025-10-07T03:42:43.239539Z",
     "shell.execute_reply": "2025-10-07T03:42:43.239014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing synchronous streaming generation with overlap removal ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  [Name] and I'm a [occupation] with [number of years] years of experience in [field]. I'm a [character trait] and I'm always looking for ways to [describe a new challenge or opportunity]. I'm a [character trait] and I'm always looking for ways to [describe a new challenge or opportunity]. I'm a [character trait] and I'm always looking for ways to [describe a new challenge or opportunity]. I'm a [character trait] and I'm always looking for ways to [describe a new challenge or opportunity]. I'm a [character trait] and I'm always looking for\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  Paris, also known as the City of Light. It is a historic city with a rich history and a vibrant culture, known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. Paris is also a major center for art, fashion, and cuisine, and is home to many world-renowned museums, theaters, and restaurants. The city is also known for its annual festivals and events, including the Eiffel Tower Festival and the Parisian Carnival. Paris is a city of contrasts, with its modern architecture and cultural attractions blending seamlessly with its historic landmarks. Its status as the capital\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  likely to be characterized by a number of trends that are expected to shape the technology's direction. Here are some of the most likely trends that could emerge in the coming years:\n",
      "\n",
      "1. Increased focus on ethical considerations: As AI becomes more integrated into our daily lives, there will be a growing emphasis on ethical considerations. This could include issues such as bias, privacy, and transparency. As a result, there will be a greater focus on developing AI that is designed to be fair, transparent, and accountable.\n",
      "\n",
      "2. Integration with other technologies: AI is likely to become more integrated with other technologies, such as machine learning, natural language processing,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "print(\"\\n=== Testing synchronous streaming generation with overlap removal ===\\n\")\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    merged_output = stream_and_merge(llm, prompt, sampling_params)\n",
    "    print(\"Generated text:\", merged_output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Asynchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T03:42:43.241238Z",
     "iopub.status.busy": "2025-10-07T03:42:43.241087Z",
     "iopub.status.idle": "2025-10-07T03:42:43.472929Z",
     "shell.execute_reply": "2025-10-07T03:42:43.472416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing asynchronous batch generation ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text:  [Name]. I am an AI language model designed to assist you with your queries and tasks. I'm here to help you with any questions you may have, whether you're looking for information, support, or just some distraction-free time. How can I assist you today? Let me know if there's anything I can do for you. I'm always here to help and provide you with the best possible service. Is there anything specific you would like to know or discuss? I'm here to help you learn and improve your language skills in the best way possible. I'm here to help you with any questions or concerns you may have.\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text:  Paris.\n",
      "\n",
      "Paris is the largest city in France and the second-largest city in Europe. It is the capital of the Department of Paris, and the capital of the French Department of the Centre-Val de Loire. It is also the seat of the President of the French Republic and of the Conseil d’État. The city is renowned for its fashion, art, gastronomy and nightlife. It is also the birthplace of Louis XIV, the king of France. The city is also a UNESCO World Heritage site. According to the 2021 census, Paris has a population of 2,284,70\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text:  full of possibilities and challenges, and we can expect some exciting developments in the coming years. Here are some of the most likely trends we can expect:\n",
      "\n",
      "1. Improved Natural Language Processing: With the help of deep learning algorithms, we will see an increase in the ability of AI to understand and interpret natural language. This will allow for more accurate and natural conversations between humans and AI, and will also enable the development of chatbots and virtual assistants that can interact with users in a more conversational way.\n",
      "\n",
      "2. Enhanced Image and Speech Recognition: AI will also see significant improvements in image and speech recognition. This will enable computers to accurately interpret and\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing asynchronous batch generation ===\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    outputs = await llm.async_generate(prompts, sampling_params)\n",
    "\n",
    "    for prompt, output in zip(prompts, outputs):\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(f\"Generated text: {output['text']}\")\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Asynchronous Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T03:42:43.474505Z",
     "iopub.status.busy": "2025-10-07T03:42:43.474348Z",
     "iopub.status.idle": "2025-10-07T03:42:44.116892Z",
     "shell.execute_reply": "2025-10-07T03:42:44.116249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing asynchronous streaming generation (no repeats) ===\n",
      "\n",
      "Prompt: Write a short, neutral self-introduction for a fictional character. Hello, my name is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " John"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " an"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " language"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " so"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " job"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " provide"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " helpful"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " informative"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " responses"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " your"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " queries"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " can"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " answer"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " questions"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " history"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " science"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " literature"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " technology"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " many"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " other"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " topics"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " also"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " skilled"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " logical"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reasoning"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " can"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " assist"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " complex"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tasks"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " problem"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-solving"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " enjoy"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " helping"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " others"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " learning"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " from"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " experiences"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " others"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " excited"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " learn and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " share"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " knowledge"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " virtual"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " world"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Let"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " me"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " know"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " if"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " have"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " any"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " questions"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " or"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " need"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " any"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " assistance"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " John"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tone"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " this"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " self"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-int"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roduction"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tone"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " this"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " self"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-int"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roduction"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " neutral"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " friendly"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: Provide a concise factual statement about France’s capital city. The capital of France is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " are"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " an"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " assistant"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " that"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " helps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " understand"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reasons"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " behind"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " decisions."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Don't"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " write copies"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of arguments"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", reviews"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " orinions"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Use"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " your"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " own"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " words"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Français"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " capital"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ll"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " provide"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " concise"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " factual"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " statement"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " capital"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " capital"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vibrant"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " capital"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " renowned"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " its"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " architecture"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " culture"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lively"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lifestyle"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Known"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Light"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bustling"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " met"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ropolis"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " population"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " over"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " million"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " people"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " making"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " most"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " populous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " European"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Union"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Famous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " landmarks"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " include"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iff"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tower"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: Explain possible future trends in artificial intelligence. The future of AI is\n",
      "Generated text: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " full"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " exciting"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " possibilities"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " possibilities"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " innovation"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " but"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " important"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " remember"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " that"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rapidly"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " evolving"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " field"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " with"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " many"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " unknown"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " challenges"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " potential"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " future"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trend"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " development"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " that"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " can"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " operate"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wider"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " variety"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " environments"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " situations"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " including"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " internet"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " things"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Io"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "),"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " space"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " exploration"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " autonomous"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vehicles"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " would"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " allow"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " more"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adaptive"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " intelligent"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " better"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " able"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adapt"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " different"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " types"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " work"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tasks"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " more"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " effective"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " at"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " handling"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " complex"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dynamic"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " environments"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trend"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " could"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " development"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " that"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " can"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " generate"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " human"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-like"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " thought"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " creativity"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " areas"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " such"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " language"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " translation"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " creative"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " writing"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a short, neutral self-introduction for a fictional character. Hello, my name is\",\n",
    "    \"Provide a concise factual statement about France’s capital city. The capital of France is\",\n",
    "    \"Explain possible future trends in artificial intelligence. The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing asynchronous streaming generation (no repeats) ===\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    for prompt in prompts:\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(\"Generated text: \", end=\"\", flush=True)\n",
    "\n",
    "        # Replace direct calls to async_generate with our custom overlap-aware version\n",
    "        async for cleaned_chunk in async_stream_and_merge(llm, prompt, sampling_params):\n",
    "            print(cleaned_chunk, end=\"\", flush=True)\n",
    "\n",
    "        print()  # New line after each prompt\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T03:42:44.118498Z",
     "iopub.status.busy": "2025-10-07T03:42:44.118341Z",
     "iopub.status.idle": "2025-10-07T03:42:44.154351Z",
     "shell.execute_reply": "2025-10-07T03:42:44.147877Z"
    }
   },
   "outputs": [],
   "source": [
    "llm.shutdown()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
