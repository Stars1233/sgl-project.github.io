{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Launch A Server and Send Requests\n",
    "\n",
    "This section provides a quick start guide to using SGLang after installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a server\n",
    "\n",
    "This code block is equivalent to executing \n",
    "\n",
    "```bash\n",
    "python -m sglang.launch_server --model-path meta-llama/Meta-Llama-3.1-8B-Instruct \\\n",
    "--port 30000 --host 0.0.0.0 --log-level warning\n",
    "```\n",
    "\n",
    "in your command line and wait for the server to be ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T23:25:12.782403Z",
     "iopub.status.busy": "2024-10-27T23:25:12.781995Z",
     "iopub.status.idle": "2024-10-27T23:25:50.292760Z",
     "shell.execute_reply": "2024-10-27T23:25:50.291723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is ready. Proceeding with the next steps.\n"
     ]
    }
   ],
   "source": [
    "from sglang.utils import execute_shell_command, wait_for_server, terminate_process\n",
    "\n",
    "\n",
    "server_process = execute_shell_command(\n",
    "    \"\"\"\n",
    "python -m sglang.launch_server --model-path meta-llama/Meta-Llama-3.1-8B-Instruct \\\n",
    "--port 30000 --host 0.0.0.0 --log-level warning\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "wait_for_server(\"http://localhost:30000\")\n",
    "print(\"Server is ready. Proceeding with the next steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a Request\n",
    "\n",
    "Once the server is running, you can send test requests using curl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T23:25:50.328286Z",
     "iopub.status.busy": "2024-10-27T23:25:50.327797Z",
     "iopub.status.idle": "2024-10-27T23:25:53.479602Z",
     "shell.execute_reply": "2024-10-27T23:25:53.478670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"6ae7fabfd4c54054a8017e2aa7c6bc5a\",\"object\":\"chat.completion\",\"created\":1730071553,\"model\":\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"LLM stands for Large Language Model. It's a type of artificial intelligence (AI) designed to process and generate human-like language. LLMs are trained on vast amounts of text data, which allows them to learn patterns, relationships, and structures of language.\\n\\nLarge Language Models are typically characterized by their ability to:\\n\\n1. **Understand natural language**: LLMs can comprehend and interpret human language, including nuances, idioms, and context.\\n2. **Generate text**: LLMs can create coherent and context-specific text, such as responses to questions, summaries of articles, or even entire stories.\\n3. **Answer questions**: LLMs can provide accurate and informative answers to a wide range of questions, from simple facts to complex topics.\\n4. **Translate languages**: LLMs can translate text from one language to another, often with high accuracy.\\n5. **Summarize content**: LLMs can condense long pieces of text into shorter, more digestible summaries.\\n\\nThe core of an LLM is its **neural network architecture**, which is composed of multiple layers of interconnected nodes (neurons) that process and transform the input data. This architecture allows LLMs to learn complex patterns and relationships in language, enabling them to generate human-like text.\\n\\nSome popular examples of LLMs include:\\n\\n* **Chatbots**: Virtual assistants that use LLMs to understand and respond to user queries.\\n* **Language translation tools**: Services that use LLMs to translate text from one language to another.\\n* **Content generation platforms**: Tools that use LLMs to generate text, such as articles, social media posts, or even entire books.\\n* **Virtual assistants**: AI-powered assistants, like Siri, Alexa, or Google Assistant, that use LLMs to understand and respond to user queries.\\n\\nOverall, LLMs have revolutionized the field of natural language processing (NLP) and have numerous applications in various industries, from customer service to content creation.\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":128009}],\"usage\":{\"prompt_tokens\":47,\"total_tokens\":450,\"completion_tokens\":403,\"prompt_tokens_details\":null}}"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:30000/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer None\" \\\n",
    "  -d '{\"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is a LLM?\"}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI Compatible API\n",
    "\n",
    "SGLang supports OpenAI-compatible APIs. Here are Python examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T23:25:53.481936Z",
     "iopub.status.busy": "2024-10-27T23:25:53.481707Z",
     "iopub.status.idle": "2024-10-27T23:25:54.273214Z",
     "shell.execute_reply": "2024-10-27T23:25:54.272434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='da93c64364af475cbdd2cb19155fd68d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here are 3 countries and their capitals:\\n\\n1. **Country:** Japan\\n**Capital:** Tokyo\\n\\n2. **Country:** Australia\\n**Capital:** Canberra\\n\\n3. **Country:** Brazil\\n**Capital:** Bras√≠lia', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), matched_stop=128009)], created=1730071554, model='meta-llama/Meta-Llama-3.1-8B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=46, prompt_tokens=49, total_tokens=95, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Always assign an api_key, even if not specified during server initialization.\n",
    "# Setting an API key during server initialization is strongly recommended.\n",
    "\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", api_key=\"None\")\n",
    "\n",
    "# Chat completion example\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"List 3 countries and their capitals.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=64,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T23:25:54.275385Z",
     "iopub.status.busy": "2024-10-27T23:25:54.274807Z",
     "iopub.status.idle": "2024-10-27T23:25:57.082401Z",
     "shell.execute_reply": "2024-10-27T23:25:57.080829Z"
    }
   },
   "outputs": [],
   "source": [
    "terminate_process(server_process)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlphaMeemory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
