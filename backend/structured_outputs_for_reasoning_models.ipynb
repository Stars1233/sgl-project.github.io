{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Outputs For Reasoning Models\n",
    "\n",
    "When working with reasoning models that use special tokens like `<think>...</think>` to denote reasoning sections, you might want to allow free-form text within these sections while still enforcing grammar constraints on the rest of the output.\n",
    "\n",
    "SGLang provides a feature to disable grammar restrictions within reasoning sections. This is particularly useful for models that need to perform complex reasoning steps before providing a structured output.\n",
    "\n",
    "To enable this feature, use the `--reasoning-parser` flag which decide the think_end_token, such as `</think>`, when launching the server. You can also specify the reasoning parser using the `--reasoning-parser` flag.\n",
    "\n",
    "## Supported Models\n",
    "\n",
    "Currently, SGLang supports the following reasoning models:\n",
    "- [DeepSeek R1 series](https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d): The reasoning content is wrapped with `<think>` and `</think>` tags.\n",
    "- [QwQ](https://huggingface.co/Qwen/QwQ-32B): The reasoning content is wrapped with `<think>` and `</think>` tags.\n",
    "\n",
    "\n",
    "## Usage\n",
    "\n",
    "## OpenAI Compatible API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the `--grammar-backend`, `--reasoning-parser` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:34:35.550893Z",
     "iopub.status.busy": "2025-04-14T22:34:35.550564Z",
     "iopub.status.idle": "2025-04-14T22:35:16.216077Z",
     "shell.execute_reply": "2025-04-14T22:35:16.215480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:34:52] server_args=ServerArgs(model_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', tokenizer_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', chat_template=None, completion_template=None, is_embedding=False, revision=None, host='0.0.0.0', port=36234, mem_fraction_static=0.88, max_running_requests=200, max_total_tokens=20480, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=813499764, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser='deepseek-r1', dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=True, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, enable_llama4_multimodal=None, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_deepep_moe=False, deepep_mode='auto', enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, hicache_ratio=2.0, enable_flashinfer_mla=False, enable_flashmla=False, flashinfer_mla_disable_ragged=False, warmups=None, n_share_experts_fusion=0, disable_shared_experts_fusion=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_bootstrap_port=8998, disaggregation_transfer_backend='mooncake', disable_fast_image_processor=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:03 TP0] Attention backend not set. Use flashinfer backend by default.\n",
      "[2025-04-14 22:35:03 TP0] Init torch distributed begin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:05 TP0] Init torch distributed ends. mem usage=0.00 GB\n",
      "[2025-04-14 22:35:05 TP0] Load weight begin. avail mem=38.07 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:05 TP0] Ignore import error when loading sglang.srt.models.llama4. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:05 TP0] Using model weights format ['*.safetensors']\n",
      "\r",
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.25s/it]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.26s/it]\n",
      "\n",
      "[2025-04-14 22:35:08 TP0] Load weight end. type=Qwen2ForCausalLM, dtype=torch.bfloat16, avail mem=20.25 GB, mem usage=17.82 GB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:08 TP0] KV Cache is allocated. #tokens: 20480, K size: 0.55 GB, V size: 0.55 GB\n",
      "[2025-04-14 22:35:08 TP0] Memory pool end. avail mem=43.79 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:09 TP0] \n",
      "\n",
      "CUDA Graph is DISABLED.\n",
      "This will cause significant performance degradation.\n",
      "CUDA Graph should almost never be disabled in most usage scenarios.\n",
      "If you encounter OOM issues, please try setting --mem-fraction-static to a lower value (such as 0.8 or 0.7) instead of disabling CUDA Graph.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:09 TP0] max_total_num_tokens=20480, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=200, context_len=131072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:10] INFO:     Started server process [3950474]\n",
      "[2025-04-14 22:35:10] INFO:     Waiting for application startup.\n",
      "[2025-04-14 22:35:10] INFO:     Application startup complete.\n",
      "[2025-04-14 22:35:10] INFO:     Uvicorn running on http://0.0.0.0:36234 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:11] INFO:     127.0.0.1:37670 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
      "[2025-04-14 22:35:11] INFO:     127.0.0.1:37682 - \"GET /get_model_info HTTP/1.1\" 200 OK\n",
      "[2025-04-14 22:35:11 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:14] INFO:     127.0.0.1:37690 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-04-14 22:35:14] The server is fired up and ready to roll!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'><br><br>                    NOTE: Typically, the server runs in a separate terminal.<br>                    In this notebook, we run the server and notebook code together, so their outputs are combined.<br>                    To improve clarity, the server logs are displayed in the original black color, while the notebook outputs are highlighted in blue.<br>                    We are running those notebooks in a CI parallel environment, so the throughput is not representative of the actual performance.<br>                    </strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from sglang.test.test_utils import is_in_ci\n",
    "\n",
    "if is_in_ci():\n",
    "    from patch import launch_server_cmd\n",
    "else:\n",
    "    from sglang.utils import launch_server_cmd\n",
    "\n",
    "from sglang.utils import wait_for_server, print_highlight, terminate_process\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "server_process, port = launch_server_cmd(\n",
    "    \"python -m sglang.launch_server --model-path deepseek-ai/DeepSeek-R1-Distill-Qwen-7B --host 0.0.0.0 --reasoning-parser deepseek-r1\"\n",
    ")\n",
    "\n",
    "wait_for_server(f\"http://localhost:{port}\")\n",
    "client = openai.Client(base_url=f\"http://127.0.0.1:{port}/v1\", api_key=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON\n",
    "\n",
    "you can directly define a JSON schema or use [Pydantic](https://docs.pydantic.dev/latest/) to define and validate the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Pydantic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:35:16.218385Z",
     "iopub.status.busy": "2025-04-14T22:35:16.217889Z",
     "iopub.status.idle": "2025-04-14T22:35:38.149580Z",
     "shell.execute_reply": "2025-04-14T22:35:38.149038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:16 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:17 TP0] Decode batch. #running-req: 1, #token: 52, token usage: 0.00, gen throughput (token/s): 5.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:17 TP0] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, gen throughput (token/s): 102.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:18 TP0] Decode batch. #running-req: 1, #token: 132, token usage: 0.01, gen throughput (token/s): 99.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:18 TP0] Decode batch. #running-req: 1, #token: 172, token usage: 0.01, gen throughput (token/s): 102.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:19 TP0] Decode batch. #running-req: 1, #token: 212, token usage: 0.01, gen throughput (token/s): 95.58, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:19 TP0] Decode batch. #running-req: 1, #token: 252, token usage: 0.01, gen throughput (token/s): 99.92, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:20 TP0] Decode batch. #running-req: 1, #token: 292, token usage: 0.01, gen throughput (token/s): 99.38, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:20 TP0] Decode batch. #running-req: 1, #token: 332, token usage: 0.02, gen throughput (token/s): 101.14, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:20 TP0] Decode batch. #running-req: 1, #token: 372, token usage: 0.02, gen throughput (token/s): 84.31, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:21 TP0] Decode batch. #running-req: 1, #token: 412, token usage: 0.02, gen throughput (token/s): 98.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:21 TP0] Decode batch. #running-req: 1, #token: 452, token usage: 0.02, gen throughput (token/s): 98.65, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:22 TP0] Decode batch. #running-req: 1, #token: 492, token usage: 0.02, gen throughput (token/s): 98.67, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:22 TP0] Decode batch. #running-req: 1, #token: 532, token usage: 0.03, gen throughput (token/s): 99.55, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:22 TP0] Decode batch. #running-req: 1, #token: 572, token usage: 0.03, gen throughput (token/s): 102.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:23 TP0] Decode batch. #running-req: 1, #token: 612, token usage: 0.03, gen throughput (token/s): 99.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:23 TP0] Decode batch. #running-req: 1, #token: 652, token usage: 0.03, gen throughput (token/s): 97.56, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:24 TP0] Decode batch. #running-req: 1, #token: 692, token usage: 0.03, gen throughput (token/s): 98.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:24 TP0] Decode batch. #running-req: 1, #token: 732, token usage: 0.04, gen throughput (token/s): 98.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:24 TP0] Decode batch. #running-req: 1, #token: 772, token usage: 0.04, gen throughput (token/s): 100.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:25 TP0] Decode batch. #running-req: 1, #token: 812, token usage: 0.04, gen throughput (token/s): 96.17, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:25 TP0] Decode batch. #running-req: 1, #token: 852, token usage: 0.04, gen throughput (token/s): 97.32, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:26 TP0] Decode batch. #running-req: 1, #token: 892, token usage: 0.04, gen throughput (token/s): 101.41, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:26 TP0] Decode batch. #running-req: 1, #token: 932, token usage: 0.05, gen throughput (token/s): 96.60, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:26 TP0] Decode batch. #running-req: 1, #token: 972, token usage: 0.05, gen throughput (token/s): 100.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:27 TP0] Decode batch. #running-req: 1, #token: 1012, token usage: 0.05, gen throughput (token/s): 96.53, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:27 TP0] Decode batch. #running-req: 1, #token: 1052, token usage: 0.05, gen throughput (token/s): 97.61, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:28 TP0] Decode batch. #running-req: 1, #token: 1092, token usage: 0.05, gen throughput (token/s): 97.33, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:28 TP0] Decode batch. #running-req: 1, #token: 1132, token usage: 0.06, gen throughput (token/s): 96.47, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:28 TP0] Decode batch. #running-req: 1, #token: 1172, token usage: 0.06, gen throughput (token/s): 99.09, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:29 TP0] Decode batch. #running-req: 1, #token: 1212, token usage: 0.06, gen throughput (token/s): 90.78, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:29 TP0] Decode batch. #running-req: 1, #token: 1252, token usage: 0.06, gen throughput (token/s): 100.07, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:30 TP0] Decode batch. #running-req: 1, #token: 1292, token usage: 0.06, gen throughput (token/s): 93.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:30 TP0] Decode batch. #running-req: 1, #token: 1332, token usage: 0.07, gen throughput (token/s): 100.86, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:31 TP0] Decode batch. #running-req: 1, #token: 1372, token usage: 0.07, gen throughput (token/s): 97.09, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:31 TP0] Decode batch. #running-req: 1, #token: 1412, token usage: 0.07, gen throughput (token/s): 99.13, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:31 TP0] Decode batch. #running-req: 1, #token: 1452, token usage: 0.07, gen throughput (token/s): 98.51, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:32 TP0] Decode batch. #running-req: 1, #token: 1492, token usage: 0.07, gen throughput (token/s): 97.58, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:32 TP0] Decode batch. #running-req: 1, #token: 1532, token usage: 0.07, gen throughput (token/s): 96.01, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:33 TP0] Decode batch. #running-req: 1, #token: 1572, token usage: 0.08, gen throughput (token/s): 98.31, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:33 TP0] Decode batch. #running-req: 1, #token: 1612, token usage: 0.08, gen throughput (token/s): 100.49, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:33 TP0] Decode batch. #running-req: 1, #token: 1652, token usage: 0.08, gen throughput (token/s): 95.36, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:34 TP0] Decode batch. #running-req: 1, #token: 1692, token usage: 0.08, gen throughput (token/s): 97.80, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:34 TP0] Decode batch. #running-req: 1, #token: 1732, token usage: 0.08, gen throughput (token/s): 100.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:35 TP0] Decode batch. #running-req: 1, #token: 1772, token usage: 0.09, gen throughput (token/s): 94.86, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:35 TP0] Decode batch. #running-req: 1, #token: 1812, token usage: 0.09, gen throughput (token/s): 98.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:35 TP0] Decode batch. #running-req: 1, #token: 1852, token usage: 0.09, gen throughput (token/s): 98.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:36 TP0] Decode batch. #running-req: 1, #token: 1892, token usage: 0.09, gen throughput (token/s): 99.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:36 TP0] Decode batch. #running-req: 1, #token: 1932, token usage: 0.09, gen throughput (token/s): 101.04, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:37 TP0] Decode batch. #running-req: 1, #token: 1972, token usage: 0.10, gen throughput (token/s): 98.61, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:37 TP0] Decode batch. #running-req: 1, #token: 2012, token usage: 0.10, gen throughput (token/s): 98.95, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:37 TP0] Decode batch. #running-req: 1, #token: 2052, token usage: 0.10, gen throughput (token/s): 99.28, #queue-req: 0, \n",
      "[2025-04-14 22:35:38] INFO:     127.0.0.1:37706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>reasoing_content: Okay, so I need to generate information about the capital of France, Paris, in JSON format. Hmm, where do I start? Well, I know that Paris is the main city in France, but I'm not exactly sure about all the details. Let me think about what information is typically included about a city's capital.<br><br>First, the name of the city is obviously Paris. Then, the country it's the capital of, which is France. I remember that Paris is the largest city in France, but I'm not sure about its population. I think it's a big city, maybe around 2 million people? I'm not certain, though. I should probably look that up, but since I'm just brainstorming, I'll go with that for now.<br><br>Next, the location. Paris is located in the northern part of France, specifically in the Île-de-France region. I think it's on the Seine River, which is a major river there. The Eiffel Tower is in Paris, so that's a key landmark. I should include that.<br><br>Language-wise, Paris is a center for French culture, so French is definitely the predominant language. I'm not sure about minority languages or dialects, but maybe there are some, but I don't know which ones. I'll just note that French is the main language.<br><br>Cuisine is another aspect. Paris is famous for its food, like baguettes, croissants, and wine. I should mention some of the popular dishes, maybe something like \"Baguette,Croissant, and wine.\"<br><br>Transportation-wise, Paris has a well-developed public transit system, like the Métro, which is a subway network. I think there are trams and buses too. I should include that the public transport is extensive.<br><br>Economically, Paris is a significant hub. I believe it's home to many multinational companies and financial institutions. Maybe something like \"home to many multinational companies and financial institutions.\"<br><br>Culturally, Paris is rich in museums, art, and historical sites. The Louvre and the Musée d'Histéritage come to mind. Also, it's a UNESCO World Heritage Site, so I should mention that.<br><br>I should also include some notable landmarks. The Eiffel Tower, the Arc de Triomphe, the Louvre, Notre-Dame, and the Sacré-Cœur Basilica. Maybe the gardens around the Eiffel Tower, like Champ de Mars.<br><br>Now, putting this all together into JSON format. I need to structure it with the key \"capital\" and then include all these details as a value. I'll organize them under different categories for clarity, like \"name,\" \"country,\" \"population,\" \"location,\" \"language,\" \"cuisine,\" \"transportation,\" \"economy,\" \"culture,\" and \"landmarks.\"<br><br>Wait, I'm not sure about the population figure. I think it's around 2 million, but I'm not 100% certain. Maybe I should double-check that, but for now, I'll proceed with that number.<br><br>Also, I'm not sure if Paris is the only city in France that's a capital. I think there are others, but Paris is the main one. So, I should specify that Paris is the main capital.<br><br>I should make sure the JSON syntax is correct, with proper commas and quotation marks. Each key should be in quotes, and the entire structure should be an object within the \"capital\" key.<br><br>Putting it all together, I'll structure the JSON with each category as a key, and the corresponding details as values. I'll make sure to include all the points I thought of, but I'll keep it concise and relevant.<br><br>I think that's a good start. Now, I'll format it properly in JSON, ensuring that each key is correctly spelled and the values are accurate based on my understanding.<br><br><br>content: {<br><br>\"name\": \"Paris\",<br>\"population\": 20000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define the schema using Pydantic\n",
    "class CapitalInfo(BaseModel):\n",
    "    name: str = Field(..., pattern=r\"^\\w+$\", description=\"Name of the capital city\")\n",
    "    population: int = Field(..., description=\"Population of the capital city\")\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please generate the information of the capital of France in the JSON format.\",\n",
    "        },\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"foo\",\n",
    "            # convert the pydantic model to json schema\n",
    "            \"schema\": CapitalInfo.model_json_schema(),\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "print_highlight(\n",
    "    f\"reasoing_content: {response.choices[0].message.reasoning_content}\\n\\ncontent: {response.choices[0].message.content}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON Schema Directly**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:35:38.151522Z",
     "iopub.status.busy": "2025-04-14T22:35:38.151220Z",
     "iopub.status.idle": "2025-04-14T22:35:59.316375Z",
     "shell.execute_reply": "2025-04-14T22:35:59.315953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:38 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:38 TP0] Decode batch. #running-req: 1, #token: 44, token usage: 0.00, gen throughput (token/s): 71.60, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:38 TP0] Decode batch. #running-req: 1, #token: 84, token usage: 0.00, gen throughput (token/s): 99.09, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:39 TP0] Decode batch. #running-req: 1, #token: 124, token usage: 0.01, gen throughput (token/s): 97.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:39 TP0] Decode batch. #running-req: 1, #token: 164, token usage: 0.01, gen throughput (token/s): 101.19, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:40 TP0] Decode batch. #running-req: 1, #token: 204, token usage: 0.01, gen throughput (token/s): 97.44, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:40 TP0] Decode batch. #running-req: 1, #token: 244, token usage: 0.01, gen throughput (token/s): 98.13, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:40 TP0] Decode batch. #running-req: 1, #token: 284, token usage: 0.01, gen throughput (token/s): 99.08, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:41 TP0] Decode batch. #running-req: 1, #token: 324, token usage: 0.02, gen throughput (token/s): 99.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:41 TP0] Decode batch. #running-req: 1, #token: 364, token usage: 0.02, gen throughput (token/s): 97.99, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:42 TP0] Decode batch. #running-req: 1, #token: 404, token usage: 0.02, gen throughput (token/s): 99.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:42 TP0] Decode batch. #running-req: 1, #token: 444, token usage: 0.02, gen throughput (token/s): 100.23, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:42 TP0] Decode batch. #running-req: 1, #token: 484, token usage: 0.02, gen throughput (token/s): 98.74, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:43 TP0] Decode batch. #running-req: 1, #token: 524, token usage: 0.03, gen throughput (token/s): 97.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:43 TP0] Decode batch. #running-req: 1, #token: 564, token usage: 0.03, gen throughput (token/s): 102.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:44 TP0] Decode batch. #running-req: 1, #token: 604, token usage: 0.03, gen throughput (token/s): 96.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:44 TP0] Decode batch. #running-req: 1, #token: 644, token usage: 0.03, gen throughput (token/s): 96.32, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:45 TP0] Decode batch. #running-req: 1, #token: 684, token usage: 0.03, gen throughput (token/s): 99.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:45 TP0] Decode batch. #running-req: 1, #token: 724, token usage: 0.04, gen throughput (token/s): 101.36, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:45 TP0] Decode batch. #running-req: 1, #token: 764, token usage: 0.04, gen throughput (token/s): 82.64, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:46 TP0] Decode batch. #running-req: 1, #token: 804, token usage: 0.04, gen throughput (token/s): 98.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:46 TP0] Decode batch. #running-req: 1, #token: 844, token usage: 0.04, gen throughput (token/s): 95.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:47 TP0] Decode batch. #running-req: 1, #token: 884, token usage: 0.04, gen throughput (token/s): 97.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:47 TP0] Decode batch. #running-req: 1, #token: 924, token usage: 0.05, gen throughput (token/s): 95.63, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:47 TP0] Decode batch. #running-req: 1, #token: 964, token usage: 0.05, gen throughput (token/s): 93.93, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:48 TP0] Decode batch. #running-req: 1, #token: 1004, token usage: 0.05, gen throughput (token/s): 95.39, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:48 TP0] Decode batch. #running-req: 1, #token: 1044, token usage: 0.05, gen throughput (token/s): 86.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:49 TP0] Decode batch. #running-req: 1, #token: 1084, token usage: 0.05, gen throughput (token/s): 99.77, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:49 TP0] Decode batch. #running-req: 1, #token: 1124, token usage: 0.05, gen throughput (token/s): 98.58, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:50 TP0] Decode batch. #running-req: 1, #token: 1164, token usage: 0.06, gen throughput (token/s): 97.04, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:50 TP0] Decode batch. #running-req: 1, #token: 1204, token usage: 0.06, gen throughput (token/s): 92.95, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:50 TP0] Decode batch. #running-req: 1, #token: 1244, token usage: 0.06, gen throughput (token/s): 83.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:51 TP0] Decode batch. #running-req: 1, #token: 1284, token usage: 0.06, gen throughput (token/s): 96.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:51 TP0] Decode batch. #running-req: 1, #token: 1324, token usage: 0.06, gen throughput (token/s): 98.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:52 TP0] Decode batch. #running-req: 1, #token: 1364, token usage: 0.07, gen throughput (token/s): 103.30, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:52 TP0] Decode batch. #running-req: 1, #token: 1404, token usage: 0.07, gen throughput (token/s): 98.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:52 TP0] Decode batch. #running-req: 1, #token: 1444, token usage: 0.07, gen throughput (token/s): 103.23, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:53 TP0] Decode batch. #running-req: 1, #token: 1484, token usage: 0.07, gen throughput (token/s): 99.98, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:53 TP0] Decode batch. #running-req: 1, #token: 1524, token usage: 0.07, gen throughput (token/s): 100.54, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:54 TP0] Decode batch. #running-req: 1, #token: 1564, token usage: 0.08, gen throughput (token/s): 97.73, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:54 TP0] Decode batch. #running-req: 1, #token: 1604, token usage: 0.08, gen throughput (token/s): 100.42, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:55 TP0] Decode batch. #running-req: 1, #token: 1644, token usage: 0.08, gen throughput (token/s): 98.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:55 TP0] Decode batch. #running-req: 1, #token: 1684, token usage: 0.08, gen throughput (token/s): 96.91, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:55 TP0] Decode batch. #running-req: 1, #token: 1724, token usage: 0.08, gen throughput (token/s): 99.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:56 TP0] Decode batch. #running-req: 1, #token: 1764, token usage: 0.09, gen throughput (token/s): 102.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:56 TP0] Decode batch. #running-req: 1, #token: 1804, token usage: 0.09, gen throughput (token/s): 98.25, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:57 TP0] Decode batch. #running-req: 1, #token: 1844, token usage: 0.09, gen throughput (token/s): 97.98, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:57 TP0] Decode batch. #running-req: 1, #token: 1884, token usage: 0.09, gen throughput (token/s): 98.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:57 TP0] Decode batch. #running-req: 1, #token: 1924, token usage: 0.09, gen throughput (token/s): 96.47, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:58 TP0] Decode batch. #running-req: 1, #token: 1964, token usage: 0.10, gen throughput (token/s): 100.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:58 TP0] Decode batch. #running-req: 1, #token: 2004, token usage: 0.10, gen throughput (token/s): 97.27, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:59 TP0] Decode batch. #running-req: 1, #token: 2044, token usage: 0.10, gen throughput (token/s): 96.32, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:59] INFO:     127.0.0.1:37706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>reasoing_content: Okay, so I need to figure out the information about the capital of France and present it in JSON format. Hmm, let's start by recalling what I know about France. I know that Paris is the capital, but I should double-check that to be sure. Yeah, Paris is definitely the administrative and cultural center of France.<br><br>Now, I need to gather more details about Paris. Let me think about its location. Paris is located in the northern part of France, right? It's in the Île-de-France region. I remember that it's an island, so that's an important geographical feature. The coordinates are something like 48°51′N 2°28′E. I think that's correct, but I should make sure. Maybe I can visualize it on a map—Paris is in the north, near the Eiffel Tower and the Seine River.<br><br>Next, I should consider the history of Paris. It's been a major city for centuries. I know that during the French Revolution, Paris was the center of the revolution, and it's still a significant cultural and political hub today. It's also a global city, attracting millions of visitors each year.<br><br>Economically, Paris is a major financial and business center. I believe it's home to many multinational corporations and financial institutions. The Paris Stock Exchange comes to mind, and there are a lot of big companies based there. The city is also known for its fashion industry, with some of the world's most famous brands having headquarters in Paris.<br><br>Culturally, Paris is rich with art, literature, and history. The Louvre Museum is one of the world's largest art museums, and it's located in Paris. There's also the Musée d'Orsay, which is another major cultural institution. The city has a vibrant nightlife, with famous bars and clubs. I think places like Le Marais and Montmartre are known for their lively nightlife and artistic scenes.<br><br>Demographically, Paris is a large city, but it's also one of the most densely populated in the world. The metropolitan area covers a vast area, extending beyond the city limits into the outer suburbs. The population is diverse, with people from many different countries and backgrounds living there.<br><br>Transportation-wise, Paris has an extensive public transit system, including the Métro, which is a highly efficient subway network. There are also buses, trams, and trolleys that serve the city. The Seine River has several bridges and ferries that connect different parts of the city.<br><br>I should also mention some notable landmarks. The Eiffel Tower is a must-see, and the Arc de Triomphe is another iconic structure. The Notre-Dame Cathedral is a major religious site, though it's had some recent renovations and changes due to the fire that occurred in 2019.<br><br>In terms of language, Paris is a city where French is the official language, but it's also a multicultural city. People from around the world speak English, Spanish, German, and other languages there, contributing to a very international atmosphere.<br><br>I think I've covered the main points. Now, I need to structure this information into a JSON format. I'll start with the basic information: name, location, and status. Then, I'll add historical, economic, cultural, demographic, transportation, and notable landmarks sections. Each section will have relevant details under subkeys.<br><br>Wait, I should make sure that the JSON syntax is correct. I'll use proper braces, commas, and quotation marks. Also, I'll ensure that the keys are in lowercase letters as per JSON standards. Let me organize the information step by step.<br><br>First, the capital object will have properties like name, location, and status. Then, each additional section will be an object with its own properties. I'll make sure to include all the key details I thought of earlier, making sure each is accurate and concise.<br><br>I think that's a solid plan. Now, I'll put it all together into the JSON structure, double-checking for any missing or incorrect information. Once done, I'll review it to ensure it's well-organized and accurately represents the information about Paris as the capital of France.<br><br><br>content: {<br><br>\"name\": \"Paris\",<br>\"population\": 2153000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_schema = json.dumps(\n",
    "    {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\"type\": \"string\", \"pattern\": \"^[\\\\w]+$\"},\n",
    "            \"population\": {\"type\": \"integer\"},\n",
    "        },\n",
    "        \"required\": [\"name\", \"population\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me the information of the capital of France in the JSON format.\",\n",
    "        },\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\"name\": \"foo\", \"schema\": json.loads(json_schema)},\n",
    "    },\n",
    ")\n",
    "\n",
    "print_highlight(\n",
    "    f\"reasoing_content: {response.choices[0].message.reasoning_content}\\n\\ncontent: {response.choices[0].message.content}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:35:59.318021Z",
     "iopub.status.busy": "2025-04-14T22:35:59.317858Z",
     "iopub.status.idle": "2025-04-14T22:36:01.131244Z",
     "shell.execute_reply": "2025-04-14T22:36:01.130827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:59 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:59 TP0] Decode batch. #running-req: 1, #token: 39, token usage: 0.00, gen throughput (token/s): 84.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:35:59 TP0] Decode batch. #running-req: 1, #token: 79, token usage: 0.00, gen throughput (token/s): 102.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:00 TP0] Decode batch. #running-req: 1, #token: 119, token usage: 0.01, gen throughput (token/s): 100.07, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:00 TP0] Decode batch. #running-req: 1, #token: 159, token usage: 0.01, gen throughput (token/s): 98.92, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:01] INFO:     127.0.0.1:37706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>reasoing_content: Okay, so I need to figure out the capital of France. Hmm, I remember that France is a country in Europe, right? I think Paris is the capital because I've heard it mentioned a lot. But wait, I'm not 100% sure. Let me think about other capitals I know. Germany's capital is Berlin, Italy's is Rome, Spain's is Madrid, and the UK's is London. Yeah, Paris fits in there as the capital of France. I don't think there's any other city that's as prominent as Paris when it comes to being the country's main administrative center. Plus, I've heard people talk about the Eiffel Tower and the Louvre, which are both in Paris. So, I'm pretty confident that Paris is the correct answer.<br><br><br>content: Paris is the capital of France</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebnf_grammar = \"\"\"\n",
    "root ::= city | description\n",
    "city ::= \"London\" | \"Paris\" | \"Berlin\" | \"Rome\"\n",
    "description ::= city \" is \" status\n",
    "status ::= \"the capital of \" country\n",
    "country ::= \"England\" | \"France\" | \"Germany\" | \"Italy\"\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful geography bot.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me the information of the capital of France.\",\n",
    "        },\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    extra_body={\"ebnf\": ebnf_grammar},\n",
    ")\n",
    "\n",
    "print_highlight(\n",
    "    f\"reasoing_content: {response.choices[0].message.reasoning_content}\\n\\ncontent: {response.choices[0].message.content}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:36:01.132977Z",
     "iopub.status.busy": "2025-04-14T22:36:01.132711Z",
     "iopub.status.idle": "2025-04-14T22:36:02.665458Z",
     "shell.execute_reply": "2025-04-14T22:36:02.665041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:01 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, \n",
      "[2025-04-14 22:36:01 TP0] Decode batch. #running-req: 1, #token: 17, token usage: 0.00, gen throughput (token/s): 86.31, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:01 TP0] Decode batch. #running-req: 1, #token: 57, token usage: 0.00, gen throughput (token/s): 97.67, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:02 TP0] Decode batch. #running-req: 1, #token: 97, token usage: 0.00, gen throughput (token/s): 100.01, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:02 TP0] Decode batch. #running-req: 1, #token: 137, token usage: 0.01, gen throughput (token/s): 99.78, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:02] INFO:     127.0.0.1:37706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>reasoing_content: Okay, so I need to figure out the capital of France. Hmm, I remember that France is a country in Europe, right? I think Paris is the capital because I've heard it mentioned a lot, especially in movies and TV shows. But wait, I'm not entirely sure. Maybe I should think about other capitals of countries I know. For example, Germany's capital is Berlin, Italy's is Rome, Spain's is Madrid. So, following that pattern, France's capital should be Paris. I don't think it's another city like Lille or Nice because those are more known for their cities or natural beauty rather than being the official capital. Yeah, I'm pretty confident that Paris is the correct answer.<br><br><br>content: Paris</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    extra_body={\"regex\": \"(Paris|London)\"},\n",
    ")\n",
    "\n",
    "print_highlight(\n",
    "    f\"reasoing_content: {response.choices[0].message.reasoning_content}\\n\\ncontent: {response.choices[0].message.content}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:36:02.667415Z",
     "iopub.status.busy": "2025-04-14T22:36:02.667135Z",
     "iopub.status.idle": "2025-04-14T22:39:33.512563Z",
     "shell.execute_reply": "2025-04-14T22:39:33.512126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:02 TP0] Prefill batch. #new-seq: 1, #new-token: 471, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:03 TP0] Decode batch. #running-req: 1, #token: 488, token usage: 0.02, gen throughput (token/s): 50.79, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:03 TP0] Decode batch. #running-req: 1, #token: 528, token usage: 0.03, gen throughput (token/s): 100.50, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:04 TP0] Decode batch. #running-req: 1, #token: 568, token usage: 0.03, gen throughput (token/s): 92.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:04 TP0] Decode batch. #running-req: 1, #token: 608, token usage: 0.03, gen throughput (token/s): 95.30, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:04 TP0] Decode batch. #running-req: 1, #token: 648, token usage: 0.03, gen throughput (token/s): 96.73, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:05 TP0] Decode batch. #running-req: 1, #token: 688, token usage: 0.03, gen throughput (token/s): 87.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:05 TP0] Decode batch. #running-req: 1, #token: 728, token usage: 0.04, gen throughput (token/s): 60.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:06 TP0] Decode batch. #running-req: 1, #token: 768, token usage: 0.04, gen throughput (token/s): 62.08, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:07 TP0] Decode batch. #running-req: 1, #token: 808, token usage: 0.04, gen throughput (token/s): 74.32, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:07 TP0] Decode batch. #running-req: 1, #token: 848, token usage: 0.04, gen throughput (token/s): 67.23, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:08 TP0] Decode batch. #running-req: 1, #token: 888, token usage: 0.04, gen throughput (token/s): 64.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:09 TP0] Decode batch. #running-req: 1, #token: 928, token usage: 0.05, gen throughput (token/s): 61.99, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:09 TP0] Decode batch. #running-req: 1, #token: 968, token usage: 0.05, gen throughput (token/s): 61.42, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:10 TP0] Decode batch. #running-req: 1, #token: 1008, token usage: 0.05, gen throughput (token/s): 61.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:10 TP0] Decode batch. #running-req: 1, #token: 1048, token usage: 0.05, gen throughput (token/s): 61.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:11 TP0] Decode batch. #running-req: 1, #token: 1088, token usage: 0.05, gen throughput (token/s): 60.95, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:12 TP0] Decode batch. #running-req: 1, #token: 1128, token usage: 0.06, gen throughput (token/s): 61.83, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:12 TP0] Decode batch. #running-req: 1, #token: 1168, token usage: 0.06, gen throughput (token/s): 61.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:13 TP0] Decode batch. #running-req: 1, #token: 1208, token usage: 0.06, gen throughput (token/s): 67.93, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:13 TP0] Decode batch. #running-req: 1, #token: 1248, token usage: 0.06, gen throughput (token/s): 99.90, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:14 TP0] Decode batch. #running-req: 1, #token: 1288, token usage: 0.06, gen throughput (token/s): 96.24, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:14 TP0] Decode batch. #running-req: 1, #token: 1328, token usage: 0.06, gen throughput (token/s): 98.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:15 TP0] Decode batch. #running-req: 1, #token: 1368, token usage: 0.07, gen throughput (token/s): 100.45, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:15 TP0] Decode batch. #running-req: 1, #token: 1408, token usage: 0.07, gen throughput (token/s): 97.78, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:15 TP0] Decode batch. #running-req: 1, #token: 1448, token usage: 0.07, gen throughput (token/s): 97.74, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:16 TP0] Decode batch. #running-req: 1, #token: 1488, token usage: 0.07, gen throughput (token/s): 95.91, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:16 TP0] Decode batch. #running-req: 1, #token: 1528, token usage: 0.07, gen throughput (token/s): 99.77, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:17 TP0] Decode batch. #running-req: 1, #token: 1568, token usage: 0.08, gen throughput (token/s): 95.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:17 TP0] Decode batch. #running-req: 1, #token: 1608, token usage: 0.08, gen throughput (token/s): 97.82, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:18 TP0] Decode batch. #running-req: 1, #token: 1648, token usage: 0.08, gen throughput (token/s): 100.28, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:18 TP0] Decode batch. #running-req: 1, #token: 1688, token usage: 0.08, gen throughput (token/s): 97.86, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:18 TP0] Decode batch. #running-req: 1, #token: 1728, token usage: 0.08, gen throughput (token/s): 97.95, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:19 TP0] Decode batch. #running-req: 1, #token: 1768, token usage: 0.09, gen throughput (token/s): 94.76, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:19 TP0] Decode batch. #running-req: 1, #token: 1808, token usage: 0.09, gen throughput (token/s): 100.07, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:20 TP0] Decode batch. #running-req: 1, #token: 1848, token usage: 0.09, gen throughput (token/s): 95.42, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:20 TP0] Decode batch. #running-req: 1, #token: 1888, token usage: 0.09, gen throughput (token/s): 98.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:20 TP0] Decode batch. #running-req: 1, #token: 1928, token usage: 0.09, gen throughput (token/s): 100.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:21 TP0] Decode batch. #running-req: 1, #token: 1968, token usage: 0.10, gen throughput (token/s): 97.77, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:21 TP0] Decode batch. #running-req: 1, #token: 2008, token usage: 0.10, gen throughput (token/s): 95.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:22 TP0] Decode batch. #running-req: 1, #token: 2048, token usage: 0.10, gen throughput (token/s): 97.39, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:22 TP0] Decode batch. #running-req: 1, #token: 2088, token usage: 0.10, gen throughput (token/s): 99.07, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:22 TP0] Decode batch. #running-req: 1, #token: 2128, token usage: 0.10, gen throughput (token/s): 101.07, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:23 TP0] Decode batch. #running-req: 1, #token: 2168, token usage: 0.11, gen throughput (token/s): 99.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:23 TP0] Decode batch. #running-req: 1, #token: 2208, token usage: 0.11, gen throughput (token/s): 96.41, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:24 TP0] Decode batch. #running-req: 1, #token: 2248, token usage: 0.11, gen throughput (token/s): 100.44, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:24 TP0] Decode batch. #running-req: 1, #token: 2288, token usage: 0.11, gen throughput (token/s): 79.60, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:25 TP0] Decode batch. #running-req: 1, #token: 2328, token usage: 0.11, gen throughput (token/s): 101.08, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:25 TP0] Decode batch. #running-req: 1, #token: 2368, token usage: 0.12, gen throughput (token/s): 63.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:26 TP0] Decode batch. #running-req: 1, #token: 2408, token usage: 0.12, gen throughput (token/s): 62.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:26 TP0] Decode batch. #running-req: 1, #token: 2448, token usage: 0.12, gen throughput (token/s): 59.64, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:27 TP0] Decode batch. #running-req: 1, #token: 2488, token usage: 0.12, gen throughput (token/s): 63.17, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:28 TP0] Decode batch. #running-req: 1, #token: 2528, token usage: 0.12, gen throughput (token/s): 82.41, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:28 TP0] Decode batch. #running-req: 1, #token: 2568, token usage: 0.13, gen throughput (token/s): 101.72, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:28 TP0] Decode batch. #running-req: 1, #token: 2608, token usage: 0.13, gen throughput (token/s): 94.25, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:29 TP0] Decode batch. #running-req: 1, #token: 2648, token usage: 0.13, gen throughput (token/s): 95.55, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:29 TP0] Decode batch. #running-req: 1, #token: 2688, token usage: 0.13, gen throughput (token/s): 101.07, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:30 TP0] Decode batch. #running-req: 1, #token: 2728, token usage: 0.13, gen throughput (token/s): 97.90, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:30 TP0] Decode batch. #running-req: 1, #token: 2768, token usage: 0.14, gen throughput (token/s): 97.55, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:30 TP0] Decode batch. #running-req: 1, #token: 2808, token usage: 0.14, gen throughput (token/s): 94.37, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:31 TP0] Decode batch. #running-req: 1, #token: 2848, token usage: 0.14, gen throughput (token/s): 97.90, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:31 TP0] Decode batch. #running-req: 1, #token: 2888, token usage: 0.14, gen throughput (token/s): 101.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:32 TP0] Decode batch. #running-req: 1, #token: 2928, token usage: 0.14, gen throughput (token/s): 97.97, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:32 TP0] Decode batch. #running-req: 1, #token: 2968, token usage: 0.14, gen throughput (token/s): 96.83, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:32 TP0] Decode batch. #running-req: 1, #token: 3008, token usage: 0.15, gen throughput (token/s): 97.89, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:33 TP0] Decode batch. #running-req: 1, #token: 3048, token usage: 0.15, gen throughput (token/s): 96.64, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:33 TP0] Decode batch. #running-req: 1, #token: 3088, token usage: 0.15, gen throughput (token/s): 92.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:34 TP0] Decode batch. #running-req: 1, #token: 3128, token usage: 0.15, gen throughput (token/s): 98.70, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:34 TP0] Decode batch. #running-req: 1, #token: 3168, token usage: 0.15, gen throughput (token/s): 96.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:35 TP0] Decode batch. #running-req: 1, #token: 3208, token usage: 0.16, gen throughput (token/s): 88.05, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:35 TP0] Decode batch. #running-req: 1, #token: 3248, token usage: 0.16, gen throughput (token/s): 98.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:35 TP0] Decode batch. #running-req: 1, #token: 3288, token usage: 0.16, gen throughput (token/s): 98.81, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:36 TP0] Decode batch. #running-req: 1, #token: 3328, token usage: 0.16, gen throughput (token/s): 101.23, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:36 TP0] Decode batch. #running-req: 1, #token: 3368, token usage: 0.16, gen throughput (token/s): 98.45, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:37 TP0] Decode batch. #running-req: 1, #token: 3408, token usage: 0.17, gen throughput (token/s): 91.25, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:37 TP0] Decode batch. #running-req: 1, #token: 3448, token usage: 0.17, gen throughput (token/s): 87.66, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:38 TP0] Decode batch. #running-req: 1, #token: 3488, token usage: 0.17, gen throughput (token/s): 89.85, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:38 TP0] Decode batch. #running-req: 1, #token: 3528, token usage: 0.17, gen throughput (token/s): 97.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:38 TP0] Decode batch. #running-req: 1, #token: 3568, token usage: 0.17, gen throughput (token/s): 97.61, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:39 TP0] Decode batch. #running-req: 1, #token: 3608, token usage: 0.18, gen throughput (token/s): 98.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:39 TP0] Decode batch. #running-req: 1, #token: 3648, token usage: 0.18, gen throughput (token/s): 101.38, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:40 TP0] Decode batch. #running-req: 1, #token: 3688, token usage: 0.18, gen throughput (token/s): 96.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:40 TP0] Decode batch. #running-req: 1, #token: 3728, token usage: 0.18, gen throughput (token/s): 100.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:40 TP0] Decode batch. #running-req: 1, #token: 3768, token usage: 0.18, gen throughput (token/s): 97.77, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:41 TP0] Decode batch. #running-req: 1, #token: 3808, token usage: 0.19, gen throughput (token/s): 96.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:41 TP0] Decode batch. #running-req: 1, #token: 3848, token usage: 0.19, gen throughput (token/s): 100.78, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:42 TP0] Decode batch. #running-req: 1, #token: 3888, token usage: 0.19, gen throughput (token/s): 95.81, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:42 TP0] Decode batch. #running-req: 1, #token: 3928, token usage: 0.19, gen throughput (token/s): 98.07, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:42 TP0] Decode batch. #running-req: 1, #token: 3968, token usage: 0.19, gen throughput (token/s): 98.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:43 TP0] Decode batch. #running-req: 1, #token: 4008, token usage: 0.20, gen throughput (token/s): 99.97, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:43 TP0] Decode batch. #running-req: 1, #token: 4048, token usage: 0.20, gen throughput (token/s): 98.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:44 TP0] Decode batch. #running-req: 1, #token: 4088, token usage: 0.20, gen throughput (token/s): 96.14, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:44 TP0] Decode batch. #running-req: 1, #token: 4128, token usage: 0.20, gen throughput (token/s): 98.90, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:44 TP0] Decode batch. #running-req: 1, #token: 4168, token usage: 0.20, gen throughput (token/s): 98.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:45 TP0] Decode batch. #running-req: 1, #token: 4208, token usage: 0.21, gen throughput (token/s): 97.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:45 TP0] Decode batch. #running-req: 1, #token: 4248, token usage: 0.21, gen throughput (token/s): 96.77, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:46 TP0] Decode batch. #running-req: 1, #token: 4288, token usage: 0.21, gen throughput (token/s): 91.56, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:46 TP0] Decode batch. #running-req: 1, #token: 4328, token usage: 0.21, gen throughput (token/s): 95.56, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:47 TP0] Decode batch. #running-req: 1, #token: 4368, token usage: 0.21, gen throughput (token/s): 94.59, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:47 TP0] Decode batch. #running-req: 1, #token: 4408, token usage: 0.22, gen throughput (token/s): 95.81, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:47 TP0] Decode batch. #running-req: 1, #token: 4448, token usage: 0.22, gen throughput (token/s): 95.74, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:48 TP0] Decode batch. #running-req: 1, #token: 4488, token usage: 0.22, gen throughput (token/s): 95.92, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:48 TP0] Decode batch. #running-req: 1, #token: 4528, token usage: 0.22, gen throughput (token/s): 94.82, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:49 TP0] Decode batch. #running-req: 1, #token: 4568, token usage: 0.22, gen throughput (token/s): 95.39, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:49 TP0] Decode batch. #running-req: 1, #token: 4608, token usage: 0.23, gen throughput (token/s): 95.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:50 TP0] Decode batch. #running-req: 1, #token: 4648, token usage: 0.23, gen throughput (token/s): 95.91, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:50 TP0] Decode batch. #running-req: 1, #token: 4688, token usage: 0.23, gen throughput (token/s): 94.05, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:50 TP0] Decode batch. #running-req: 1, #token: 4728, token usage: 0.23, gen throughput (token/s): 97.09, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:51 TP0] Decode batch. #running-req: 1, #token: 4768, token usage: 0.23, gen throughput (token/s): 97.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:51 TP0] Decode batch. #running-req: 1, #token: 4808, token usage: 0.23, gen throughput (token/s): 93.09, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:52 TP0] Decode batch. #running-req: 1, #token: 4848, token usage: 0.24, gen throughput (token/s): 97.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:52 TP0] Decode batch. #running-req: 1, #token: 4888, token usage: 0.24, gen throughput (token/s): 94.44, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:52 TP0] Decode batch. #running-req: 1, #token: 4928, token usage: 0.24, gen throughput (token/s): 99.59, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:53 TP0] Decode batch. #running-req: 1, #token: 4968, token usage: 0.24, gen throughput (token/s): 94.72, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:53 TP0] Decode batch. #running-req: 1, #token: 5008, token usage: 0.24, gen throughput (token/s): 98.36, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:54 TP0] Decode batch. #running-req: 1, #token: 5048, token usage: 0.25, gen throughput (token/s): 92.95, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:54 TP0] Decode batch. #running-req: 1, #token: 5088, token usage: 0.25, gen throughput (token/s): 97.64, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:55 TP0] Decode batch. #running-req: 1, #token: 5128, token usage: 0.25, gen throughput (token/s): 95.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:55 TP0] Decode batch. #running-req: 1, #token: 5168, token usage: 0.25, gen throughput (token/s): 94.78, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:55 TP0] Decode batch. #running-req: 1, #token: 5208, token usage: 0.25, gen throughput (token/s): 94.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:56 TP0] Decode batch. #running-req: 1, #token: 5248, token usage: 0.26, gen throughput (token/s): 98.92, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:56 TP0] Decode batch. #running-req: 1, #token: 5288, token usage: 0.26, gen throughput (token/s): 94.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:57 TP0] Decode batch. #running-req: 1, #token: 5328, token usage: 0.26, gen throughput (token/s): 96.28, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:57 TP0] Decode batch. #running-req: 1, #token: 5368, token usage: 0.26, gen throughput (token/s): 98.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:57 TP0] Decode batch. #running-req: 1, #token: 5408, token usage: 0.26, gen throughput (token/s): 99.91, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:58 TP0] Decode batch. #running-req: 1, #token: 5448, token usage: 0.27, gen throughput (token/s): 94.87, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:58 TP0] Decode batch. #running-req: 1, #token: 5488, token usage: 0.27, gen throughput (token/s): 99.61, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:59 TP0] Decode batch. #running-req: 1, #token: 5528, token usage: 0.27, gen throughput (token/s): 94.97, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:59 TP0] Decode batch. #running-req: 1, #token: 5568, token usage: 0.27, gen throughput (token/s): 97.41, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:36:59 TP0] Decode batch. #running-req: 1, #token: 5608, token usage: 0.27, gen throughput (token/s): 96.70, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:00 TP0] Decode batch. #running-req: 1, #token: 5648, token usage: 0.28, gen throughput (token/s): 96.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:00 TP0] Decode batch. #running-req: 1, #token: 5688, token usage: 0.28, gen throughput (token/s): 94.45, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:01 TP0] Decode batch. #running-req: 1, #token: 5728, token usage: 0.28, gen throughput (token/s): 95.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:01 TP0] Decode batch. #running-req: 1, #token: 5768, token usage: 0.28, gen throughput (token/s): 92.55, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:02 TP0] Decode batch. #running-req: 1, #token: 5808, token usage: 0.28, gen throughput (token/s): 83.79, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:02 TP0] Decode batch. #running-req: 1, #token: 5848, token usage: 0.29, gen throughput (token/s): 80.56, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:03 TP0] Decode batch. #running-req: 1, #token: 5888, token usage: 0.29, gen throughput (token/s): 87.59, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:03 TP0] Decode batch. #running-req: 1, #token: 5928, token usage: 0.29, gen throughput (token/s): 91.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:04 TP0] Decode batch. #running-req: 1, #token: 5968, token usage: 0.29, gen throughput (token/s): 81.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:04 TP0] Decode batch. #running-req: 1, #token: 6008, token usage: 0.29, gen throughput (token/s): 85.05, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:05 TP0] Decode batch. #running-req: 1, #token: 6048, token usage: 0.30, gen throughput (token/s): 81.54, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:05 TP0] Decode batch. #running-req: 1, #token: 6088, token usage: 0.30, gen throughput (token/s): 95.55, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:05 TP0] Decode batch. #running-req: 1, #token: 6128, token usage: 0.30, gen throughput (token/s): 93.05, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:06 TP0] Decode batch. #running-req: 1, #token: 6168, token usage: 0.30, gen throughput (token/s): 66.79, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:07 TP0] Decode batch. #running-req: 1, #token: 6208, token usage: 0.30, gen throughput (token/s): 66.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:07 TP0] Decode batch. #running-req: 1, #token: 6248, token usage: 0.31, gen throughput (token/s): 67.01, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:08 TP0] Decode batch. #running-req: 1, #token: 6288, token usage: 0.31, gen throughput (token/s): 91.55, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:08 TP0] Decode batch. #running-req: 1, #token: 6328, token usage: 0.31, gen throughput (token/s): 94.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:08 TP0] Decode batch. #running-req: 1, #token: 6368, token usage: 0.31, gen throughput (token/s): 100.64, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:09 TP0] Decode batch. #running-req: 1, #token: 6408, token usage: 0.31, gen throughput (token/s): 96.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:09 TP0] Decode batch. #running-req: 1, #token: 6448, token usage: 0.31, gen throughput (token/s): 98.36, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:10 TP0] Decode batch. #running-req: 1, #token: 6488, token usage: 0.32, gen throughput (token/s): 98.14, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:10 TP0] Decode batch. #running-req: 1, #token: 6528, token usage: 0.32, gen throughput (token/s): 97.71, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:10 TP0] Decode batch. #running-req: 1, #token: 6568, token usage: 0.32, gen throughput (token/s): 98.27, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:11 TP0] Decode batch. #running-req: 1, #token: 6608, token usage: 0.32, gen throughput (token/s): 100.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:11 TP0] Decode batch. #running-req: 1, #token: 6648, token usage: 0.32, gen throughput (token/s): 94.16, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:12 TP0] Decode batch. #running-req: 1, #token: 6688, token usage: 0.33, gen throughput (token/s): 93.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:12 TP0] Decode batch. #running-req: 1, #token: 6728, token usage: 0.33, gen throughput (token/s): 99.63, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:13 TP0] Decode batch. #running-req: 1, #token: 6768, token usage: 0.33, gen throughput (token/s): 96.28, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:13 TP0] Decode batch. #running-req: 1, #token: 6808, token usage: 0.33, gen throughput (token/s): 95.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:13 TP0] Decode batch. #running-req: 1, #token: 6848, token usage: 0.33, gen throughput (token/s): 91.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:14 TP0] Decode batch. #running-req: 1, #token: 6888, token usage: 0.34, gen throughput (token/s): 93.63, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:14 TP0] Decode batch. #running-req: 1, #token: 6928, token usage: 0.34, gen throughput (token/s): 96.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:15 TP0] Decode batch. #running-req: 1, #token: 6968, token usage: 0.34, gen throughput (token/s): 98.09, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:15 TP0] Decode batch. #running-req: 1, #token: 7008, token usage: 0.34, gen throughput (token/s): 94.72, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:15 TP0] Decode batch. #running-req: 1, #token: 7048, token usage: 0.34, gen throughput (token/s): 98.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:16 TP0] Decode batch. #running-req: 1, #token: 7088, token usage: 0.35, gen throughput (token/s): 97.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:16 TP0] Decode batch. #running-req: 1, #token: 7128, token usage: 0.35, gen throughput (token/s): 100.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:17 TP0] Decode batch. #running-req: 1, #token: 7168, token usage: 0.35, gen throughput (token/s): 96.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:17 TP0] Decode batch. #running-req: 1, #token: 7208, token usage: 0.35, gen throughput (token/s): 98.33, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:17 TP0] Decode batch. #running-req: 1, #token: 7248, token usage: 0.35, gen throughput (token/s): 100.31, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:18 TP0] Decode batch. #running-req: 1, #token: 7288, token usage: 0.36, gen throughput (token/s): 96.99, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:18 TP0] Decode batch. #running-req: 1, #token: 7328, token usage: 0.36, gen throughput (token/s): 95.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:19 TP0] Decode batch. #running-req: 1, #token: 7368, token usage: 0.36, gen throughput (token/s): 96.04, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:19 TP0] Decode batch. #running-req: 1, #token: 7408, token usage: 0.36, gen throughput (token/s): 95.26, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:20 TP0] Decode batch. #running-req: 1, #token: 7448, token usage: 0.36, gen throughput (token/s): 92.35, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:20 TP0] Decode batch. #running-req: 1, #token: 7488, token usage: 0.37, gen throughput (token/s): 95.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:20 TP0] Decode batch. #running-req: 1, #token: 7528, token usage: 0.37, gen throughput (token/s): 93.36, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:21 TP0] Decode batch. #running-req: 1, #token: 7568, token usage: 0.37, gen throughput (token/s): 97.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:21 TP0] Decode batch. #running-req: 1, #token: 7608, token usage: 0.37, gen throughput (token/s): 95.54, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:22 TP0] Decode batch. #running-req: 1, #token: 7648, token usage: 0.37, gen throughput (token/s): 95.74, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:22 TP0] Decode batch. #running-req: 1, #token: 7688, token usage: 0.38, gen throughput (token/s): 96.42, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:23 TP0] Decode batch. #running-req: 1, #token: 7728, token usage: 0.38, gen throughput (token/s): 94.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:23 TP0] Decode batch. #running-req: 1, #token: 7768, token usage: 0.38, gen throughput (token/s): 96.87, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:23 TP0] Decode batch. #running-req: 1, #token: 7808, token usage: 0.38, gen throughput (token/s): 96.41, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:24 TP0] Decode batch. #running-req: 1, #token: 7848, token usage: 0.38, gen throughput (token/s): 96.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:24 TP0] Decode batch. #running-req: 1, #token: 7888, token usage: 0.39, gen throughput (token/s): 94.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:25 TP0] Decode batch. #running-req: 1, #token: 7928, token usage: 0.39, gen throughput (token/s): 97.12, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:25 TP0] Decode batch. #running-req: 1, #token: 7968, token usage: 0.39, gen throughput (token/s): 96.83, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:25 TP0] Decode batch. #running-req: 1, #token: 8008, token usage: 0.39, gen throughput (token/s): 97.26, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:26 TP0] Decode batch. #running-req: 1, #token: 8048, token usage: 0.39, gen throughput (token/s): 94.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:26 TP0] Decode batch. #running-req: 1, #token: 8088, token usage: 0.39, gen throughput (token/s): 99.78, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:27 TP0] Decode batch. #running-req: 1, #token: 8128, token usage: 0.40, gen throughput (token/s): 97.66, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:27 TP0] Decode batch. #running-req: 1, #token: 8168, token usage: 0.40, gen throughput (token/s): 95.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:28 TP0] Decode batch. #running-req: 1, #token: 8208, token usage: 0.40, gen throughput (token/s): 94.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:28 TP0] Decode batch. #running-req: 1, #token: 8248, token usage: 0.40, gen throughput (token/s): 96.80, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:28 TP0] Decode batch. #running-req: 1, #token: 8288, token usage: 0.40, gen throughput (token/s): 97.34, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:29 TP0] Decode batch. #running-req: 1, #token: 8328, token usage: 0.41, gen throughput (token/s): 96.98, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:29 TP0] Decode batch. #running-req: 1, #token: 8368, token usage: 0.41, gen throughput (token/s): 97.90, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:30 TP0] Decode batch. #running-req: 1, #token: 8408, token usage: 0.41, gen throughput (token/s): 98.21, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:30 TP0] Decode batch. #running-req: 1, #token: 8448, token usage: 0.41, gen throughput (token/s): 98.50, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:30 TP0] Decode batch. #running-req: 1, #token: 8488, token usage: 0.41, gen throughput (token/s): 98.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:31 TP0] Decode batch. #running-req: 1, #token: 8528, token usage: 0.42, gen throughput (token/s): 98.59, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:31 TP0] Decode batch. #running-req: 1, #token: 8568, token usage: 0.42, gen throughput (token/s): 98.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:32 TP0] Decode batch. #running-req: 1, #token: 8608, token usage: 0.42, gen throughput (token/s): 98.25, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:32 TP0] Decode batch. #running-req: 1, #token: 8648, token usage: 0.42, gen throughput (token/s): 100.90, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:32 TP0] Decode batch. #running-req: 1, #token: 8688, token usage: 0.42, gen throughput (token/s): 99.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:33 TP0] Decode batch. #running-req: 1, #token: 8728, token usage: 0.43, gen throughput (token/s): 98.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:33 TP0] Decode batch. #running-req: 1, #token: 8768, token usage: 0.43, gen throughput (token/s): 96.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:34 TP0] Decode batch. #running-req: 1, #token: 8808, token usage: 0.43, gen throughput (token/s): 98.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:34 TP0] Decode batch. #running-req: 1, #token: 8848, token usage: 0.43, gen throughput (token/s): 100.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:34 TP0] Decode batch. #running-req: 1, #token: 8888, token usage: 0.43, gen throughput (token/s): 98.47, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:35 TP0] Decode batch. #running-req: 1, #token: 8928, token usage: 0.44, gen throughput (token/s): 98.44, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:35 TP0] Decode batch. #running-req: 1, #token: 8968, token usage: 0.44, gen throughput (token/s): 96.72, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:36 TP0] Decode batch. #running-req: 1, #token: 9008, token usage: 0.44, gen throughput (token/s): 101.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:36 TP0] Decode batch. #running-req: 1, #token: 9048, token usage: 0.44, gen throughput (token/s): 96.99, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:36 TP0] Decode batch. #running-req: 1, #token: 9088, token usage: 0.44, gen throughput (token/s): 98.36, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:37 TP0] Decode batch. #running-req: 1, #token: 9128, token usage: 0.45, gen throughput (token/s): 96.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:37 TP0] Decode batch. #running-req: 1, #token: 9168, token usage: 0.45, gen throughput (token/s): 98.66, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:38 TP0] Decode batch. #running-req: 1, #token: 9208, token usage: 0.45, gen throughput (token/s): 100.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:38 TP0] Decode batch. #running-req: 1, #token: 9248, token usage: 0.45, gen throughput (token/s): 98.01, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:39 TP0] Decode batch. #running-req: 1, #token: 9288, token usage: 0.45, gen throughput (token/s): 95.52, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:39 TP0] Decode batch. #running-req: 1, #token: 9328, token usage: 0.46, gen throughput (token/s): 100.59, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:39 TP0] Decode batch. #running-req: 1, #token: 9368, token usage: 0.46, gen throughput (token/s): 97.76, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:40 TP0] Decode batch. #running-req: 1, #token: 9408, token usage: 0.46, gen throughput (token/s): 94.90, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:40 TP0] Decode batch. #running-req: 1, #token: 9448, token usage: 0.46, gen throughput (token/s): 99.07, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:41 TP0] Decode batch. #running-req: 1, #token: 9488, token usage: 0.46, gen throughput (token/s): 95.25, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:41 TP0] Decode batch. #running-req: 1, #token: 9528, token usage: 0.47, gen throughput (token/s): 97.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:41 TP0] Decode batch. #running-req: 1, #token: 9568, token usage: 0.47, gen throughput (token/s): 100.53, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:42 TP0] Decode batch. #running-req: 1, #token: 9608, token usage: 0.47, gen throughput (token/s): 97.33, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:42 TP0] Decode batch. #running-req: 1, #token: 9648, token usage: 0.47, gen throughput (token/s): 95.82, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:43 TP0] Decode batch. #running-req: 1, #token: 9688, token usage: 0.47, gen throughput (token/s): 95.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:43 TP0] Decode batch. #running-req: 1, #token: 9728, token usage: 0.47, gen throughput (token/s): 94.78, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:43 TP0] Decode batch. #running-req: 1, #token: 9768, token usage: 0.48, gen throughput (token/s): 100.51, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:44 TP0] Decode batch. #running-req: 1, #token: 9808, token usage: 0.48, gen throughput (token/s): 96.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:44 TP0] Decode batch. #running-req: 1, #token: 9848, token usage: 0.48, gen throughput (token/s): 100.41, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:45 TP0] Decode batch. #running-req: 1, #token: 9888, token usage: 0.48, gen throughput (token/s): 95.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:45 TP0] Decode batch. #running-req: 1, #token: 9928, token usage: 0.48, gen throughput (token/s): 97.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:45 TP0] Decode batch. #running-req: 1, #token: 9968, token usage: 0.49, gen throughput (token/s): 97.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:46 TP0] Decode batch. #running-req: 1, #token: 10008, token usage: 0.49, gen throughput (token/s): 98.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:46 TP0] Decode batch. #running-req: 1, #token: 10048, token usage: 0.49, gen throughput (token/s): 99.25, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:47 TP0] Decode batch. #running-req: 1, #token: 10088, token usage: 0.49, gen throughput (token/s): 99.76, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:47 TP0] Decode batch. #running-req: 1, #token: 10128, token usage: 0.49, gen throughput (token/s): 97.97, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:48 TP0] Decode batch. #running-req: 1, #token: 10168, token usage: 0.50, gen throughput (token/s): 100.38, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:48 TP0] Decode batch. #running-req: 1, #token: 10208, token usage: 0.50, gen throughput (token/s): 96.17, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:48 TP0] Decode batch. #running-req: 1, #token: 10248, token usage: 0.50, gen throughput (token/s): 97.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:49 TP0] Decode batch. #running-req: 1, #token: 10288, token usage: 0.50, gen throughput (token/s): 97.25, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:49 TP0] Decode batch. #running-req: 1, #token: 10328, token usage: 0.50, gen throughput (token/s): 96.81, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:50 TP0] Decode batch. #running-req: 1, #token: 10368, token usage: 0.51, gen throughput (token/s): 97.73, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:50 TP0] Decode batch. #running-req: 1, #token: 10408, token usage: 0.51, gen throughput (token/s): 98.74, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:50 TP0] Decode batch. #running-req: 1, #token: 10448, token usage: 0.51, gen throughput (token/s): 102.44, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:51 TP0] Decode batch. #running-req: 1, #token: 10488, token usage: 0.51, gen throughput (token/s): 97.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:51 TP0] Decode batch. #running-req: 1, #token: 10528, token usage: 0.51, gen throughput (token/s): 98.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:52 TP0] Decode batch. #running-req: 1, #token: 10568, token usage: 0.52, gen throughput (token/s): 99.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:52 TP0] Decode batch. #running-req: 1, #token: 10608, token usage: 0.52, gen throughput (token/s): 98.32, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:52 TP0] Decode batch. #running-req: 1, #token: 10648, token usage: 0.52, gen throughput (token/s): 99.85, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:53 TP0] Decode batch. #running-req: 1, #token: 10688, token usage: 0.52, gen throughput (token/s): 95.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:53 TP0] Decode batch. #running-req: 1, #token: 10728, token usage: 0.52, gen throughput (token/s): 100.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:54 TP0] Decode batch. #running-req: 1, #token: 10768, token usage: 0.53, gen throughput (token/s): 98.33, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:54 TP0] Decode batch. #running-req: 1, #token: 10808, token usage: 0.53, gen throughput (token/s): 95.35, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:54 TP0] Decode batch. #running-req: 1, #token: 10848, token usage: 0.53, gen throughput (token/s): 97.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:55 TP0] Decode batch. #running-req: 1, #token: 10888, token usage: 0.53, gen throughput (token/s): 98.08, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:55 TP0] Decode batch. #running-req: 1, #token: 10928, token usage: 0.53, gen throughput (token/s): 97.87, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:56 TP0] Decode batch. #running-req: 1, #token: 10968, token usage: 0.54, gen throughput (token/s): 97.93, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:56 TP0] Decode batch. #running-req: 1, #token: 11008, token usage: 0.54, gen throughput (token/s): 100.24, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:56 TP0] Decode batch. #running-req: 1, #token: 11048, token usage: 0.54, gen throughput (token/s): 95.72, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:57 TP0] Decode batch. #running-req: 1, #token: 11088, token usage: 0.54, gen throughput (token/s): 98.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:57 TP0] Decode batch. #running-req: 1, #token: 11128, token usage: 0.54, gen throughput (token/s): 98.14, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:58 TP0] Decode batch. #running-req: 1, #token: 11168, token usage: 0.55, gen throughput (token/s): 97.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:58 TP0] Decode batch. #running-req: 1, #token: 11208, token usage: 0.55, gen throughput (token/s): 98.26, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:59 TP0] Decode batch. #running-req: 1, #token: 11248, token usage: 0.55, gen throughput (token/s): 100.92, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:59 TP0] Decode batch. #running-req: 1, #token: 11288, token usage: 0.55, gen throughput (token/s): 98.37, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:37:59 TP0] Decode batch. #running-req: 1, #token: 11328, token usage: 0.55, gen throughput (token/s): 94.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:00 TP0] Decode batch. #running-req: 1, #token: 11368, token usage: 0.56, gen throughput (token/s): 99.38, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:00 TP0] Decode batch. #running-req: 1, #token: 11408, token usage: 0.56, gen throughput (token/s): 99.58, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:01 TP0] Decode batch. #running-req: 1, #token: 11448, token usage: 0.56, gen throughput (token/s): 99.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:01 TP0] Decode batch. #running-req: 1, #token: 11488, token usage: 0.56, gen throughput (token/s): 99.88, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:01 TP0] Decode batch. #running-req: 1, #token: 11528, token usage: 0.56, gen throughput (token/s): 98.86, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:02 TP0] Decode batch. #running-req: 1, #token: 11568, token usage: 0.56, gen throughput (token/s): 99.08, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:02 TP0] Decode batch. #running-req: 1, #token: 11608, token usage: 0.57, gen throughput (token/s): 101.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:03 TP0] Decode batch. #running-req: 1, #token: 11648, token usage: 0.57, gen throughput (token/s): 96.74, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:03 TP0] Decode batch. #running-req: 1, #token: 11688, token usage: 0.57, gen throughput (token/s): 96.89, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:03 TP0] Decode batch. #running-req: 1, #token: 11728, token usage: 0.57, gen throughput (token/s): 99.83, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:04 TP0] Decode batch. #running-req: 1, #token: 11768, token usage: 0.57, gen throughput (token/s): 98.53, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:04 TP0] Decode batch. #running-req: 1, #token: 11808, token usage: 0.58, gen throughput (token/s): 94.58, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:05 TP0] Decode batch. #running-req: 1, #token: 11848, token usage: 0.58, gen throughput (token/s): 98.51, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:05 TP0] Decode batch. #running-req: 1, #token: 11888, token usage: 0.58, gen throughput (token/s): 97.67, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:05 TP0] Decode batch. #running-req: 1, #token: 11928, token usage: 0.58, gen throughput (token/s): 97.19, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:06 TP0] Decode batch. #running-req: 1, #token: 11968, token usage: 0.58, gen throughput (token/s): 100.47, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:06 TP0] Decode batch. #running-req: 1, #token: 12008, token usage: 0.59, gen throughput (token/s): 96.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:07 TP0] Decode batch. #running-req: 1, #token: 12048, token usage: 0.59, gen throughput (token/s): 97.21, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:07 TP0] Decode batch. #running-req: 1, #token: 12088, token usage: 0.59, gen throughput (token/s): 100.78, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:07 TP0] Decode batch. #running-req: 1, #token: 12128, token usage: 0.59, gen throughput (token/s): 95.81, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:08 TP0] Decode batch. #running-req: 1, #token: 12168, token usage: 0.59, gen throughput (token/s): 100.41, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:08 TP0] Decode batch. #running-req: 1, #token: 12208, token usage: 0.60, gen throughput (token/s): 97.81, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:09 TP0] Decode batch. #running-req: 1, #token: 12248, token usage: 0.60, gen throughput (token/s): 95.34, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:09 TP0] Decode batch. #running-req: 1, #token: 12288, token usage: 0.60, gen throughput (token/s): 100.28, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:10 TP0] Decode batch. #running-req: 1, #token: 12328, token usage: 0.60, gen throughput (token/s): 95.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:10 TP0] Decode batch. #running-req: 1, #token: 12368, token usage: 0.60, gen throughput (token/s): 97.19, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:10 TP0] Decode batch. #running-req: 1, #token: 12408, token usage: 0.61, gen throughput (token/s): 99.78, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:11 TP0] Decode batch. #running-req: 1, #token: 12448, token usage: 0.61, gen throughput (token/s): 95.86, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:11 TP0] Decode batch. #running-req: 1, #token: 12488, token usage: 0.61, gen throughput (token/s): 97.91, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:12 TP0] Decode batch. #running-req: 1, #token: 12528, token usage: 0.61, gen throughput (token/s): 99.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:12 TP0] Decode batch. #running-req: 1, #token: 12568, token usage: 0.61, gen throughput (token/s): 95.33, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:12 TP0] Decode batch. #running-req: 1, #token: 12608, token usage: 0.62, gen throughput (token/s): 97.97, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:13 TP0] Decode batch. #running-req: 1, #token: 12648, token usage: 0.62, gen throughput (token/s): 99.05, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:13 TP0] Decode batch. #running-req: 1, #token: 12688, token usage: 0.62, gen throughput (token/s): 95.61, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:14 TP0] Decode batch. #running-req: 1, #token: 12728, token usage: 0.62, gen throughput (token/s): 101.27, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:14 TP0] Decode batch. #running-req: 1, #token: 12768, token usage: 0.62, gen throughput (token/s): 96.80, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:14 TP0] Decode batch. #running-req: 1, #token: 12808, token usage: 0.63, gen throughput (token/s): 98.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:15 TP0] Decode batch. #running-req: 1, #token: 12848, token usage: 0.63, gen throughput (token/s): 97.85, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:15 TP0] Decode batch. #running-req: 1, #token: 12888, token usage: 0.63, gen throughput (token/s): 99.85, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:16 TP0] Decode batch. #running-req: 1, #token: 12928, token usage: 0.63, gen throughput (token/s): 97.23, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:16 TP0] Decode batch. #running-req: 1, #token: 12968, token usage: 0.63, gen throughput (token/s): 98.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:16 TP0] Decode batch. #running-req: 1, #token: 13008, token usage: 0.64, gen throughput (token/s): 97.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:17 TP0] Decode batch. #running-req: 1, #token: 13048, token usage: 0.64, gen throughput (token/s): 99.30, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:17 TP0] Decode batch. #running-req: 1, #token: 13088, token usage: 0.64, gen throughput (token/s): 96.99, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:18 TP0] Decode batch. #running-req: 1, #token: 13128, token usage: 0.64, gen throughput (token/s): 95.31, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:18 TP0] Decode batch. #running-req: 1, #token: 13168, token usage: 0.64, gen throughput (token/s): 99.45, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:19 TP0] Decode batch. #running-req: 1, #token: 13208, token usage: 0.64, gen throughput (token/s): 98.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:19 TP0] Decode batch. #running-req: 1, #token: 13248, token usage: 0.65, gen throughput (token/s): 94.70, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:19 TP0] Decode batch. #running-req: 1, #token: 13288, token usage: 0.65, gen throughput (token/s): 96.54, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:20 TP0] Decode batch. #running-req: 1, #token: 13328, token usage: 0.65, gen throughput (token/s): 99.30, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:20 TP0] Decode batch. #running-req: 1, #token: 13368, token usage: 0.65, gen throughput (token/s): 95.61, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:21 TP0] Decode batch. #running-req: 1, #token: 13408, token usage: 0.65, gen throughput (token/s): 100.21, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:21 TP0] Decode batch. #running-req: 1, #token: 13448, token usage: 0.66, gen throughput (token/s): 95.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:21 TP0] Decode batch. #running-req: 1, #token: 13488, token usage: 0.66, gen throughput (token/s): 99.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:22 TP0] Decode batch. #running-req: 1, #token: 13528, token usage: 0.66, gen throughput (token/s): 98.45, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:22 TP0] Decode batch. #running-req: 1, #token: 13568, token usage: 0.66, gen throughput (token/s): 97.84, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:23 TP0] Decode batch. #running-req: 1, #token: 13608, token usage: 0.66, gen throughput (token/s): 97.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:23 TP0] Decode batch. #running-req: 1, #token: 13648, token usage: 0.67, gen throughput (token/s): 97.66, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:23 TP0] Decode batch. #running-req: 1, #token: 13688, token usage: 0.67, gen throughput (token/s): 98.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:24 TP0] Decode batch. #running-req: 1, #token: 13728, token usage: 0.67, gen throughput (token/s): 98.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:24 TP0] Decode batch. #running-req: 1, #token: 13768, token usage: 0.67, gen throughput (token/s): 99.09, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:25 TP0] Decode batch. #running-req: 1, #token: 13808, token usage: 0.67, gen throughput (token/s): 101.32, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:25 TP0] Decode batch. #running-req: 1, #token: 13848, token usage: 0.68, gen throughput (token/s): 98.12, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:25 TP0] Decode batch. #running-req: 1, #token: 13888, token usage: 0.68, gen throughput (token/s): 98.35, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:26 TP0] Decode batch. #running-req: 1, #token: 13928, token usage: 0.68, gen throughput (token/s): 99.23, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:26 TP0] Decode batch. #running-req: 1, #token: 13968, token usage: 0.68, gen throughput (token/s): 96.98, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:27 TP0] Decode batch. #running-req: 1, #token: 14008, token usage: 0.68, gen throughput (token/s): 101.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:27 TP0] Decode batch. #running-req: 1, #token: 14048, token usage: 0.69, gen throughput (token/s): 98.79, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:27 TP0] Decode batch. #running-req: 1, #token: 14088, token usage: 0.69, gen throughput (token/s): 99.39, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:28 TP0] Decode batch. #running-req: 1, #token: 14128, token usage: 0.69, gen throughput (token/s): 98.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:28 TP0] Decode batch. #running-req: 1, #token: 14168, token usage: 0.69, gen throughput (token/s): 96.87, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:29 TP0] Decode batch. #running-req: 1, #token: 14208, token usage: 0.69, gen throughput (token/s): 101.49, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:29 TP0] Decode batch. #running-req: 1, #token: 14248, token usage: 0.70, gen throughput (token/s): 97.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:29 TP0] Decode batch. #running-req: 1, #token: 14288, token usage: 0.70, gen throughput (token/s): 99.55, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:30 TP0] Decode batch. #running-req: 1, #token: 14328, token usage: 0.70, gen throughput (token/s): 101.93, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:30 TP0] Decode batch. #running-req: 1, #token: 14368, token usage: 0.70, gen throughput (token/s): 99.24, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:31 TP0] Decode batch. #running-req: 1, #token: 14408, token usage: 0.70, gen throughput (token/s): 96.13, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:31 TP0] Decode batch. #running-req: 1, #token: 14448, token usage: 0.71, gen throughput (token/s): 97.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:32 TP0] Decode batch. #running-req: 1, #token: 14488, token usage: 0.71, gen throughput (token/s): 97.80, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:32 TP0] Decode batch. #running-req: 1, #token: 14528, token usage: 0.71, gen throughput (token/s): 99.51, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:32 TP0] Decode batch. #running-req: 1, #token: 14568, token usage: 0.71, gen throughput (token/s): 92.95, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:33 TP0] Decode batch. #running-req: 1, #token: 14608, token usage: 0.71, gen throughput (token/s): 99.97, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:33 TP0] Decode batch. #running-req: 1, #token: 14648, token usage: 0.72, gen throughput (token/s): 99.14, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:34 TP0] Decode batch. #running-req: 1, #token: 14688, token usage: 0.72, gen throughput (token/s): 98.19, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:34 TP0] Decode batch. #running-req: 1, #token: 14728, token usage: 0.72, gen throughput (token/s): 93.38, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:34 TP0] Decode batch. #running-req: 1, #token: 14768, token usage: 0.72, gen throughput (token/s): 99.99, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:35 TP0] Decode batch. #running-req: 1, #token: 14808, token usage: 0.72, gen throughput (token/s): 97.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:35 TP0] Decode batch. #running-req: 1, #token: 14848, token usage: 0.72, gen throughput (token/s): 94.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:36 TP0] Decode batch. #running-req: 1, #token: 14888, token usage: 0.73, gen throughput (token/s): 97.88, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:36 TP0] Decode batch. #running-req: 1, #token: 14928, token usage: 0.73, gen throughput (token/s): 98.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:36 TP0] Decode batch. #running-req: 1, #token: 14968, token usage: 0.73, gen throughput (token/s): 98.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:37 TP0] Decode batch. #running-req: 1, #token: 15008, token usage: 0.73, gen throughput (token/s): 98.26, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:37 TP0] Decode batch. #running-req: 1, #token: 15048, token usage: 0.73, gen throughput (token/s): 100.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:38 TP0] Decode batch. #running-req: 1, #token: 15088, token usage: 0.74, gen throughput (token/s): 96.24, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:38 TP0] Decode batch. #running-req: 1, #token: 15128, token usage: 0.74, gen throughput (token/s): 97.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:38 TP0] Decode batch. #running-req: 1, #token: 15168, token usage: 0.74, gen throughput (token/s): 97.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:39 TP0] Decode batch. #running-req: 1, #token: 15208, token usage: 0.74, gen throughput (token/s): 97.72, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:39 TP0] Decode batch. #running-req: 1, #token: 15248, token usage: 0.74, gen throughput (token/s): 98.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:40 TP0] Decode batch. #running-req: 1, #token: 15288, token usage: 0.75, gen throughput (token/s): 96.60, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:40 TP0] Decode batch. #running-req: 1, #token: 15328, token usage: 0.75, gen throughput (token/s): 96.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:41 TP0] Decode batch. #running-req: 1, #token: 15368, token usage: 0.75, gen throughput (token/s): 95.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:41 TP0] Decode batch. #running-req: 1, #token: 15408, token usage: 0.75, gen throughput (token/s): 98.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:41 TP0] Decode batch. #running-req: 1, #token: 15448, token usage: 0.75, gen throughput (token/s): 98.97, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:42 TP0] Decode batch. #running-req: 1, #token: 15488, token usage: 0.76, gen throughput (token/s): 96.01, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:42 TP0] Decode batch. #running-req: 1, #token: 15528, token usage: 0.76, gen throughput (token/s): 96.60, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:43 TP0] Decode batch. #running-req: 1, #token: 15568, token usage: 0.76, gen throughput (token/s): 98.30, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:43 TP0] Decode batch. #running-req: 1, #token: 15608, token usage: 0.76, gen throughput (token/s): 98.56, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:43 TP0] Decode batch. #running-req: 1, #token: 15648, token usage: 0.76, gen throughput (token/s): 100.83, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:44 TP0] Decode batch. #running-req: 1, #token: 15688, token usage: 0.77, gen throughput (token/s): 96.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:44 TP0] Decode batch. #running-req: 1, #token: 15728, token usage: 0.77, gen throughput (token/s): 98.63, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:45 TP0] Decode batch. #running-req: 1, #token: 15768, token usage: 0.77, gen throughput (token/s): 98.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:45 TP0] Decode batch. #running-req: 1, #token: 15808, token usage: 0.77, gen throughput (token/s): 98.33, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:45 TP0] Decode batch. #running-req: 1, #token: 15848, token usage: 0.77, gen throughput (token/s): 97.87, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:46 TP0] Decode batch. #running-req: 1, #token: 15888, token usage: 0.78, gen throughput (token/s): 98.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:46 TP0] Decode batch. #running-req: 1, #token: 15928, token usage: 0.78, gen throughput (token/s): 98.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:47 TP0] Decode batch. #running-req: 1, #token: 15968, token usage: 0.78, gen throughput (token/s): 95.77, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:47 TP0] Decode batch. #running-req: 1, #token: 16008, token usage: 0.78, gen throughput (token/s): 100.13, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:47 TP0] Decode batch. #running-req: 1, #token: 16048, token usage: 0.78, gen throughput (token/s): 97.38, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:48 TP0] Decode batch. #running-req: 1, #token: 16088, token usage: 0.79, gen throughput (token/s): 97.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:48 TP0] Decode batch. #running-req: 1, #token: 16128, token usage: 0.79, gen throughput (token/s): 97.25, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:49 TP0] Decode batch. #running-req: 1, #token: 16168, token usage: 0.79, gen throughput (token/s): 97.35, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:49 TP0] Decode batch. #running-req: 1, #token: 16208, token usage: 0.79, gen throughput (token/s): 94.27, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:50 TP0] Decode batch. #running-req: 1, #token: 16248, token usage: 0.79, gen throughput (token/s): 95.88, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:50 TP0] Decode batch. #running-req: 1, #token: 16288, token usage: 0.80, gen throughput (token/s): 99.27, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:50 TP0] Decode batch. #running-req: 1, #token: 16328, token usage: 0.80, gen throughput (token/s): 95.09, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:51 TP0] Decode batch. #running-req: 1, #token: 16368, token usage: 0.80, gen throughput (token/s): 99.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:51 TP0] Decode batch. #running-req: 1, #token: 16408, token usage: 0.80, gen throughput (token/s): 97.60, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:52 TP0] Decode batch. #running-req: 1, #token: 16448, token usage: 0.80, gen throughput (token/s): 97.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:52 TP0] Decode batch. #running-req: 1, #token: 16488, token usage: 0.81, gen throughput (token/s): 97.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:52 TP0] Decode batch. #running-req: 1, #token: 16528, token usage: 0.81, gen throughput (token/s): 97.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:53 TP0] Decode batch. #running-req: 1, #token: 16568, token usage: 0.81, gen throughput (token/s): 95.76, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:53 TP0] Decode batch. #running-req: 1, #token: 16608, token usage: 0.81, gen throughput (token/s): 97.41, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:54 TP0] Decode batch. #running-req: 1, #token: 16648, token usage: 0.81, gen throughput (token/s): 98.26, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:54 TP0] Decode batch. #running-req: 1, #token: 16688, token usage: 0.81, gen throughput (token/s): 98.01, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:54 TP0] Decode batch. #running-req: 1, #token: 16728, token usage: 0.82, gen throughput (token/s): 96.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:55 TP0] Decode batch. #running-req: 1, #token: 16768, token usage: 0.82, gen throughput (token/s): 102.30, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:55 TP0] Decode batch. #running-req: 1, #token: 16808, token usage: 0.82, gen throughput (token/s): 99.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:56 TP0] Decode batch. #running-req: 1, #token: 16848, token usage: 0.82, gen throughput (token/s): 97.58, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:56 TP0] Decode batch. #running-req: 1, #token: 16888, token usage: 0.82, gen throughput (token/s): 98.21, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:57 TP0] Decode batch. #running-req: 1, #token: 16928, token usage: 0.83, gen throughput (token/s): 96.24, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:57 TP0] Decode batch. #running-req: 1, #token: 16968, token usage: 0.83, gen throughput (token/s): 96.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:57 TP0] Decode batch. #running-req: 1, #token: 17008, token usage: 0.83, gen throughput (token/s): 98.82, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:58 TP0] Decode batch. #running-req: 1, #token: 17048, token usage: 0.83, gen throughput (token/s): 101.34, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:58 TP0] Decode batch. #running-req: 1, #token: 17088, token usage: 0.83, gen throughput (token/s): 96.59, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:59 TP0] Decode batch. #running-req: 1, #token: 17128, token usage: 0.84, gen throughput (token/s): 100.97, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:59 TP0] Decode batch. #running-req: 1, #token: 17168, token usage: 0.84, gen throughput (token/s): 93.24, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:38:59 TP0] Decode batch. #running-req: 1, #token: 17208, token usage: 0.84, gen throughput (token/s): 99.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:00 TP0] Decode batch. #running-req: 1, #token: 17248, token usage: 0.84, gen throughput (token/s): 96.01, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:00 TP0] Decode batch. #running-req: 1, #token: 17288, token usage: 0.84, gen throughput (token/s): 101.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:01 TP0] Decode batch. #running-req: 1, #token: 17328, token usage: 0.85, gen throughput (token/s): 99.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:01 TP0] Decode batch. #running-req: 1, #token: 17368, token usage: 0.85, gen throughput (token/s): 96.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:01 TP0] Decode batch. #running-req: 1, #token: 17408, token usage: 0.85, gen throughput (token/s): 99.41, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:02 TP0] Decode batch. #running-req: 1, #token: 17448, token usage: 0.85, gen throughput (token/s): 101.71, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:02 TP0] Decode batch. #running-req: 1, #token: 17488, token usage: 0.85, gen throughput (token/s): 96.74, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:03 TP0] Decode batch. #running-req: 1, #token: 17528, token usage: 0.86, gen throughput (token/s): 98.61, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:03 TP0] Decode batch. #running-req: 1, #token: 17568, token usage: 0.86, gen throughput (token/s): 101.90, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:03 TP0] Decode batch. #running-req: 1, #token: 17608, token usage: 0.86, gen throughput (token/s): 97.45, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:04 TP0] Decode batch. #running-req: 1, #token: 17648, token usage: 0.86, gen throughput (token/s): 99.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:04 TP0] Decode batch. #running-req: 1, #token: 17688, token usage: 0.86, gen throughput (token/s): 101.22, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:05 TP0] Decode batch. #running-req: 1, #token: 17728, token usage: 0.87, gen throughput (token/s): 98.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:05 TP0] Decode batch. #running-req: 1, #token: 17768, token usage: 0.87, gen throughput (token/s): 98.08, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:05 TP0] Decode batch. #running-req: 1, #token: 17808, token usage: 0.87, gen throughput (token/s): 96.61, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:06 TP0] Decode batch. #running-req: 1, #token: 17848, token usage: 0.87, gen throughput (token/s): 98.99, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:06 TP0] Decode batch. #running-req: 1, #token: 17888, token usage: 0.87, gen throughput (token/s): 99.44, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:07 TP0] Decode batch. #running-req: 1, #token: 17928, token usage: 0.88, gen throughput (token/s): 100.55, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:07 TP0] Decode batch. #running-req: 1, #token: 17968, token usage: 0.88, gen throughput (token/s): 98.50, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:07 TP0] Decode batch. #running-req: 1, #token: 18008, token usage: 0.88, gen throughput (token/s): 98.33, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:08 TP0] Decode batch. #running-req: 1, #token: 18048, token usage: 0.88, gen throughput (token/s): 98.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:08 TP0] Decode batch. #running-req: 1, #token: 18088, token usage: 0.88, gen throughput (token/s): 98.21, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:09 TP0] Decode batch. #running-req: 1, #token: 18128, token usage: 0.89, gen throughput (token/s): 99.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:09 TP0] Decode batch. #running-req: 1, #token: 18168, token usage: 0.89, gen throughput (token/s): 96.72, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:10 TP0] Decode batch. #running-req: 1, #token: 18208, token usage: 0.89, gen throughput (token/s): 98.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:10 TP0] Decode batch. #running-req: 1, #token: 18248, token usage: 0.89, gen throughput (token/s): 99.64, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:10 TP0] Decode batch. #running-req: 1, #token: 18288, token usage: 0.89, gen throughput (token/s): 99.23, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:11 TP0] Decode batch. #running-req: 1, #token: 18328, token usage: 0.89, gen throughput (token/s): 98.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:11 TP0] Decode batch. #running-req: 1, #token: 18368, token usage: 0.90, gen throughput (token/s): 100.04, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:12 TP0] Decode batch. #running-req: 1, #token: 18408, token usage: 0.90, gen throughput (token/s): 95.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:12 TP0] Decode batch. #running-req: 1, #token: 18448, token usage: 0.90, gen throughput (token/s): 95.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:12 TP0] Decode batch. #running-req: 1, #token: 18488, token usage: 0.90, gen throughput (token/s): 97.33, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:13 TP0] Decode batch. #running-req: 1, #token: 18528, token usage: 0.90, gen throughput (token/s): 96.99, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:13 TP0] Decode batch. #running-req: 1, #token: 18568, token usage: 0.91, gen throughput (token/s): 96.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:14 TP0] Decode batch. #running-req: 1, #token: 18608, token usage: 0.91, gen throughput (token/s): 90.12, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:14 TP0] Decode batch. #running-req: 1, #token: 18648, token usage: 0.91, gen throughput (token/s): 96.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:14 TP0] Decode batch. #running-req: 1, #token: 18688, token usage: 0.91, gen throughput (token/s): 96.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:15 TP0] Decode batch. #running-req: 1, #token: 18728, token usage: 0.91, gen throughput (token/s): 93.01, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:15 TP0] Decode batch. #running-req: 1, #token: 18768, token usage: 0.92, gen throughput (token/s): 98.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:16 TP0] Decode batch. #running-req: 1, #token: 18808, token usage: 0.92, gen throughput (token/s): 96.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:16 TP0] Decode batch. #running-req: 1, #token: 18848, token usage: 0.92, gen throughput (token/s): 96.17, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:17 TP0] Decode batch. #running-req: 1, #token: 18888, token usage: 0.92, gen throughput (token/s): 96.63, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:17 TP0] Decode batch. #running-req: 1, #token: 18928, token usage: 0.92, gen throughput (token/s): 98.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:17 TP0] Decode batch. #running-req: 1, #token: 18968, token usage: 0.93, gen throughput (token/s): 95.32, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:18 TP0] Decode batch. #running-req: 1, #token: 19008, token usage: 0.93, gen throughput (token/s): 99.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:18 TP0] Decode batch. #running-req: 1, #token: 19048, token usage: 0.93, gen throughput (token/s): 96.92, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:19 TP0] Decode batch. #running-req: 1, #token: 19088, token usage: 0.93, gen throughput (token/s): 96.85, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:19 TP0] Decode batch. #running-req: 1, #token: 19128, token usage: 0.93, gen throughput (token/s): 96.74, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:19 TP0] Decode batch. #running-req: 1, #token: 19168, token usage: 0.94, gen throughput (token/s): 96.96, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:20 TP0] Decode batch. #running-req: 1, #token: 19208, token usage: 0.94, gen throughput (token/s): 96.67, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:20 TP0] Decode batch. #running-req: 1, #token: 19248, token usage: 0.94, gen throughput (token/s): 94.97, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:21 TP0] Decode batch. #running-req: 1, #token: 19288, token usage: 0.94, gen throughput (token/s): 96.20, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:21 TP0] Decode batch. #running-req: 1, #token: 19328, token usage: 0.94, gen throughput (token/s): 98.07, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:22 TP0] Decode batch. #running-req: 1, #token: 19368, token usage: 0.95, gen throughput (token/s): 94.80, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:22 TP0] Decode batch. #running-req: 1, #token: 19408, token usage: 0.95, gen throughput (token/s): 96.80, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:22 TP0] Decode batch. #running-req: 1, #token: 19448, token usage: 0.95, gen throughput (token/s): 96.87, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:23 TP0] Decode batch. #running-req: 1, #token: 19488, token usage: 0.95, gen throughput (token/s): 96.38, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:23 TP0] Decode batch. #running-req: 1, #token: 19528, token usage: 0.95, gen throughput (token/s): 96.12, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:24 TP0] Decode batch. #running-req: 1, #token: 19568, token usage: 0.96, gen throughput (token/s): 98.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:24 TP0] Decode batch. #running-req: 1, #token: 19608, token usage: 0.96, gen throughput (token/s): 88.86, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:24 TP0] Decode batch. #running-req: 1, #token: 19648, token usage: 0.96, gen throughput (token/s): 97.31, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:25 TP0] Decode batch. #running-req: 1, #token: 19688, token usage: 0.96, gen throughput (token/s): 96.67, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:25 TP0] Decode batch. #running-req: 1, #token: 19728, token usage: 0.96, gen throughput (token/s): 98.95, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:26 TP0] Decode batch. #running-req: 1, #token: 19768, token usage: 0.97, gen throughput (token/s): 94.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:26 TP0] Decode batch. #running-req: 1, #token: 19808, token usage: 0.97, gen throughput (token/s): 95.76, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:26 TP0] Decode batch. #running-req: 1, #token: 19848, token usage: 0.97, gen throughput (token/s): 98.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:27 TP0] Decode batch. #running-req: 1, #token: 19888, token usage: 0.97, gen throughput (token/s): 95.61, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:27 TP0] Decode batch. #running-req: 1, #token: 19928, token usage: 0.97, gen throughput (token/s): 93.71, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:28 TP0] Decode batch. #running-req: 1, #token: 19968, token usage: 0.97, gen throughput (token/s): 99.52, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:28 TP0] Decode batch. #running-req: 1, #token: 20008, token usage: 0.98, gen throughput (token/s): 98.08, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:29 TP0] Decode batch. #running-req: 1, #token: 20048, token usage: 0.98, gen throughput (token/s): 98.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:29 TP0] Decode batch. #running-req: 1, #token: 20088, token usage: 0.98, gen throughput (token/s): 95.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:29 TP0] Decode batch. #running-req: 1, #token: 20128, token usage: 0.98, gen throughput (token/s): 97.85, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:30 TP0] Decode batch. #running-req: 1, #token: 20168, token usage: 0.98, gen throughput (token/s): 97.24, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:30 TP0] Decode batch. #running-req: 1, #token: 20208, token usage: 0.99, gen throughput (token/s): 95.04, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:31 TP0] Decode batch. #running-req: 1, #token: 20248, token usage: 0.99, gen throughput (token/s): 95.21, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:31 TP0] Decode batch. #running-req: 1, #token: 20288, token usage: 0.99, gen throughput (token/s): 96.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:31 TP0] Decode batch. #running-req: 1, #token: 20328, token usage: 0.99, gen throughput (token/s): 95.65, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:32 TP0] Decode batch. #running-req: 1, #token: 20368, token usage: 0.99, gen throughput (token/s): 93.58, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:32 TP0] Decode batch. #running-req: 1, #token: 20408, token usage: 1.00, gen throughput (token/s): 98.67, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:33 TP0] Decode batch. #running-req: 1, #token: 20448, token usage: 1.00, gen throughput (token/s): 100.65, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:33] INFO:     127.0.0.1:37706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>reasoing_content: Okay, the user is in New York and wants the current date and time along with the weather. I need to figure out how to help them using the functions available. <br><br>First, they mentioned they're in New York, so the timezone is 'America/New_York'. For the date and time, I should use the 'get_current_date' function. The parameters required are the timezone, so I'll set that to 'America/New_York'.<br><br>Next, for the weather, the user is in a specific location. The city is New York, the state is NY, and I should fetch the temperature in Fahrenheit since that's a common request. So, I'll use the 'get_current_weather' function with city 'New York', state 'NY', and unit 'fahrenheit'.<br><br>I have to structure each function call separately, as per the instructions. Each reply should be on one line with the function name and parameters in JSON format. I'll also need to include a source for each function call, probably from the official documentation.<br><br>Putting it all together, I'll send two separate function calls: one for the date and time, and another for the weather. Each will have their respective parameters and sources noted.<br><br><br>content: To get the current date and time in New York, I will use the `get_current_date` function with the timezone parameter set to 'America/New_York'. Additionally, to retrieve the current weather in New York, I will use the `get_current_weather` function with the city, state, and unit parameters set to 'New York', 'NY', and 'fahrenheit' respectively.<br><br><function=get_current_date>{\"timezone\": \"America/New_York)}</function> <br>Source: https://docs.python-requests.org/en/latest/ <br><br> <function=get_current_weather>{\"</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tool_get_current_weather = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city to find the weather for, e.g. 'San Francisco'\",\n",
    "                },\n",
    "                \"state\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"the two-letter abbreviation for the state that the city is\"\n",
    "                    \" in, e.g. 'CA' which would mean 'California'\",\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unit to fetch the temperature in\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"city\", \"state\", \"unit\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tool_get_current_date = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_current_date\",\n",
    "        \"description\": \"Get the current date and time for a given timezone\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"timezone\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The timezone to fetch the current date and time for, e.g. 'America/New_York'\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"timezone\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "schema_get_current_weather = tool_get_current_weather[\"function\"][\"parameters\"]\n",
    "schema_get_current_date = tool_get_current_date[\"function\"][\"parameters\"]\n",
    "\n",
    "\n",
    "def get_messages():\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "# Tool Instructions\n",
    "- Always execute python code in messages that you share.\n",
    "- When looking for real time information use relevant functions if available else fallback to brave_search\n",
    "You have access to the following functions:\n",
    "Use the function 'get_current_weather' to: Get the current weather in a given location\n",
    "{tool_get_current_weather[\"function\"]}\n",
    "Use the function 'get_current_date' to: Get the current date and time for a given timezone\n",
    "{tool_get_current_date[\"function\"]}\n",
    "If a you choose to call a function ONLY reply in the following format:\n",
    "<{{start_tag}}={{function_name}}>{{parameters}}{{end_tag}}\n",
    "where\n",
    "start_tag => `<function`\n",
    "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
    "end_tag => `</function>`\n",
    "Here is an example,\n",
    "<function=example_function_name>{{\"example_name\": \"example_value\"}}</function>\n",
    "Reminder:\n",
    "- Function calls MUST follow the specified format\n",
    "- Required parameters MUST be specified\n",
    "- Only call one function at a time\n",
    "- Put the entire function call reply on one line\n",
    "- Always add your sources when using search results to answer the user query\n",
    "You are a helpful assistant.\"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"You are in New York. Please get the current date and time, and the weather.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "messages = get_messages()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    messages=messages,\n",
    "    response_format={\n",
    "        \"type\": \"structural_tag\",\n",
    "        \"max_new_tokens\": 2048,\n",
    "        \"structures\": [\n",
    "            {\n",
    "                \"begin\": \"<function=get_current_weather>\",\n",
    "                \"schema\": schema_get_current_weather,\n",
    "                \"end\": \"</function>\",\n",
    "            },\n",
    "            {\n",
    "                \"begin\": \"<function=get_current_date>\",\n",
    "                \"schema\": schema_get_current_date,\n",
    "                \"end\": \"</function>\",\n",
    "            },\n",
    "        ],\n",
    "        \"triggers\": [\"<function=\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print_highlight(\n",
    "    f\"reasoing_content: {response.choices[0].message.reasoning_content}\\n\\ncontent: {response.choices[0].message.content}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Native API and SGLang Runtime (SRT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Pydantic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:39:33.514400Z",
     "iopub.status.busy": "2025-04-14T22:39:33.514086Z",
     "iopub.status.idle": "2025-04-14T22:39:41.128243Z",
     "shell.execute_reply": "2025-04-14T22:39:41.127678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:33 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, \n",
      "[2025-04-14 22:39:34 TP0] Decode batch. #running-req: 1, #token: 30, token usage: 0.00, gen throughput (token/s): 45.36, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:34 TP0] Decode batch. #running-req: 1, #token: 70, token usage: 0.00, gen throughput (token/s): 100.13, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:34 TP0] Decode batch. #running-req: 1, #token: 110, token usage: 0.01, gen throughput (token/s): 100.50, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:35 TP0] Decode batch. #running-req: 1, #token: 150, token usage: 0.01, gen throughput (token/s): 100.26, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:35 TP0] Decode batch. #running-req: 1, #token: 190, token usage: 0.01, gen throughput (token/s): 99.49, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:36 TP0] Decode batch. #running-req: 1, #token: 230, token usage: 0.01, gen throughput (token/s): 97.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:36 TP0] Decode batch. #running-req: 1, #token: 270, token usage: 0.01, gen throughput (token/s): 98.98, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:36 TP0] Decode batch. #running-req: 1, #token: 310, token usage: 0.02, gen throughput (token/s): 98.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:37 TP0] Decode batch. #running-req: 1, #token: 350, token usage: 0.02, gen throughput (token/s): 99.82, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:37 TP0] Decode batch. #running-req: 1, #token: 390, token usage: 0.02, gen throughput (token/s): 103.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:38 TP0] Decode batch. #running-req: 1, #token: 430, token usage: 0.02, gen throughput (token/s): 98.04, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:38 TP0] Decode batch. #running-req: 1, #token: 470, token usage: 0.02, gen throughput (token/s): 99.33, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:38 TP0] Decode batch. #running-req: 1, #token: 510, token usage: 0.02, gen throughput (token/s): 99.31, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:39 TP0] Decode batch. #running-req: 1, #token: 550, token usage: 0.03, gen throughput (token/s): 101.48, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:39 TP0] Decode batch. #running-req: 1, #token: 590, token usage: 0.03, gen throughput (token/s): 97.83, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:40 TP0] Decode batch. #running-req: 1, #token: 630, token usage: 0.03, gen throughput (token/s): 102.86, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:40 TP0] Decode batch. #running-req: 1, #token: 670, token usage: 0.03, gen throughput (token/s): 97.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:40 TP0] Decode batch. #running-req: 1, #token: 710, token usage: 0.03, gen throughput (token/s): 99.59, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:41] INFO:     127.0.0.1:59754 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "{'text': 'Okay, so I need to provide the information about the capital of France in JSON format. Hmm, I\\'m not exactly sure where the capital of France is, but I think it\\'s Paris. Yeah, I remember hearing that Paris is the capital. Let me think about what details I should include. \\n\\nFirst, the basic info: country, city, population, and maybe some key landmarks. I know the population is around 2 million, but I\\'m not sure of the exact number. I think it\\'s approximately 2,165,000. As for landmarks, the Eiffel Tower is a must. The Louvre Museum is another famous spot. The Arc de Triomphe is also iconic. Maybe the Seine River is important too since it\\'s a major river in the city.\\n\\nI should structure this in JSON. So, the main object would have a \"country\" key pointing to \"France,\" and the \"capital\" key pointing to \"Paris.\" Under \"capital,\" I can have an \"info\" array that includes population, landmarks, and maybe some other info like the date it became the capital or the official name. Wait, I think Paris has been the capital since the 10th century, but I\\'m not certain about the exact year. I\\'ll just put around 978 AD for now.\\n\\nLet me make sure I\\'m not missing anything important. Maybe the official name of the city is \"City of Light,\" which is the official name of Paris. Including that could be helpful. Also, perhaps the area of the city, but I don\\'t remember the exact figure. Maybe around 105 square kilometers? I\\'m not sure, but I\\'ll include it as an estimate.\\n\\nPutting it all together, the JSON structure would have a top-level object with \"country\" and \"capital.\" The \"capital\" would have an \"info\" array with population, landmarks, area, and official name. I think that covers the essentials. I should double-check some of these numbers to make sure they\\'re accurate, but since I\\'m just recalling, I\\'ll proceed with what I have.\\n\\nWait, I should also consider if there are any other notable facts. Maybe the number of hospitals or universities? I\\'m not sure, but perhaps that\\'s too detailed. Keeping it simple with population, landmarks, area, and official name seems sufficient.\\n\\nSo, to summarize, the JSON would look like this:\\n\\n{\\n  \"country\": \"France\",\\n  \"capital\": {\\n    \"info\": [\\n      {\\n        \"key\": \"population\",\\n        \"value\": \"2,165,000\"\\n      },\\n      {\\n        \"key\": \"landmarks\",\\n        \"value\": [\\n          \"Eiffel Tower\",\\n          \"Louvre Museum\",\\n          \"Arc de Triomphe\",\\n          \"Seine River\"\\n        ]\\n      },\\n      {\\n        \"key\": \"area\",\\n        \"value\": \"105 km²\"\\n      },\\n      {\\n        \"key\": \"official_name\",\\n        \"value\": \"City of Light\"\\n      },\\n      {\\n        \"key\": \"capital_year\",\\n        \"value\": \"978 AD\"\\n      }\\n    ]\\n  }\\n}\\n\\nI think that\\'s a comprehensive yet concise structure. I hope I didn\\'t miss any important details, but this should cover the basics about the capital of France.\\n</think>{\\n\\n\"name\": \"Paris\",\\n\"population\": 2165000\\n}', 'meta_info': {'id': '759a2f1d60644b0391ad5417f7f5d596', 'finish_reason': {'type': 'stop', 'matched': 151643}, 'prompt_tokens': 20, 'completion_tokens': 711, 'cached_tokens': 1, 'e2e_latency': 7.154998540878296}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>reasoing_content: Okay, so I need to provide the information about the capital of France in JSON format. Hmm, I'm not exactly sure where the capital of France is, but I think it's Paris. Yeah, I remember hearing that Paris is the capital. Let me think about what details I should include. <br><br>First, the basic info: country, city, population, and maybe some key landmarks. I know the population is around 2 million, but I'm not sure of the exact number. I think it's approximately 2,165,000. As for landmarks, the Eiffel Tower is a must. The Louvre Museum is another famous spot. The Arc de Triomphe is also iconic. Maybe the Seine River is important too since it's a major river in the city.<br><br>I should structure this in JSON. So, the main object would have a \"country\" key pointing to \"France,\" and the \"capital\" key pointing to \"Paris.\" Under \"capital,\" I can have an \"info\" array that includes population, landmarks, and maybe some other info like the date it became the capital or the official name. Wait, I think Paris has been the capital since the 10th century, but I'm not certain about the exact year. I'll just put around 978 AD for now.<br><br>Let me make sure I'm not missing anything important. Maybe the official name of the city is \"City of Light,\" which is the official name of Paris. Including that could be helpful. Also, perhaps the area of the city, but I don't remember the exact figure. Maybe around 105 square kilometers? I'm not sure, but I'll include it as an estimate.<br><br>Putting it all together, the JSON structure would have a top-level object with \"country\" and \"capital.\" The \"capital\" would have an \"info\" array with population, landmarks, area, and official name. I think that covers the essentials. I should double-check some of these numbers to make sure they're accurate, but since I'm just recalling, I'll proceed with what I have.<br><br>Wait, I should also consider if there are any other notable facts. Maybe the number of hospitals or universities? I'm not sure, but perhaps that's too detailed. Keeping it simple with population, landmarks, area, and official name seems sufficient.<br><br>So, to summarize, the JSON would look like this:<br><br>{<br>  \"country\": \"France\",<br>  \"capital\": {<br>    \"info\": [<br>      {<br>        \"key\": \"population\",<br>        \"value\": \"2,165,000\"<br>      },<br>      {<br>        \"key\": \"landmarks\",<br>        \"value\": [<br>          \"Eiffel Tower\",<br>          \"Louvre Museum\",<br>          \"Arc de Triomphe\",<br>          \"Seine River\"<br>        ]<br>      },<br>      {<br>        \"key\": \"area\",<br>        \"value\": \"105 km²\"<br>      },<br>      {<br>        \"key\": \"official_name\",<br>        \"value\": \"City of Light\"<br>      },<br>      {<br>        \"key\": \"capital_year\",<br>        \"value\": \"978 AD\"<br>      }<br>    ]<br>  }<br>}<br><br>I think that's a comprehensive yet concise structure. I hope I didn't miss any important details, but this should cover the basics about the capital of France.<br><br><br>content: {'name': 'Paris', 'population': 2165000}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\")\n",
    "\n",
    "\n",
    "# Define the schema using Pydantic\n",
    "class CapitalInfo(BaseModel):\n",
    "    name: str = Field(..., pattern=r\"^\\w+$\", description=\"Name of the capital city\")\n",
    "    population: int = Field(..., description=\"Population of the capital city\")\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Here is the information of the capital of France in the JSON format.\\n\",\n",
    "    }\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "# Make API request\n",
    "response = requests.post(\n",
    "    f\"http://localhost:{port}/generate\",\n",
    "    json={\n",
    "        \"text\": text,\n",
    "        \"sampling_params\": {\n",
    "            \"temperature\": 0,\n",
    "            \"max_new_tokens\": 2048,\n",
    "            \"json_schema\": json.dumps(CapitalInfo.model_json_schema()),\n",
    "        },\n",
    "    },\n",
    ")\n",
    "print(response.json())\n",
    "\n",
    "\n",
    "reasoing_content = response.json()[\"text\"].split(\"</think>\")[0]\n",
    "content = json.loads(response.json()[\"text\"].split(\"</think>\")[1])\n",
    "print_highlight(f\"reasoing_content: {reasoing_content}\\n\\ncontent: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON Schema Directly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:39:41.130340Z",
     "iopub.status.busy": "2025-04-14T22:39:41.129744Z",
     "iopub.status.idle": "2025-04-14T22:40:01.776128Z",
     "shell.execute_reply": "2025-04-14T22:40:01.775701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:41 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:41 TP0] Decode batch. #running-req: 1, #token: 24, token usage: 0.00, gen throughput (token/s): 92.22, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:41 TP0] Decode batch. #running-req: 1, #token: 64, token usage: 0.00, gen throughput (token/s): 102.82, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:42 TP0] Decode batch. #running-req: 1, #token: 104, token usage: 0.01, gen throughput (token/s): 98.49, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:42 TP0] Decode batch. #running-req: 1, #token: 144, token usage: 0.01, gen throughput (token/s): 100.53, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:42 TP0] Decode batch. #running-req: 1, #token: 184, token usage: 0.01, gen throughput (token/s): 100.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:43 TP0] Decode batch. #running-req: 1, #token: 224, token usage: 0.01, gen throughput (token/s): 102.50, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:43 TP0] Decode batch. #running-req: 1, #token: 264, token usage: 0.01, gen throughput (token/s): 96.47, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:44 TP0] Decode batch. #running-req: 1, #token: 304, token usage: 0.01, gen throughput (token/s): 98.64, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:44 TP0] Decode batch. #running-req: 1, #token: 344, token usage: 0.02, gen throughput (token/s): 98.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:44 TP0] Decode batch. #running-req: 1, #token: 384, token usage: 0.02, gen throughput (token/s): 95.95, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:45 TP0] Decode batch. #running-req: 1, #token: 424, token usage: 0.02, gen throughput (token/s): 99.52, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:45 TP0] Decode batch. #running-req: 1, #token: 464, token usage: 0.02, gen throughput (token/s): 100.49, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:46 TP0] Decode batch. #running-req: 1, #token: 504, token usage: 0.02, gen throughput (token/s): 97.47, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:46 TP0] Decode batch. #running-req: 1, #token: 544, token usage: 0.03, gen throughput (token/s): 100.50, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:46 TP0] Decode batch. #running-req: 1, #token: 584, token usage: 0.03, gen throughput (token/s): 100.51, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:47 TP0] Decode batch. #running-req: 1, #token: 624, token usage: 0.03, gen throughput (token/s): 101.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:47 TP0] Decode batch. #running-req: 1, #token: 664, token usage: 0.03, gen throughput (token/s): 103.32, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:48 TP0] Decode batch. #running-req: 1, #token: 704, token usage: 0.03, gen throughput (token/s): 97.88, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:48 TP0] Decode batch. #running-req: 1, #token: 744, token usage: 0.04, gen throughput (token/s): 103.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:48 TP0] Decode batch. #running-req: 1, #token: 784, token usage: 0.04, gen throughput (token/s): 98.62, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:49 TP0] Decode batch. #running-req: 1, #token: 824, token usage: 0.04, gen throughput (token/s): 100.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:49 TP0] Decode batch. #running-req: 1, #token: 864, token usage: 0.04, gen throughput (token/s): 100.65, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:50 TP0] Decode batch. #running-req: 1, #token: 904, token usage: 0.04, gen throughput (token/s): 100.27, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:50 TP0] Decode batch. #running-req: 1, #token: 944, token usage: 0.05, gen throughput (token/s): 102.92, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:50 TP0] Decode batch. #running-req: 1, #token: 984, token usage: 0.05, gen throughput (token/s): 95.49, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:51 TP0] Decode batch. #running-req: 1, #token: 1024, token usage: 0.05, gen throughput (token/s): 100.99, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:51 TP0] Decode batch. #running-req: 1, #token: 1064, token usage: 0.05, gen throughput (token/s): 97.40, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:52 TP0] Decode batch. #running-req: 1, #token: 1104, token usage: 0.05, gen throughput (token/s): 99.56, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:52 TP0] Decode batch. #running-req: 1, #token: 1144, token usage: 0.06, gen throughput (token/s): 100.25, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:52 TP0] Decode batch. #running-req: 1, #token: 1184, token usage: 0.06, gen throughput (token/s): 100.51, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:53 TP0] Decode batch. #running-req: 1, #token: 1224, token usage: 0.06, gen throughput (token/s): 98.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:53 TP0] Decode batch. #running-req: 1, #token: 1264, token usage: 0.06, gen throughput (token/s): 96.09, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:54 TP0] Decode batch. #running-req: 1, #token: 1304, token usage: 0.06, gen throughput (token/s): 95.78, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:54 TP0] Decode batch. #running-req: 1, #token: 1344, token usage: 0.07, gen throughput (token/s): 95.64, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:55 TP0] Decode batch. #running-req: 1, #token: 1384, token usage: 0.07, gen throughput (token/s): 98.92, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:55 TP0] Decode batch. #running-req: 1, #token: 1424, token usage: 0.07, gen throughput (token/s): 101.60, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:55 TP0] Decode batch. #running-req: 1, #token: 1464, token usage: 0.07, gen throughput (token/s): 98.79, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:56 TP0] Decode batch. #running-req: 1, #token: 1504, token usage: 0.07, gen throughput (token/s): 96.59, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:56 TP0] Decode batch. #running-req: 1, #token: 1544, token usage: 0.08, gen throughput (token/s): 101.08, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:57 TP0] Decode batch. #running-req: 1, #token: 1584, token usage: 0.08, gen throughput (token/s): 96.72, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:57 TP0] Decode batch. #running-req: 1, #token: 1624, token usage: 0.08, gen throughput (token/s): 98.83, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:57 TP0] Decode batch. #running-req: 1, #token: 1664, token usage: 0.08, gen throughput (token/s): 98.87, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:58 TP0] Decode batch. #running-req: 1, #token: 1704, token usage: 0.08, gen throughput (token/s): 101.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:58 TP0] Decode batch. #running-req: 1, #token: 1744, token usage: 0.09, gen throughput (token/s): 96.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:59 TP0] Decode batch. #running-req: 1, #token: 1784, token usage: 0.09, gen throughput (token/s): 98.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:59 TP0] Decode batch. #running-req: 1, #token: 1824, token usage: 0.09, gen throughput (token/s): 98.66, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:39:59 TP0] Decode batch. #running-req: 1, #token: 1864, token usage: 0.09, gen throughput (token/s): 100.86, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:00 TP0] Decode batch. #running-req: 1, #token: 1904, token usage: 0.09, gen throughput (token/s): 97.81, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:00 TP0] Decode batch. #running-req: 1, #token: 1944, token usage: 0.09, gen throughput (token/s): 102.95, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:01 TP0] Decode batch. #running-req: 1, #token: 1984, token usage: 0.10, gen throughput (token/s): 98.15, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:01 TP0] Decode batch. #running-req: 1, #token: 2024, token usage: 0.10, gen throughput (token/s): 99.72, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:01] INFO:     127.0.0.1:50568 - \"POST /generate HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{'text': 'Okay, so I need to figure out how to solve this problem. Hmm, wait, the user just said \"Anshul\" and then \"Please reason step by step, and put your final answer within \\\\boxed{}.\" But there\\'s no specific question here. Maybe they forgot to ask a question? Or perhaps they\\'re referring to a previous conversation? I\\'m a bit confused. Let me think about what I can do.\\n\\nMaybe I can prompt them to provide more details or clarify what they need help with. I should respond politely and ask for clarification. That way, I can assist them better once I understand their request.\\n\\nSo, I\\'ll say something like, \"Hello! It seems like your question got cut off. Could you please provide more details or clarify what you need help with? I\\'m here to assist you!\"\\n\\nYeah, that should do it. It\\'s friendly and encourages them to share more information so I can help them effectively.\\n</think>{\\n\\n\"name\" \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', 'meta_info': {'id': 'd016e49e4ed4404da2af8550d01d2545', 'finish_reason': {'type': 'length', 'length': 2048}, 'prompt_tokens': 5, 'completion_tokens': 2048, 'cached_tokens': 2, 'e2e_latency': 20.6363844871521}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "json_schema = json.dumps(\n",
    "    {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\"type\": \"string\", \"pattern\": \"^[\\\\w]+$\"},\n",
    "            \"population\": {\"type\": \"integer\"},\n",
    "        },\n",
    "        \"required\": [\"name\", \"population\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# JSON\n",
    "text = tokenizer.apply_chat_template(text, tokenize=False, add_generation_prompt=True)\n",
    "response = requests.post(\n",
    "    f\"http://localhost:{port}/generate\",\n",
    "    json={\n",
    "        \"text\": text,\n",
    "        \"sampling_params\": {\n",
    "            \"temperature\": 0,\n",
    "            \"max_new_tokens\": 2048,\n",
    "            \"json_schema\": json_schema,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "print_highlight(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:40:01.777943Z",
     "iopub.status.busy": "2025-04-14T22:40:01.777613Z",
     "iopub.status.idle": "2025-04-14T22:40:24.167193Z",
     "shell.execute_reply": "2025-04-14T22:40:24.166710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:01 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, \n",
      "[2025-04-14 22:40:01 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:02 TP0] Decode batch. #running-req: 3, #token: 41, token usage: 0.00, gen throughput (token/s): 86.37, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:02 TP0] Decode batch. #running-req: 3, #token: 161, token usage: 0.01, gen throughput (token/s): 285.74, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:02 TP0] Decode batch. #running-req: 3, #token: 281, token usage: 0.01, gen throughput (token/s): 293.30, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:03 TP0] Decode batch. #running-req: 3, #token: 401, token usage: 0.02, gen throughput (token/s): 286.39, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:03 TP0] Decode batch. #running-req: 3, #token: 521, token usage: 0.03, gen throughput (token/s): 270.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:04 TP0] Decode batch. #running-req: 3, #token: 641, token usage: 0.03, gen throughput (token/s): 276.79, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:04 TP0] Decode batch. #running-req: 3, #token: 761, token usage: 0.04, gen throughput (token/s): 271.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:05 TP0] Decode batch. #running-req: 3, #token: 881, token usage: 0.04, gen throughput (token/s): 271.70, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:05 TP0] Decode batch. #running-req: 3, #token: 1001, token usage: 0.05, gen throughput (token/s): 263.58, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:06 TP0] Decode batch. #running-req: 3, #token: 1121, token usage: 0.05, gen throughput (token/s): 286.90, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:06 TP0] Decode batch. #running-req: 3, #token: 1241, token usage: 0.06, gen throughput (token/s): 278.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:06 TP0] Decode batch. #running-req: 3, #token: 1361, token usage: 0.07, gen throughput (token/s): 275.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:07 TP0] Decode batch. #running-req: 3, #token: 1481, token usage: 0.07, gen throughput (token/s): 279.89, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:07 TP0] Decode batch. #running-req: 3, #token: 1601, token usage: 0.08, gen throughput (token/s): 272.04, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:08 TP0] Decode batch. #running-req: 3, #token: 1721, token usage: 0.08, gen throughput (token/s): 284.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:08 TP0] Decode batch. #running-req: 3, #token: 1841, token usage: 0.09, gen throughput (token/s): 278.23, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:09 TP0] Decode batch. #running-req: 3, #token: 1961, token usage: 0.10, gen throughput (token/s): 271.37, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:09 TP0] Decode batch. #running-req: 3, #token: 2081, token usage: 0.10, gen throughput (token/s): 277.10, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:09 TP0] Decode batch. #running-req: 3, #token: 2201, token usage: 0.11, gen throughput (token/s): 282.60, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:10 TP0] Decode batch. #running-req: 3, #token: 2321, token usage: 0.11, gen throughput (token/s): 275.70, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:10 TP0] Decode batch. #running-req: 3, #token: 2441, token usage: 0.12, gen throughput (token/s): 277.41, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:11 TP0] Decode batch. #running-req: 3, #token: 2561, token usage: 0.13, gen throughput (token/s): 272.55, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:11 TP0] Decode batch. #running-req: 3, #token: 2681, token usage: 0.13, gen throughput (token/s): 284.01, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:12 TP0] Decode batch. #running-req: 3, #token: 2801, token usage: 0.14, gen throughput (token/s): 277.84, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:12 TP0] Decode batch. #running-req: 3, #token: 2921, token usage: 0.14, gen throughput (token/s): 270.92, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:12 TP0] Decode batch. #running-req: 3, #token: 3041, token usage: 0.15, gen throughput (token/s): 286.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:13 TP0] Decode batch. #running-req: 3, #token: 3161, token usage: 0.15, gen throughput (token/s): 271.47, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:13 TP0] Decode batch. #running-req: 3, #token: 3281, token usage: 0.16, gen throughput (token/s): 284.79, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:14 TP0] Decode batch. #running-req: 3, #token: 3401, token usage: 0.17, gen throughput (token/s): 268.14, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:14 TP0] Decode batch. #running-req: 3, #token: 3521, token usage: 0.17, gen throughput (token/s): 282.52, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:15 TP0] Decode batch. #running-req: 3, #token: 3641, token usage: 0.18, gen throughput (token/s): 271.82, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:15 TP0] Decode batch. #running-req: 3, #token: 3761, token usage: 0.18, gen throughput (token/s): 285.76, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:15 TP0] Decode batch. #running-req: 3, #token: 3881, token usage: 0.19, gen throughput (token/s): 278.42, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:16 TP0] Decode batch. #running-req: 3, #token: 4001, token usage: 0.20, gen throughput (token/s): 278.04, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:16 TP0] Decode batch. #running-req: 3, #token: 4121, token usage: 0.20, gen throughput (token/s): 279.50, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:17 TP0] Decode batch. #running-req: 3, #token: 4241, token usage: 0.21, gen throughput (token/s): 272.93, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:17 TP0] Decode batch. #running-req: 3, #token: 4361, token usage: 0.21, gen throughput (token/s): 278.28, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:18 TP0] Decode batch. #running-req: 3, #token: 4481, token usage: 0.22, gen throughput (token/s): 269.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:18 TP0] Decode batch. #running-req: 3, #token: 4601, token usage: 0.22, gen throughput (token/s): 274.60, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:19 TP0] Decode batch. #running-req: 3, #token: 4721, token usage: 0.23, gen throughput (token/s): 275.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:19 TP0] Decode batch. #running-req: 3, #token: 4841, token usage: 0.24, gen throughput (token/s): 283.08, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:19 TP0] Decode batch. #running-req: 3, #token: 4961, token usage: 0.24, gen throughput (token/s): 271.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:20 TP0] Decode batch. #running-req: 3, #token: 5081, token usage: 0.25, gen throughput (token/s): 276.73, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:20 TP0] Decode batch. #running-req: 3, #token: 5201, token usage: 0.25, gen throughput (token/s): 275.63, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:21 TP0] Decode batch. #running-req: 3, #token: 5321, token usage: 0.26, gen throughput (token/s): 278.59, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:21 TP0] Decode batch. #running-req: 3, #token: 5441, token usage: 0.27, gen throughput (token/s): 288.12, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:22 TP0] Decode batch. #running-req: 3, #token: 5561, token usage: 0.27, gen throughput (token/s): 281.47, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:22 TP0] Decode batch. #running-req: 3, #token: 5681, token usage: 0.28, gen throughput (token/s): 281.45, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:22 TP0] Decode batch. #running-req: 3, #token: 5801, token usage: 0.28, gen throughput (token/s): 281.03, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:23 TP0] Decode batch. #running-req: 3, #token: 5921, token usage: 0.29, gen throughput (token/s): 273.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:23 TP0] Decode batch. #running-req: 3, #token: 6041, token usage: 0.29, gen throughput (token/s): 284.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:24] INFO:     127.0.0.1:37238 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[{'text': \"600 words.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bour\", 'meta_info': {'id': 'd1f679d3c34f4ab8875bf0b3152ddd69', 'finish_reason': {'type': 'length', 'length': 2048}, 'prompt_tokens': 11, 'completion_tokens': 2048, 'cached_tokens': 10, 'e2e_latency': 22.38086438179016}}, {'text': \"600 words.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bour\", 'meta_info': {'id': 'e6bfa6708aab42e6b08dadd722b9cb94', 'finish_reason': {'type': 'length', 'length': 2048}, 'prompt_tokens': 11, 'completion_tokens': 2048, 'cached_tokens': 10, 'e2e_latency': 22.38087511062622}}, {'text': \"600 words.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bourguignon being some of the most popular. The city is surrounded by the Seine River, which flows through it, and the bridges over the river add to the city's charm. Paris is a vibrant city with a mix of old-world charm and modern innovation, making it a unique and fascinating place to visit.\\n\\nThe capital of France is Paris. Paris is one of the most important cities in the world, and it's also the political, cultural, and economic center of France. The city has a rich history that dates back to ancient times, and it's known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Arc de Triomphe. Paris is also famous for its cuisine, with dishes like baguette, croissant, and boeuf bour\", 'meta_info': {'id': 'a3c4517597f643e7a093632db16d3a72', 'finish_reason': {'type': 'length', 'length': 2048}, 'prompt_tokens': 11, 'completion_tokens': 2048, 'cached_tokens': 10, 'e2e_latency': 22.380879402160645}}]\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    f\"http://localhost:{port}/generate\",\n",
    "    json={\n",
    "        \"text\": \"Give me the information of the capital of France.\",\n",
    "        \"sampling_params\": {\n",
    "            \"max_new_tokens\": 2048,\n",
    "            \"temperature\": 0,\n",
    "            \"n\": 3,\n",
    "            \"ebnf\": (\n",
    "                \"root ::= city | description\\n\"\n",
    "                'city ::= \"London\" | \"Paris\" | \"Berlin\" | \"Rome\"\\n'\n",
    "                'description ::= city \" is \" status\\n'\n",
    "                'status ::= \"the capital of \" country\\n'\n",
    "                'country ::= \"England\" | \"France\" | \"Germany\" | \"Italy\"'\n",
    "            ),\n",
    "        },\n",
    "        \"stream\": False,\n",
    "        \"return_logprob\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:40:24.169258Z",
     "iopub.status.busy": "2025-04-14T22:40:24.168936Z",
     "iopub.status.idle": "2025-04-14T22:40:44.891308Z",
     "shell.execute_reply": "2025-04-14T22:40:44.890825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:24 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, \n",
      "[2025-04-14 22:40:24 TP0] Decode batch. #running-req: 1, #token: 8, token usage: 0.00, gen throughput (token/s): 256.35, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:24 TP0] Decode batch. #running-req: 1, #token: 48, token usage: 0.00, gen throughput (token/s): 99.71, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:25 TP0] Decode batch. #running-req: 1, #token: 88, token usage: 0.00, gen throughput (token/s): 99.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:25 TP0] Decode batch. #running-req: 1, #token: 128, token usage: 0.01, gen throughput (token/s): 99.79, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:25 TP0] Decode batch. #running-req: 1, #token: 168, token usage: 0.01, gen throughput (token/s): 98.38, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:26 TP0] Decode batch. #running-req: 1, #token: 208, token usage: 0.01, gen throughput (token/s): 96.55, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:26 TP0] Decode batch. #running-req: 1, #token: 248, token usage: 0.01, gen throughput (token/s): 98.26, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:27 TP0] Decode batch. #running-req: 1, #token: 288, token usage: 0.01, gen throughput (token/s): 98.79, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:27 TP0] Decode batch. #running-req: 1, #token: 328, token usage: 0.02, gen throughput (token/s): 102.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:27 TP0] Decode batch. #running-req: 1, #token: 368, token usage: 0.02, gen throughput (token/s): 97.24, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:28 TP0] Decode batch. #running-req: 1, #token: 408, token usage: 0.02, gen throughput (token/s): 102.18, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:28 TP0] Decode batch. #running-req: 1, #token: 448, token usage: 0.02, gen throughput (token/s): 97.70, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:29 TP0] Decode batch. #running-req: 1, #token: 488, token usage: 0.02, gen throughput (token/s): 100.05, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:29 TP0] Decode batch. #running-req: 1, #token: 528, token usage: 0.03, gen throughput (token/s): 100.12, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:29 TP0] Decode batch. #running-req: 1, #token: 568, token usage: 0.03, gen throughput (token/s): 99.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:30 TP0] Decode batch. #running-req: 1, #token: 608, token usage: 0.03, gen throughput (token/s): 101.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:30 TP0] Decode batch. #running-req: 1, #token: 648, token usage: 0.03, gen throughput (token/s): 99.27, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:31 TP0] Decode batch. #running-req: 1, #token: 688, token usage: 0.03, gen throughput (token/s): 96.23, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:31 TP0] Decode batch. #running-req: 1, #token: 728, token usage: 0.04, gen throughput (token/s): 98.50, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:31 TP0] Decode batch. #running-req: 1, #token: 768, token usage: 0.04, gen throughput (token/s): 100.73, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:32 TP0] Decode batch. #running-req: 1, #token: 808, token usage: 0.04, gen throughput (token/s): 98.61, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:32 TP0] Decode batch. #running-req: 1, #token: 848, token usage: 0.04, gen throughput (token/s): 98.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:33 TP0] Decode batch. #running-req: 1, #token: 888, token usage: 0.04, gen throughput (token/s): 96.45, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:33 TP0] Decode batch. #running-req: 1, #token: 928, token usage: 0.05, gen throughput (token/s): 98.43, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:33 TP0] Decode batch. #running-req: 1, #token: 968, token usage: 0.05, gen throughput (token/s): 98.26, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:34 TP0] Decode batch. #running-req: 1, #token: 1008, token usage: 0.05, gen throughput (token/s): 100.86, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:34 TP0] Decode batch. #running-req: 1, #token: 1048, token usage: 0.05, gen throughput (token/s): 96.37, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:35 TP0] Decode batch. #running-req: 1, #token: 1088, token usage: 0.05, gen throughput (token/s): 99.17, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:35 TP0] Decode batch. #running-req: 1, #token: 1128, token usage: 0.06, gen throughput (token/s): 99.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:35 TP0] Decode batch. #running-req: 1, #token: 1168, token usage: 0.06, gen throughput (token/s): 101.47, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:36 TP0] Decode batch. #running-req: 1, #token: 1208, token usage: 0.06, gen throughput (token/s): 99.54, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:36 TP0] Decode batch. #running-req: 1, #token: 1248, token usage: 0.06, gen throughput (token/s): 97.13, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:37 TP0] Decode batch. #running-req: 1, #token: 1288, token usage: 0.06, gen throughput (token/s): 99.30, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:37 TP0] Decode batch. #running-req: 1, #token: 1328, token usage: 0.06, gen throughput (token/s): 101.63, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:37 TP0] Decode batch. #running-req: 1, #token: 1368, token usage: 0.07, gen throughput (token/s): 100.19, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:38 TP0] Decode batch. #running-req: 1, #token: 1408, token usage: 0.07, gen throughput (token/s): 96.81, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:38 TP0] Decode batch. #running-req: 1, #token: 1448, token usage: 0.07, gen throughput (token/s): 101.34, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:39 TP0] Decode batch. #running-req: 1, #token: 1488, token usage: 0.07, gen throughput (token/s): 97.26, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:39 TP0] Decode batch. #running-req: 1, #token: 1528, token usage: 0.07, gen throughput (token/s): 96.67, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:39 TP0] Decode batch. #running-req: 1, #token: 1568, token usage: 0.08, gen throughput (token/s): 102.04, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:40 TP0] Decode batch. #running-req: 1, #token: 1608, token usage: 0.08, gen throughput (token/s): 99.68, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:40 TP0] Decode batch. #running-req: 1, #token: 1648, token usage: 0.08, gen throughput (token/s): 97.07, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:41 TP0] Decode batch. #running-req: 1, #token: 1688, token usage: 0.08, gen throughput (token/s): 101.57, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:41 TP0] Decode batch. #running-req: 1, #token: 1728, token usage: 0.08, gen throughput (token/s): 99.29, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:41 TP0] Decode batch. #running-req: 1, #token: 1768, token usage: 0.09, gen throughput (token/s): 98.04, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:42 TP0] Decode batch. #running-req: 1, #token: 1808, token usage: 0.09, gen throughput (token/s): 95.76, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:42 TP0] Decode batch. #running-req: 1, #token: 1848, token usage: 0.09, gen throughput (token/s): 98.11, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:43 TP0] Decode batch. #running-req: 1, #token: 1888, token usage: 0.09, gen throughput (token/s): 98.37, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:43 TP0] Decode batch. #running-req: 1, #token: 1928, token usage: 0.09, gen throughput (token/s): 99.42, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:44 TP0] Decode batch. #running-req: 1, #token: 1968, token usage: 0.10, gen throughput (token/s): 99.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:44 TP0] Decode batch. #running-req: 1, #token: 2008, token usage: 0.10, gen throughput (token/s): 100.05, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:44 TP0] Decode batch. #running-req: 1, #token: 2048, token usage: 0.10, gen throughput (token/s): 95.85, #queue-req: 0, \n",
      "[2025-04-14 22:40:44] INFO:     127.0.0.1:37664 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "{'text': ' the \\\\( n \\\\9121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121', 'meta_info': {'id': '93f15f720c8f4b24b8c0e219a5d0f05b', 'finish_reason': {'type': 'length', 'length': 2048}, 'prompt_tokens': 6, 'completion_tokens': 2048, 'cached_tokens': 1, 'e2e_latency': 20.71502995491028}}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    f\"http://localhost:{port}/generate\",\n",
    "    json={\n",
    "        \"text\": \"Paris is the capital of\",\n",
    "        \"sampling_params\": {\n",
    "            \"temperature\": 0,\n",
    "            \"max_new_tokens\": 2048,\n",
    "            \"regex\": \"(France|England)\",\n",
    "        },\n",
    "    },\n",
    ")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:40:44.893283Z",
     "iopub.status.busy": "2025-04-14T22:40:44.892878Z",
     "iopub.status.idle": "2025-04-14T22:40:56.179134Z",
     "shell.execute_reply": "2025-04-14T22:40:56.178714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 19, token usage: 0.00, #running-req: 0, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:45 TP0] Decode batch. #running-req: 1, #token: 54, token usage: 0.00, gen throughput (token/s): 93.98, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:45 TP0] Decode batch. #running-req: 1, #token: 94, token usage: 0.00, gen throughput (token/s): 95.85, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:46 TP0] Decode batch. #running-req: 1, #token: 134, token usage: 0.01, gen throughput (token/s): 97.69, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:46 TP0] Decode batch. #running-req: 1, #token: 174, token usage: 0.01, gen throughput (token/s): 97.46, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:46 TP0] Decode batch. #running-req: 1, #token: 214, token usage: 0.01, gen throughput (token/s): 97.05, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:47 TP0] Decode batch. #running-req: 1, #token: 254, token usage: 0.01, gen throughput (token/s): 99.71, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:47 TP0] Decode batch. #running-req: 1, #token: 294, token usage: 0.01, gen throughput (token/s): 96.51, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:48 TP0] Decode batch. #running-req: 1, #token: 334, token usage: 0.02, gen throughput (token/s): 97.59, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:48 TP0] Decode batch. #running-req: 1, #token: 374, token usage: 0.02, gen throughput (token/s): 98.28, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:48 TP0] Decode batch. #running-req: 1, #token: 414, token usage: 0.02, gen throughput (token/s): 95.05, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:49 TP0] Decode batch. #running-req: 1, #token: 454, token usage: 0.02, gen throughput (token/s): 96.77, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:49 TP0] Decode batch. #running-req: 1, #token: 494, token usage: 0.02, gen throughput (token/s): 97.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:50 TP0] Decode batch. #running-req: 1, #token: 534, token usage: 0.03, gen throughput (token/s): 99.94, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:50 TP0] Decode batch. #running-req: 1, #token: 574, token usage: 0.03, gen throughput (token/s): 99.32, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:51 TP0] Decode batch. #running-req: 1, #token: 614, token usage: 0.03, gen throughput (token/s): 95.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:51 TP0] Decode batch. #running-req: 1, #token: 654, token usage: 0.03, gen throughput (token/s): 98.75, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:51 TP0] Decode batch. #running-req: 1, #token: 694, token usage: 0.03, gen throughput (token/s): 95.02, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:52 TP0] Decode batch. #running-req: 1, #token: 734, token usage: 0.04, gen throughput (token/s): 95.98, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:52 TP0] Decode batch. #running-req: 1, #token: 774, token usage: 0.04, gen throughput (token/s): 99.20, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:53 TP0] Decode batch. #running-req: 1, #token: 814, token usage: 0.04, gen throughput (token/s): 97.97, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:53 TP0] Decode batch. #running-req: 1, #token: 854, token usage: 0.04, gen throughput (token/s): 97.21, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:53 TP0] Decode batch. #running-req: 1, #token: 894, token usage: 0.04, gen throughput (token/s): 97.37, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:54 TP0] Decode batch. #running-req: 1, #token: 934, token usage: 0.05, gen throughput (token/s): 94.90, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:54 TP0] Decode batch. #running-req: 1, #token: 974, token usage: 0.05, gen throughput (token/s): 95.81, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:55 TP0] Decode batch. #running-req: 1, #token: 1014, token usage: 0.05, gen throughput (token/s): 96.06, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:55 TP0] Decode batch. #running-req: 1, #token: 1054, token usage: 0.05, gen throughput (token/s): 99.89, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:55 TP0] Decode batch. #running-req: 1, #token: 1094, token usage: 0.05, gen throughput (token/s): 97.00, #queue-req: 0, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:56] INFO:     127.0.0.1:47510 - \"POST /generate HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{'text': 'Okay, I need to create a JSON object about Paris, the capital of France. Let me think about what information should be included. Hmm, I know Paris is the capital, so I\\'ll note that. It\\'s located in Île-de-France, France, so I should include the region and country. As the capital, what else is important? Maybe its prominence status, so Paris is definitely a global city. \\n\\nWhat languages are spoken there? I think French is the main language, but several others are also spoken. French culture is a big part of its identity, so that\\'s important. I should include that. The flags are a good point; Paris has both the French tricolore and the European Union flag because it\\'s the EU\\'s sins exam location. \\n\\nMajor landmarks like the Eiffel Tower, the Louvre, and Notre-Dame definitely deserve mentions. What aboutinity of notable people? I can list a few like Philippe de V games, but better find their nationalities to be accurate. Maybe someone from France and someone else... Wait, Dany歌声 is European but associated with France in his work. I\\'ll list countries, fortunately, not nationalities.\\n\\nClimate-wise, Paris has a temperate continental climate, so that\\'s a good point. Government info is needed, including president andInteriorMinister. Let me ensure it\\'s up to date—I think President马克龙 is current, and储存sher_SEPARATORSébastien_SDK bien? minister François-Xavier performed the latest Quebec government. Wait, no, President马克龙 is Elysee, and minister would be from Canter ETI. I think the date is March 2023, as of now. \\n\\n הולדתP number of articles: maybe US is 100, Germany 80, Russia 35, Japan 120. Those are general readership ratings. Surface area in km²—Paris is a big city, but not the largest. Population I think is around 2.2 million, excluding theGreater paris area which is larger. \\n\\nDist区Name like le Marais, Latin Quarter, Montmartre, Latin Quarter. These are key areas to highlight. Leaving other data tactually solid. Let me organize all this into a JSON structure with proper keys and formatting. I think that\\'s all the info I can recall. It\\'s important to present it clearly and accurately.\\n</think>\\n\\nHere is the JSON object containing information about Paris, the capital of France:\\n\\n```json\\n{\\n  \"Name\": \"巴黎\",\\n  \"Region\": \"Île-de-France\",\\n  \"Country\": \"France\",\\n  \"ProminenceStatus\": \"Global City\",\\n  \"LanguagesSpoken\": [\"French\", \"Mandarin Chinese\", \"German\", \"Spanish\"],\\n  \"Culture\": \"French culture\",\\n  \"National flag\": {\\n    \"Description\": \"The Tricolore\",\\n    \"Colors\": [\"blue\", \"white\", \"red\"],\\n    \" Motto\": \"Je ne suis pas un weak-end ! J\\'ami\",\\n    \"Motологии\": [\"Etoil\", \"Vagents\", \"Frogne\"]\\n\\n  },\\n  \"這是\": [\"Eiffel Tower\", \"Louvre Museum\", \"Notre-Dame Cathedral\", \"Palace of Versailles\", \" Moses Temple\"],\\n  \"Major\": [\"Jacques Ch Retinard\", \"Pierre-Auguste Renoir\", \"Henri Godon\", \"Emile Bernard\", \"César Milhaud\"],\\n  \"Geography\": {\\n    \"Climate\": \"Temperate continental\",\\n    \"Coordinates\": {\\n      \"Latitude\": \"48.8566° N\",\\n      \"Longitude\": \"2.3522° E\"\\n    }\\n  },\\n  \"Government\": {\\n    \"President\": \"马克龙\",\\n    \"OfficeHolderName\": \" François-Xavier Simon Faure\",\\n    \"Position\": \"Minister of the Interior\"\\n  },\\n  \"Demographics\": {\\n    \"Population\": \"2,143,325\",\\n    \"ysters Living\": 100,\\n    \"ArtistsInterests\": 80,\\n    \"SportsEnthusiasts\": 35,\\n    \"奖学金Holders\": 120\\n  },\\n  \"Lingustics\": {\\n    \"OfficialLanguage\": \"French\",\\n    \"OtherLanguagesSpoken\": [\"Mandarin Chinese\", \"Spanish\", \"German\", \"Russian\", \"Japanese\"]\\n  },\\n  \"Economy\": {\\n    \"GDP\": \"2,198.19 Bn EUR\",\\n    \" bailout\": \"No bailout\",\\n    \" exportImport\": \"出口商品\",\\n    \" 主导Industry\": [\"Manufacturing\", \"Agriculture\", \" Services\"]\\n  },\\n  \"Historical\": {\\n    \"MajorLandmark\": [\"Le Marais\", \"Latin Quarter\", \"Montmartre\", \" Saint-Germain-des-Prés\"],\\n    \"FamousPeople\": [\" CONTROL:(); Philip-Émile de Valois\", \" CONTROL:]; Pierre-Auguste Renoir\", \" Henry Godon\", \" Emile Bernard\", \" César Milhaud\"]\\n  }\\n}\\n```\\n\\nThis JSON object includes key information about Paris, such as its geographical location, notable landmarks, languages spoken, culture, flags, and more.', 'meta_info': {'id': '2c2b3b910fd748fd9ae4cbab7d572fe6', 'finish_reason': {'type': 'stop', 'matched': 151643}, 'prompt_tokens': 20, 'completion_tokens': 1095, 'cached_tokens': 19, 'e2e_latency': 11.276017427444458}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "payload = {\n",
    "    \"text\": text,\n",
    "    \"sampling_params\": {\n",
    "        \"max_new_tokens\": 2048,\n",
    "        \"structural_tag\": json.dumps(\n",
    "            {\n",
    "                \"type\": \"structural_tag\",\n",
    "                \"structures\": [\n",
    "                    {\n",
    "                        \"begin\": \"<function=get_current_weather>\",\n",
    "                        \"schema\": schema_get_current_weather,\n",
    "                        \"end\": \"</function>\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"begin\": \"<function=get_current_date>\",\n",
    "                        \"schema\": schema_get_current_date,\n",
    "                        \"end\": \"</function>\",\n",
    "                    },\n",
    "                ],\n",
    "                \"triggers\": [\"<function=\"],\n",
    "            }\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# Send POST request to the API endpoint\n",
    "response = requests.post(f\"http://localhost:{port}/generate\", json=payload)\n",
    "print_highlight(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:40:56.180826Z",
     "iopub.status.busy": "2025-04-14T22:40:56.180582Z",
     "iopub.status.idle": "2025-04-14T22:40:56.196196Z",
     "shell.execute_reply": "2025-04-14T22:40:56.195690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 22:40:56] Child process unexpectedly failed with an exit code 9. pid=3951278\n"
     ]
    }
   ],
   "source": [
    "terminate_process(server_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Engine API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:40:56.198157Z",
     "iopub.status.busy": "2025-04-14T22:40:56.197871Z",
     "iopub.status.idle": "2025-04-14T22:41:14.371153Z",
     "shell.execute_reply": "2025-04-14T22:41:14.370247Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.37s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.30s/it]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.31s/it]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sglang as sgl\n",
    "\n",
    "llm = sgl.Engine(\n",
    "    model_path=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    reasoning_parser=\"deepseek-r1\",\n",
    "    grammar_backend=\"xgrammar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Pydantic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:41:14.373589Z",
     "iopub.status.busy": "2025-04-14T22:41:14.373363Z",
     "iopub.status.idle": "2025-04-14T22:41:41.378924Z",
     "shell.execute_reply": "2025-04-14T22:41:41.378289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: Give me the information of the capital of China in the JSON format.\n",
      "Generated text:  and also, make sure that the JSON is valid.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"name\": \"Beijing\",\n",
      "  \"population\": 10000000,\n",
      "  \"area\": 100000,\n",
      "  \"founded\": 1500,\n",
      "  \"coordinates\": {\n",
      "    \"latitude\": \"40.4168\",\n",
      "    \"longitude\": \"-73.9352\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Is this JSON valid? If not, explain why.\n",
      "\n",
      "If it is valid, explain why.\n",
      "\n",
      "Also, provide an updated version of the JSON with any necessary corrections.\n",
      "</think>{\n",
      "\n",
      "\"name\": \"Beijing\",\n",
      "\"population\": 1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "===============================\n",
      "Prompt: Give me the information of the capital of France in the JSON format.\n",
      "Generated text:  and then convert that JSON into a JSONP object.\n",
      "\n",
      "Also, create a JSON array containing 5 different cities in France, each with their population and area.\n",
      "\n",
      "Finally, create a JSON object that contains both the information of the capital and the array of 5 cities.\n",
      "\n",
      "Make sure to include all the required fields: for the city info, it's name, country, population, area, and the capital flag. For the array, each city should have name, population, and area.\n",
      "\n",
      "Alright, so I need to figure out how to structure this JSON data. Let me start by recalling what the user is asking for. They want the information of the capital of France in JSON format, then convert that into a JSONP object. Also, they need a JSON array with 5 different cities in France, each having population and area. Finally, they want a JSON object that combines both the capital info and the array of cities.\n",
      "\n",
      "First, I should identify the capital of France. I know that Paris is the capital. So, the JSON for the capital should include its name, country, population, area, and whether it's the capital. Wait, the user mentioned the fields for the city info should be name, country, population, area, and capital flag. So, the JSON for the capital would look like:\n",
      "\n",
      "{\n",
      "  \"name\": \"Paris\",\n",
      "  \"country\": \"France\",\n",
      "  \"population\": 1000000, // I'm not sure about the exact number, but for example's sake, let's say 1 million.\n",
      "  \"area\": 100000, // Again, approximate values.\n",
      "  \"capital\": true\n",
      "}\n",
      "\n",
      "Next, I need to convert this into a JSONP object. JSONP typically wraps the JSON in a function and adds a \"func\" key. So, it would look like:\n",
      "\n",
      "{\n",
      "  \"func\": function() {\n",
      "    return {\n",
      "      \"name\": \"Paris\",\n",
      "      \"country\": \"France\",\n",
      "      \"population\": 1000000,\n",
      "      \"area\": 100000,\n",
      "      \"capital\": true\n",
      "    };\n",
      "  }\n",
      "}\n",
      "\n",
      "Wait, but JSONP often uses a function that returns the JSON object. So, the structure is correct.\n",
      "\n",
      "Now, moving on to the array of 5 cities in France. I need to list 5 cities, each with their population and area. I should pick well-known cities to make it accurate. Let me think of some major cities in France:\n",
      "\n",
      "1. Lyon\n",
      "2. Marseille\n",
      "3. Toulouse\n",
      "4. Lille\n",
      "5. Nîmes\n",
      "\n",
      "I need to find their approximate populations and areas. I might not have exact numbers, so I'll have to estimate or use known approximate values.\n",
      "\n",
      "- Lyon: Population around 400,000, area about 100 square kilometers.\n",
      "- Marseille: Population around 600,000, area about 150 square kilometers.\n",
      "- Toulouse: Population around 300,000, area about 120 square kilometers.\n",
      "- Lille: Population around 450,000, area about 110 square kilometers.\n",
      "- Nîmes: Population around 250,000, area about 80 square kilometers.\n",
      "\n",
      "So, the JSON array would be:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Lyon\",\n",
      "    \"population\": 400000,\n",
      "    \"area\": 100\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Marseille\",\n",
      "    \"population\": 600000,\n",
      "    \"area\": 150\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Toulouse\",\n",
      "    \"population\": 300000,\n",
      "    \"area\": 120\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Lille\",\n",
      "    \"population\": 450000,\n",
      "    \"area\": 110\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Nîmes\",\n",
      "    \"population\": 250000,\n",
      "    \"area\": 80\n",
      "  }\n",
      "]\n",
      "\n",
      "Now, the final part is to create a JSON object that combines both the capital info and this array. So, the top-level object will have a key, say \"data\", which contains two keys: \"capital\" and \"cities\". The \"capital\" will be the JSON object we created earlier, and \"cities\" will be the array.\n",
      "\n",
      "Putting it all together, the JSON would look like:\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"capital\": {\n",
      "      \"name\": \"Paris\",\n",
      "      \"country\": \"France\",\n",
      "      \"population\": 1000000,\n",
      "      \"area\": 100000,\n",
      "      \"capital\": true\n",
      "    },\n",
      "    \"cities\": [\n",
      "      {\n",
      "        \"name\": \"Lyon\",\n",
      "        \"population\": 400000,\n",
      "        \"area\": 100\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Marseille\",\n",
      "        \"population\": 600000,\n",
      "        \"area\": 150\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Toulouse\",\n",
      "        \"population\": 300000,\n",
      "        \"area\": 120\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Lille\",\n",
      "        \"population\": 450000,\n",
      "        \"area\": 110\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Nîmes\",\n",
      "        \"population\": 250000,\n",
      "        \"area\": 80\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "I should double-check the fields to ensure all required ones are included. For the capital, name, country, population, area, and capital flag are all there. For each city, name, population, and area are included. The structure seems correct.\n",
      "\n",
      "I also need to make sure that the JSON is properly formatted, with commas in the right places and brackets closed properly. I think I've got that covered.\n",
      "\n",
      "Lastly, I should consider if the population and area numbers are realistic. For example, Paris's population is definitely over 2 million, so 1 million might be too low. Similarly, its area is around 100 square kilometers, which seems accurate. I might want to adjust those numbers if I had more precise data, but for the sake of this exercise, these estimates should suffice.\n",
      "\n",
      "Overall, I think I've covered all the requirements: created the JSON for the capital, converted it to JSONP, made an array of cities, and combined them into a single JSON object. I just need to present this in the correct format without any markdown, as per the instructions.\n",
      "</think>{\n",
      "\n",
      "\"name\": \"Paris\",\n",
      "\"population\": 200000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "===============================\n",
      "Prompt: Give me the information of the capital of Ireland in the JSON format.\n",
      "Generated text:  and also, add a \"description\" field that explains what the capital is like.\n",
      "\n",
      "The capital of Ireland is calledDublin. It's located in the north of Ireland, and is known for its vibrant city life, beautiful streets, and famous landmarks like the SSE St. Patrick's Cathedral and the...\n",
      "Okay, I need to provide information about the capital of Ireland, which is Dublin, in JSON format. I also need to include a \"description\" field that explains what Dublin is like. Let me start by recalling the key points about Dublin.\n",
      "\n",
      "First, the capital is Dublin itself. It's located in the north of Ireland. Dublin is known for its vibrant city life, which means it's lively and dynamic. The streets are beautiful, lined with elegant buildings and greenery. There are several famous landmarks, such as the SSE St. Patrick's Cathedral, which is a prominent religious site. The city also has the famous Guinness Tower, which houses the world's largest bar. Other notable landmarks include the Phoenix Park, which is a large green space with museums and attractions, and the SSE Arena, where many sports events are held.\n",
      "\n",
      "Additionally, Dublin is known for its cultural and historical significance. It's the birthplace of JamesJoyce, a renowned author, and has a rich history dating back to medieval times. The city has a vibrant nightlife, with many pubs, clubs, and bars. It's also a major transportation hub, with good public transport options like buses and the Luas light rail system.\n",
      "\n",
      "Now, I should structure this information into a JSON format. The main information includes the name of the capital, its location, and some key landmarks and features. The \"description\" field should summarize the overall vibe and characteristics of Dublin.\n",
      "\n",
      "I should make sure the JSON is properly formatted with keys and values, and that the description is concise but informative. I'll list the landmarks and features as bullet points under the \"features\" key for clarity.\n",
      "\n",
      "Let me put it all together now.\n",
      "</think>{\n",
      "\n",
      "\"name\": \"Dublin\",\n",
      "\"population\": 50000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "prompts = [\n",
    "    \"Give me the information of the capital of China in the JSON format.\",\n",
    "    \"Give me the information of the capital of France in the JSON format.\",\n",
    "    \"Give me the information of the capital of Ireland in the JSON format.\",\n",
    "]\n",
    "\n",
    "\n",
    "# Define the schema using Pydantic\n",
    "class CapitalInfo(BaseModel):\n",
    "    name: str = Field(..., pattern=r\"^\\w+$\", description=\"Name of the capital city\")\n",
    "    population: int = Field(..., description=\"Population of the capital city\")\n",
    "\n",
    "\n",
    "sampling_params = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"max_new_tokens\": 2048,\n",
    "    \"json_schema\": json.dumps(CapitalInfo.model_json_schema()),\n",
    "}\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(f\"Prompt: {prompt}\\nGenerated text: {output['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON Schema Directly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:41:41.381057Z",
     "iopub.status.busy": "2025-04-14T22:41:41.380523Z",
     "iopub.status.idle": "2025-04-14T22:42:02.765226Z",
     "shell.execute_reply": "2025-04-14T22:42:02.764729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: Give me the information of the capital of China in the JSON format.\n",
      "Generated text:  and also, make sure that the JSON is valid.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"name\": \"Beijing\",\n",
      "  \"population\": 10000000,\n",
      "  \"area\": 100000,\n",
      "  \"founded\": 1500,\n",
      "  \"coordinates\": {\n",
      "    \"latitude\": \"40.4168\",\n",
      "    \"longitude\": \"-73.9352\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Is this JSON valid? If not, explain why.\n",
      "\n",
      "If it is valid, explain why.\n",
      "\n",
      "Also, provide an updated version of the JSON with any necessary corrections.\n",
      "</think>{\n",
      "\n",
      "\"name\": \"Beijing\",\n",
      "\"population\": 1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "===============================\n",
      "Prompt: Give me the information of the capital of France in the JSON format.\n",
      "Generated text:  and then convert that JSON into a JSONP object.\n",
      "\n",
      "Also, create a JSON array containing 5 different cities in France, each with their population and area.\n",
      "\n",
      "Finally, create a JSON object that contains both the information of the capital and the array of 5 cities.\n",
      "\n",
      "Make sure to include all the required fields: for the city info, it's name, country, population, and area. For the array, each city should have name, population, and area.\n",
      "\n",
      "Alright, so I need to figure out how to provide the information of the capital of France in JSON format, then convert that into a JSONP object. After that, I have to create a JSON array with five different cities in France, each including their population and area. Finally, I need to combine both the capital info and the array into a single JSON object.\n",
      "\n",
      "First, let me recall what the capital of France is. I think it's Paris. Yes, Paris is the capital city of France. Now, I need to find the population and area of Paris. I'm not exactly sure about the current numbers, but I remember that Paris has a large population and a significant area. Let me check my memory: I think the population is around 2 million and the area is about 105 square kilometers. I should verify these numbers to be accurate, but for the sake of this exercise, I'll go with these figures.\n",
      "\n",
      "Next, I need to represent this information in JSON format. The structure should include the name, country, population, and area. So, the JSON object for the capital would look like this:\n",
      "\n",
      "{\n",
      "  \"capital\": {\n",
      "    \"name\": \"Paris\",\n",
      "    \"country\": \"France\",\n",
      "    \"population\": 2000000,\n",
      "    \"area\": 105\n",
      "  }\n",
      "}\n",
      "\n",
      "Now, moving on to the JSONP object. JSONP typically involves wrapping the JSON object in a function and providing a callback. The syntax is usually function() { return JSON; }. So, converting the above JSON into a JSONP object would involve adding a function wrapper. It would look something like:\n",
      "\n",
      "function() {\n",
      "  return {\n",
      "    \"capital\": {\n",
      "      \"name\": \"Paris\",\n",
      "      \"country\": \"France\",\n",
      "      \"population\": 2000000,\n",
      "      \"area\": 105\n",
      "    }\n",
      "  };\n",
      "}\n",
      "\n",
      "I think that's the correct way to structure a JSONP object.\n",
      "\n",
      "Now, onto the second part: creating a JSON array of five different cities in France, each with their population and area. I need to choose five cities. Let me think of some major cities in France. I know Paris, but I need four more. Maybe Lyon, Marseille, Toulouse, and Nice? Or maybe I should include some other cities to make it diverse. Let me check their populations and areas.\n",
      "\n",
      "1. Paris: As mentioned, population around 2 million, area about 105 km².\n",
      "2. Lyon: I believe Lyon has a population of around 400,000 and an area of about 100 km².\n",
      "3. Marseille: Population is around 1.5 million, area about 100 km².\n",
      "4. Toulouse: Population is around 300,000, area about 100 km².\n",
      "5. Nice: Population is around 600,000, area about 200 km².\n",
      "\n",
      "Wait, I should verify these numbers because I might be off. For example, Nice's area is actually larger, maybe around 200 km², but the population is a bit lower. Let me adjust accordingly.\n",
      "\n",
      "So, the JSON array would look like this:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Paris\",\n",
      "    \"population\": 2000000,\n",
      "    \"area\": 105\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Lyon\",\n",
      "    \"population\": 400000,\n",
      "    \"area\": 100\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Marseille\",\n",
      "    \"population\": 1500000,\n",
      "    \"area\": 100\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Toulouse\",\n",
      "    \"population\": 300000,\n",
      "    \"area\": 100\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Nice\",\n",
      "    \"population\": 600000,\n",
      "    \"area\": 200\n",
      "  }\n",
      "]\n",
      "\n",
      "I think that's a reasonable approximation. Now, I need to combine both the capital info and this array into a single JSON object. The structure should have a key, say \"info\", which contains both the capital and the array. So, the final JSON object would be:\n",
      "\n",
      "{\n",
      "  \"info\": {\n",
      "    \"capital\": {\n",
      "      \"name\": \"Paris\",\n",
      "      \"country\": \"France\",\n",
      "      \"population\": 2000000,\n",
      "      \"area\": 105\n",
      "    },\n",
      "    \"cities\": [\n",
      "      {\n",
      "        \"name\": \"Paris\",\n",
      "        \"population\": 2000000,\n",
      "        \"area\": 105\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Lyon\",\n",
      "        \"population\": 400000,\n",
      "        \"area\": 100\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Marseille\",\n",
      "        \"population\": 1500000,\n",
      "        \"area\": 100\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Toulouse\",\n",
      "        \"population\": 300000,\n",
      "        \"area\": 100\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Nice\",\n",
      "        \"population\": 600000,\n",
      "        \"area\": 200\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "I should make sure that all the fields are correctly named and that the data types are appropriate. The populations and areas should be numbers, and the names should be strings. Also, I should ensure that the JSON syntax is correct, with proper commas and brackets.\n",
      "\n",
      "Wait, in the array, I have \"capital\" as one of the cities, which is Paris. That's okay because it's part of the array, but I should make sure that the array includes five different cities, and since Paris is the capital, it's included in both the capital info and the array. That's acceptable as per the problem statement.\n",
      "\n",
      "I think I've covered all the requirements. Now, I'll present the final answer with the JSON object containing both the capital information and the array of cities.\n",
      "</think>{\n",
      "\n",
      "\"name\": \"Paris\",\n",
      "\"population\": 2000000\n",
      "}\n",
      "===============================\n",
      "Prompt: Give me the information of the capital of Ireland in the JSON format.\n",
      "Generated text:  and also, in the JSON, include the population, area, and the official language.\n",
      "\n",
      "The capital of Ireland is ______.\n",
      "\n",
      "The population of Ireland is approximately 5 million. The area is about 9,400 square kilometers. The official language is English.\n",
      "\n",
      "Please provide the JSON structure with the key-value pairs.\n",
      "\n",
      "Okay, so I need to figure out how to provide the information about the capital of Ireland in JSON format. The user has already given me some details: the population is about 5 million, the area is approximately 9,400 square kilometers, and the official language is English. They also mentioned that the capital is ______, but I think I need to fill that in.\n",
      "\n",
      "First, I should recall what the capital of Ireland is. I'm pretty sure it's Dublin. Yeah, that's right. Dublin is the largest city in Ireland and serves as its administrative capital, even though Ireland is a constitutional monarchy and doesn't have a federal capital.\n",
      "\n",
      "Now, I need to structure this information into a JSON format. JSON typically uses key-value pairs, so I'll need to decide which keys to use. The user mentioned population, area, and official language, so I can include those. Also, since the capital is Dublin, I should include that as a key as well.\n",
      "\n",
      "So, the keys I'll use are probably \"capital\", \"population\", \"area\", and \"official_language\". Each of these will have their respective values. Let me make sure about the numbers. The population is approximately 5 million, so I'll write that as 5000000. The area is about 9,400 square kilometers, so that's 9400. The official language is English, so that's straightforward.\n",
      "\n",
      "Putting it all together, the JSON structure should look like this:\n",
      "\n",
      "{\n",
      "  \"capital\": \"Dublin\",\n",
      "  \"population\": 5000000,\n",
      "  \"area\": 9400,\n",
      "  \"official_language\": \"English\"\n",
      "}\n",
      "\n",
      "I think that covers everything the user asked for. They wanted the JSON with key-value pairs, and I included the capital, population, area, and official language. I should double-check if there are any other details they might need, but based on the information given, this should be sufficient.\n",
      "\n",
      "Wait, the user also mentioned that the population is approximately 5 million, the area is about 9,400 square kilometers, and the official language is English. I included all of these in the JSON. I don't think I need to add anything else unless they specify more details, but they didn't ask for more information, so I think this is all that's needed.\n",
      "\n",
      "I should also make sure that the JSON syntax is correct. The keys are in double quotes, the string values are in double quotes, and the numbers are without quotes. The commas are in the right places, and the structure is properly formatted. I don't see any syntax errors here.\n",
      "\n",
      "So, to summarize, the JSON object will have four key-value pairs: capital as \"Dublin\", population as 5000000, area as 9400, and official_language as \"English\". This should fulfill the user's request accurately.\n",
      "</think>{\n",
      "\n",
      "\"name\": \"Dublin\",\n",
      "\"population\": 5000000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Give me the information of the capital of China in the JSON format.\",\n",
    "    \"Give me the information of the capital of France in the JSON format.\",\n",
    "    \"Give me the information of the capital of Ireland in the JSON format.\",\n",
    "]\n",
    "\n",
    "json_schema = json.dumps(\n",
    "    {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\"type\": \"string\", \"pattern\": \"^[\\\\w]+$\"},\n",
    "            \"population\": {\"type\": \"integer\"},\n",
    "        },\n",
    "        \"required\": [\"name\", \"population\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "sampling_params = {\"temperature\": 0, \"max_new_tokens\": 2048, \"json_schema\": json_schema}\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(f\"Prompt: {prompt}\\nGenerated text: {output['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBNF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:42:02.766967Z",
     "iopub.status.busy": "2025-04-14T22:42:02.766705Z",
     "iopub.status.idle": "2025-04-14T22:42:04.185838Z",
     "shell.execute_reply": "2025-04-14T22:42:04.185340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: Give me the information of the capital of France.\n",
      "Generated text: 900 words minimum, include the geographical, economic, cultural, and political aspects. Also, include the history and famous landmarks.\n",
      "\n",
      "The user is a student who needs this for a school project.\n",
      "\n",
      "The user has already written a basic outline. So, I need to think about how to elaborate each section, add details, examples, and maybe some engaging points.\n",
      "\n",
      "I should avoid making it too lengthy, but still meet the 900-word minimum. Let me brainstorm each section step by-step, think about key points, and see how to expand them effectively.\n",
      "Okay, so the user needs information about the capital of France, which\n",
      "===============================\n",
      "Prompt: Give me the information of the capital of Germany.\n",
      "Generated text: 800 characters\n",
      "\n",
      "Alright, so the user is asking for information about the capital of Germany. I need to provide a comprehensive yet concise response within 800 characters. Let me start by identifying what the main parts of this information are.\n",
      "\n",
      "First, the name of the capital is Berlin. That's straightforward. Next, the official seat of government is Berlin City Hall, but the capital city proper is Berlin. I should clarify that distinction because sometimes people confuse the city with the government building.\n",
      "\n",
      "Now, the location-wise, Berlin is located in northeast Germany. I should mention the location coordinates so the user knows its exact position. The\n",
      "===============================\n",
      "Prompt: Give me the information of the capital of Italy.\n",
      "Generated text: 62\n",
      "\n",
      "The user is asking about the information of the capital of Italy. The capital of Italy is Rome. I should provide a detailed response about Rome.\n",
      "\n",
      "I can mention that Rome is located in central Italy, near the Apennine Mountains and the Italian coast. It's the heart of Italian culture, history, and art.\n",
      "\n",
      "I should highlight Rome's rich history, from ancient Rome through the Middle Ages to its role in the Renaissance, the Baroque period, and up to the present day.\n",
      "\n",
      "I can include aspects like its artistic and architectural heritage, such as landmarks like the Colosseum, the Vatican City, the Spanish\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Give me the information of the capital of France.\",\n",
    "    \"Give me the information of the capital of Germany.\",\n",
    "    \"Give me the information of the capital of Italy.\",\n",
    "]\n",
    "\n",
    "sampling_params = {\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"ebnf\": (\n",
    "        \"root ::= city | description\\n\"\n",
    "        'city ::= \"London\" | \"Paris\" | \"Berlin\" | \"Rome\"\\n'\n",
    "        'description ::= city \" is \" status\\n'\n",
    "        'status ::= \"the capital of \" country\\n'\n",
    "        'country ::= \"England\" | \"France\" | \"Germany\" | \"Italy\"'\n",
    "    ),\n",
    "}\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(f\"Prompt: {prompt}\\nGenerated text: {output['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:42:04.187531Z",
     "iopub.status.busy": "2025-04-14T22:42:04.187273Z",
     "iopub.status.idle": "2025-04-14T22:42:05.540044Z",
     "shell.execute_reply": "2025-04-14T22:42:05.539546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: Please provide information about London as a major global city:\n",
      "Generated text:  3 sentences. Please make sure to mention London's population, major landmarks, and whether it's a cultural hub.\n",
      "\n",
      "Certainly!\n",
      "\n",
      "London, often referred to as the \"City of London,\" is one of the most populous cities in the world, with a population exceeding 9 million. It is renowned for its iconic landmarks such as Big Ben and the Tower of London, which attract millions of visitors each year. London is widely recognized as a global cultural hub, hosting numerous museums, theaters, and renowned universities, making it a center for creativity and knowledge worldwide.\n",
      "===============================\n",
      "Prompt: Please provide information about Paris as a major global city:\n",
      "Generated text:  location, population, number of residents over the years, economic status, major attractions, mode of transportation, and cultural aspects.\n",
      "\n",
      ".\n",
      "Okay, so I need to provide information about Paris as a major global city. The user has specified several areas: location, population over the years, economic status, major attractions, transportation, and cultural aspects. Let me think about each of these sections and how to approach them.\n",
      "\n",
      "Starting with location, Paris is in France, in the Île-de-France region. It's on the Seine River, right? The exact coordinates would be something like 48°51′N 2°\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Please provide information about London as a major global city:\",\n",
    "    \"Please provide information about Paris as a major global city:\",\n",
    "]\n",
    "\n",
    "sampling_params = {\"temperature\": 0.8, \"top_p\": 0.95, \"regex\": \"(France|England)\"}\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(f\"Prompt: {prompt}\\nGenerated text: {output['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:42:05.542140Z",
     "iopub.status.busy": "2025-04-14T22:42:05.541690Z",
     "iopub.status.idle": "2025-04-14T22:42:08.837730Z",
     "shell.execute_reply": "2025-04-14T22:42:08.837224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Prompt: <｜begin▁of▁sentence｜><｜User｜>Here is the information of the capital of France in the JSON format.\n",
      "<｜Assistant｜><think>\n",
      "\n",
      "Generated text: Alright, so the user is asking for the JSON information of the capital of France, which is Paris. I need to structure this correctly. First, I'll identify the key details. Paris is located in Île-de-France, France. Its population is around 2.2 million. The area is approximately 105 square kilometers. It's the administrative center, so the administrative center code is FR000001. The current mayor as of the latest update is Jean-Louis Drogne. I should format this into a JSON structure with these fields: \"Country\", \"Region\", \"Population\", \"Area\", \"AdministrativeCenter\", and \"Mayor\". I'll make sure to use accurate and up-to-date information, especially since population and mayor can change over time. I'll also check if there's a more recent mayor, but as of my knowledge cutoff in July 2024, Drogne is listed. I'll present this in a clear, concise JSON format without any markdown, just plain text. That should cover everything the user is asking for.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"Country\": \"France\",\n",
      "  \"Region\": \"Île-de-France\",\n",
      "  \"Population\": 2198000,\n",
      "  \"Area\": 105.23,\n",
      "  \"AdministrativeCenter\": \"FR000001\",\n",
      "  \"Mayor\": \"Jean-Louis Drogne\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "prompts = [text]\n",
    "\n",
    "\n",
    "sampling_params = {\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"max_new_tokens\": 2048,\n",
    "    \"structural_tag\": json.dumps(\n",
    "        {\n",
    "            \"type\": \"structural_tag\",\n",
    "            \"structures\": [\n",
    "                {\n",
    "                    \"begin\": \"<function=get_current_weather>\",\n",
    "                    \"schema\": schema_get_current_weather,\n",
    "                    \"end\": \"</function>\",\n",
    "                },\n",
    "                {\n",
    "                    \"begin\": \"<function=get_current_date>\",\n",
    "                    \"schema\": schema_get_current_date,\n",
    "                    \"end\": \"</function>\",\n",
    "                },\n",
    "            ],\n",
    "            \"triggers\": [\"<function=\"],\n",
    "        }\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "# Send POST request to the API endpoint\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "for prompt, output in zip(prompts, outputs):\n",
    "    print(\"===============================\")\n",
    "    print(f\"Prompt: {prompt}\\nGenerated text: {output['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:42:08.839477Z",
     "iopub.status.busy": "2025-04-14T22:42:08.839159Z",
     "iopub.status.idle": "2025-04-14T22:42:08.854137Z",
     "shell.execute_reply": "2025-04-14T22:42:08.853648Z"
    }
   },
   "outputs": [],
   "source": [
    "llm.shutdown()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
