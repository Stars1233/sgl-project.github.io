
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Structured Outputs For Reasoning Models &#8212; SGLang</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=660dd02a"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'backend/structured_outputs_for_reasoning_models';</script>
    <link rel="icon" href="../_static/logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Custom Chat Template" href="custom_chat_template.html" />
    <link rel="prev" title="Reasoning Parser" href="separate_reasoning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Apr 27, 2025"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="SGLang - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="SGLang - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../start/install.html">Install SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Backend Tutorial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../references/deepseek.html">DeepSeek Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/llama4.html">Llama4 Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="send_request.html">Sending Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="openai_api_completions.html">OpenAI APIs - Completions</a></li>
<li class="toctree-l1"><a class="reference internal" href="openai_api_vision.html">OpenAI APIs - Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="openai_api_embeddings.html">OpenAI APIs - Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="native_api.html">SGLang Native APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_engine_api.html">Offline Engine API</a></li>
<li class="toctree-l1"><a class="reference internal" href="server_arguments.html">Server Arguments</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling_params.html">Sampling Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyperparameter_tuning.html">Hyperparameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="attention_backend.html">Attention Backend</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supported Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../supported_models/generative_models.html">Large Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/vision_language_models.html">Vision Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/embedding_models.html">Embedding Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/reward_models.html">Reward Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/support_new_models.html">How to Support New Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="speculative_decoding.html">Speculative Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_calling.html">Tool and Function Calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="separate_reasoning.html">Reasoning Parser</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Structured Outputs For Reasoning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_chat_template.html">Custom Chat Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="lora.html">LoRA Serving</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frontend Tutorial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../frontend/frontend.html">SGLang Frontend Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/choices_methods.html">Choices Methods in SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SGLang Router</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../router/router.html">Router for Data Parallelism</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../references/general.html">General Guidance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/hardware.html">Hardware Supports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/advanced_deploy.html">Multi-Node Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/performance_tuning.html">Performance Tuning</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/blob/main/backend/structured_outputs_for_reasoning_models.ipynb?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/edit/main/backend/structured_outputs_for_reasoning_models.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/issues/new?title=Issue%20on%20page%20%2Fbackend/structured_outputs_for_reasoning_models.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/backend/structured_outputs_for_reasoning_models.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Structured Outputs For Reasoning Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Supported-Models">Supported Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Usage">Usage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#OpenAI-Compatible-API">OpenAI Compatible API</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#JSON">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#EBNF">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Regular-expression">Regular expression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Structural-Tag">Structural Tag</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Native-API-and-SGLang-Runtime-(SRT)">Native API and SGLang Runtime (SRT)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Regular expression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Structural Tag</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Offline-Engine-API">Offline Engine API</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Regular expression</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <style>
    .output_area.stderr, .output_area.stdout {
        color: #d3d3d3 !important; /* light gray */
    }
</style><section id="Structured-Outputs-For-Reasoning-Models">
<h1>Structured Outputs For Reasoning Models<a class="headerlink" href="#Structured-Outputs-For-Reasoning-Models" title="Link to this heading">#</a></h1>
<p>When working with reasoning models that use special tokens like <code class="docutils literal notranslate"><span class="pre">&lt;think&gt;...&lt;/think&gt;</span></code> to denote reasoning sections, you might want to allow free-form text within these sections while still enforcing grammar constraints on the rest of the output.</p>
<p>SGLang provides a feature to disable grammar restrictions within reasoning sections. This is particularly useful for models that need to perform complex reasoning steps before providing a structured output.</p>
<p>To enable this feature, use the <code class="docutils literal notranslate"><span class="pre">--reasoning-parser</span></code> flag which decide the think_end_token, such as <code class="docutils literal notranslate"><span class="pre">&lt;/think&gt;</span></code>, when launching the server. You can also specify the reasoning parser using the <code class="docutils literal notranslate"><span class="pre">--reasoning-parser</span></code> flag.</p>
<section id="Supported-Models">
<h2>Supported Models<a class="headerlink" href="#Supported-Models" title="Link to this heading">#</a></h2>
<p>Currently, SGLang supports the following reasoning models:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d">DeepSeek R1 series</a>: The reasoning content is wrapped with <code class="docutils literal notranslate"><span class="pre">&lt;think&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;/think&gt;</span></code> tags.</p></li>
<li><p><a class="reference external" href="https://huggingface.co/Qwen/QwQ-32B">QwQ</a>: The reasoning content is wrapped with <code class="docutils literal notranslate"><span class="pre">&lt;think&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;/think&gt;</span></code> tags.</p></li>
</ul>
</section>
<section id="Usage">
<h2>Usage<a class="headerlink" href="#Usage" title="Link to this heading">#</a></h2>
</section>
<section id="OpenAI-Compatible-API">
<h2>OpenAI Compatible API<a class="headerlink" href="#OpenAI-Compatible-API" title="Link to this heading">#</a></h2>
<p>Specify the <code class="docutils literal notranslate"><span class="pre">--grammar-backend</span></code>, <code class="docutils literal notranslate"><span class="pre">--reasoning-parser</span></code> option.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sglang.test.test_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_in_ci</span>

<span class="k">if</span> <span class="n">is_in_ci</span><span class="p">():</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">patch</span><span class="w"> </span><span class="kn">import</span> <span class="n">launch_server_cmd</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">launch_server_cmd</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sglang.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">wait_for_server</span><span class="p">,</span> <span class="n">print_highlight</span><span class="p">,</span> <span class="n">terminate_process</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TOKENIZERS_PARALLELISM&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>


<span class="n">server_process</span><span class="p">,</span> <span class="n">port</span> <span class="o">=</span> <span class="n">launch_server_cmd</span><span class="p">(</span>
    <span class="s2">&quot;python -m sglang.launch_server --model-path deepseek-ai/DeepSeek-R1-Distill-Qwen-7B --host 0.0.0.0 --reasoning-parser deepseek-r1&quot;</span>
<span class="p">)</span>

<span class="n">wait_for_server</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">base_url</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;http://127.0.0.1:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/v1&quot;</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;None&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 00:57:53] server_args=ServerArgs(model_path=&#39;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&#39;, tokenizer_path=&#39;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&#39;, tokenizer_mode=&#39;auto&#39;, skip_tokenizer_init=False, enable_tokenizer_batch_encode=False, load_format=&#39;auto&#39;, trust_remote_code=False, dtype=&#39;auto&#39;, kv_cache_dtype=&#39;auto&#39;, quantization=None, quantization_param_path=None, context_length=None, device=&#39;cuda&#39;, served_model_name=&#39;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&#39;, chat_template=None, completion_template=None, is_embedding=False, revision=None, host=&#39;0.0.0.0&#39;, port=34281, mem_fraction_static=0.88, max_running_requests=200, max_total_tokens=20480, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy=&#39;fcfs&#39;, schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=606541243, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level=&#39;info&#39;, log_level_http=None, log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path=&#39;sglang_storage&#39;, enable_cache_report=False, reasoning_parser=&#39;deepseek-r1&#39;, dp_size=1, load_balance_method=&#39;round_robin&#39;, ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args=&#39;{}&#39;, lora_paths=None, max_loras_per_batch=8, lora_backend=&#39;triton&#39;, attention_backend=None, sampling_backend=&#39;flashinfer&#39;, grammar_backend=&#39;xgrammar&#39;, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type=&#39;qk&#39;, ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=True, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_multimodal=None, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_deepep_moe=False, deepep_mode=&#39;auto&#39;, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=None, cuda_graph_bs=None, torchao_config=&#39;&#39;, enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy=&#39;write_through_selective&#39;, flashinfer_mla_disable_ragged=False, warmups=None, moe_dense_tp_size=None, n_share_experts_fusion=0, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode=&#39;null&#39;, disaggregation_bootstrap_port=8998, disaggregation_transfer_backend=&#39;mooncake&#39;, disaggregation_ib_device=None)
[2025-04-27 00:58:04 TP0] Attention backend not set. Use fa3 backend by default.
[2025-04-27 00:58:04 TP0] Init torch distributed begin.
[2025-04-27 00:58:04 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-04-27 00:58:04 TP0] Load weight begin. avail mem=53.74 GB
[2025-04-27 00:58:04 TP0] Ignore import error when loading sglang.srt.models.llama4.
[2025-04-27 00:58:05 TP0] Using model weights format [&#39;*.safetensors&#39;]
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00&lt;?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01&lt;00:01,  1.35s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02&lt;00:00,  1.29s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02&lt;00:00,  1.30s/it]

[2025-04-27 00:58:08 TP0] Load weight end. type=Qwen2ForCausalLM, dtype=torch.bfloat16, avail mem=39.30 GB, mem usage=14.44 GB.
[2025-04-27 00:58:08 TP0] KV Cache is allocated. #tokens: 20480, K size: 0.55 GB, V size: 0.55 GB
[2025-04-27 00:58:08 TP0] Memory pool end. avail mem=37.93 GB
[2025-04-27 00:58:08 TP0] max_total_num_tokens=20480, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=200, context_len=131072
[2025-04-27 00:58:09] INFO:     Started server process [2273351]
[2025-04-27 00:58:09] INFO:     Waiting for application startup.
[2025-04-27 00:58:09] INFO:     Application startup complete.
[2025-04-27 00:58:09] INFO:     Uvicorn running on http://0.0.0.0:34281 (Press CTRL+C to quit)
[2025-04-27 00:58:09] INFO:     127.0.0.1:35252 - &#34;GET /v1/models HTTP/1.1&#34; 200 OK
[2025-04-27 00:58:10] INFO:     127.0.0.1:45038 - &#34;GET /get_model_info HTTP/1.1&#34; 200 OK
[2025-04-27 00:58:10 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'><br><br>                    NOTE: Typically, the server runs in a separate terminal.<br>                    In this notebook, we run the server and notebook code together, so their outputs are combined.<br>                    To improve clarity, the server logs are displayed in the original black color, while the notebook outputs are highlighted in blue.<br>                    We are running those notebooks in a CI parallel environment, so the throughput is not representative of the actual performance.<br>                    </strong></div>
</div>
<section id="JSON">
<h3>JSON<a class="headerlink" href="#JSON" title="Link to this heading">#</a></h3>
<p>you can directly define a JSON schema or use <a class="reference external" href="https://docs.pydantic.dev/latest/">Pydantic</a> to define and validate the response.</p>
<p><strong>Using Pydantic</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>


<span class="c1"># Define the schema using Pydantic</span>
<span class="k">class</span><span class="w"> </span><span class="nc">CapitalInfo</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;^\w+$&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Name of the capital city&quot;</span><span class="p">)</span>
    <span class="n">population</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Population of the capital city&quot;</span><span class="p">)</span>


<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Please generate the information of the capital of France in the JSON format.&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">response_format</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;json_schema&quot;</span><span class="p">,</span>
        <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;foo&quot;</span><span class="p">,</span>
            <span class="c1"># convert the pydantic model to json schema</span>
            <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">CapitalInfo</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">(),</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 00:58:15 TP0] Prefill batch. #new-seq: 1, #new-token: 18, #cached-token: 1, token usage: 0.00, #running-req: 1, #queue-req: 0
[2025-04-27 00:58:15] INFO:     127.0.0.1:45040 - &#34;POST /generate HTTP/1.1&#34; 200 OK
[2025-04-27 00:58:15] The server is fired up and ready to roll!
[2025-04-27 00:58:16 TP0] Decode batch. #running-req: 1, #token: 53, token usage: 0.00, gen throughput (token/s): 5.06, #queue-req: 0
[2025-04-27 00:58:16 TP0] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, gen throughput (token/s): 108.47, #queue-req: 0
[2025-04-27 00:58:17 TP0] Decode batch. #running-req: 1, #token: 133, token usage: 0.01, gen throughput (token/s): 108.39, #queue-req: 0
[2025-04-27 00:58:17 TP0] Decode batch. #running-req: 1, #token: 173, token usage: 0.01, gen throughput (token/s): 105.34, #queue-req: 0
[2025-04-27 00:58:17 TP0] Decode batch. #running-req: 1, #token: 213, token usage: 0.01, gen throughput (token/s): 110.25, #queue-req: 0
[2025-04-27 00:58:18 TP0] Decode batch. #running-req: 1, #token: 253, token usage: 0.01, gen throughput (token/s): 104.35, #queue-req: 0
[2025-04-27 00:58:18 TP0] Decode batch. #running-req: 1, #token: 293, token usage: 0.01, gen throughput (token/s): 106.81, #queue-req: 0
[2025-04-27 00:58:19 TP0] Decode batch. #running-req: 1, #token: 333, token usage: 0.02, gen throughput (token/s): 109.32, #queue-req: 0
[2025-04-27 00:58:19 TP0] Decode batch. #running-req: 1, #token: 373, token usage: 0.02, gen throughput (token/s): 105.24, #queue-req: 0
[2025-04-27 00:58:19 TP0] Decode batch. #running-req: 1, #token: 413, token usage: 0.02, gen throughput (token/s): 110.28, #queue-req: 0
[2025-04-27 00:58:20 TP0] Decode batch. #running-req: 1, #token: 453, token usage: 0.02, gen throughput (token/s): 108.04, #queue-req: 0
[2025-04-27 00:58:20 TP0] Decode batch. #running-req: 1, #token: 493, token usage: 0.02, gen throughput (token/s): 105.72, #queue-req: 0
[2025-04-27 00:58:20 TP0] Decode batch. #running-req: 1, #token: 533, token usage: 0.03, gen throughput (token/s): 107.29, #queue-req: 0
[2025-04-27 00:58:21 TP0] Decode batch. #running-req: 1, #token: 573, token usage: 0.03, gen throughput (token/s): 105.78, #queue-req: 0
[2025-04-27 00:58:21 TP0] Decode batch. #running-req: 1, #token: 613, token usage: 0.03, gen throughput (token/s): 103.40, #queue-req: 0
[2025-04-27 00:58:22 TP0] Decode batch. #running-req: 1, #token: 653, token usage: 0.03, gen throughput (token/s): 105.48, #queue-req: 0
[2025-04-27 00:58:22 TP0] Decode batch. #running-req: 1, #token: 693, token usage: 0.03, gen throughput (token/s): 107.42, #queue-req: 0
[2025-04-27 00:58:22 TP0] Decode batch. #running-req: 1, #token: 733, token usage: 0.04, gen throughput (token/s): 102.30, #queue-req: 0
[2025-04-27 00:58:23 TP0] Decode batch. #running-req: 1, #token: 773, token usage: 0.04, gen throughput (token/s): 103.77, #queue-req: 0
[2025-04-27 00:58:23 TP0] Decode batch. #running-req: 1, #token: 813, token usage: 0.04, gen throughput (token/s): 104.80, #queue-req: 0
[2025-04-27 00:58:24 TP0] Decode batch. #running-req: 1, #token: 853, token usage: 0.04, gen throughput (token/s): 101.85, #queue-req: 0
[2025-04-27 00:58:24 TP0] Decode batch. #running-req: 1, #token: 893, token usage: 0.04, gen throughput (token/s): 88.99, #queue-req: 0
[2025-04-27 00:58:24 TP0] Decode batch. #running-req: 1, #token: 933, token usage: 0.05, gen throughput (token/s): 79.98, #queue-req: 0
[2025-04-27 00:58:25 TP0] Decode batch. #running-req: 1, #token: 973, token usage: 0.05, gen throughput (token/s): 89.60, #queue-req: 0
[2025-04-27 00:58:25 TP0] Decode batch. #running-req: 1, #token: 1013, token usage: 0.05, gen throughput (token/s): 102.78, #queue-req: 0
[2025-04-27 00:58:26 TP0] Decode batch. #running-req: 1, #token: 1053, token usage: 0.05, gen throughput (token/s): 100.36, #queue-req: 0
[2025-04-27 00:58:26 TP0] Decode batch. #running-req: 1, #token: 1093, token usage: 0.05, gen throughput (token/s): 105.62, #queue-req: 0
[2025-04-27 00:58:26 TP0] Decode batch. #running-req: 1, #token: 1133, token usage: 0.06, gen throughput (token/s): 108.51, #queue-req: 0
[2025-04-27 00:58:27 TP0] Decode batch. #running-req: 1, #token: 1173, token usage: 0.06, gen throughput (token/s): 103.47, #queue-req: 0
[2025-04-27 00:58:27 TP0] Decode batch. #running-req: 1, #token: 1213, token usage: 0.06, gen throughput (token/s): 105.72, #queue-req: 0
[2025-04-27 00:58:28 TP0] Decode batch. #running-req: 1, #token: 1253, token usage: 0.06, gen throughput (token/s): 105.13, #queue-req: 0
[2025-04-27 00:58:28 TP0] Decode batch. #running-req: 1, #token: 1293, token usage: 0.06, gen throughput (token/s): 104.80, #queue-req: 0
[2025-04-27 00:58:28 TP0] Decode batch. #running-req: 1, #token: 1333, token usage: 0.07, gen throughput (token/s): 105.16, #queue-req: 0
[2025-04-27 00:58:29 TP0] Decode batch. #running-req: 1, #token: 1373, token usage: 0.07, gen throughput (token/s): 91.94, #queue-req: 0
[2025-04-27 00:58:29 TP0] Decode batch. #running-req: 1, #token: 1413, token usage: 0.07, gen throughput (token/s): 104.30, #queue-req: 0
[2025-04-27 00:58:30 TP0] Decode batch. #running-req: 1, #token: 1453, token usage: 0.07, gen throughput (token/s): 103.54, #queue-req: 0
[2025-04-27 00:58:30 TP0] Decode batch. #running-req: 1, #token: 1493, token usage: 0.07, gen throughput (token/s): 99.70, #queue-req: 0
[2025-04-27 00:58:30 TP0] Decode batch. #running-req: 1, #token: 1533, token usage: 0.07, gen throughput (token/s): 107.62, #queue-req: 0
[2025-04-27 00:58:31 TP0] Decode batch. #running-req: 1, #token: 1573, token usage: 0.08, gen throughput (token/s): 103.09, #queue-req: 0
[2025-04-27 00:58:31 TP0] Decode batch. #running-req: 1, #token: 1613, token usage: 0.08, gen throughput (token/s): 105.69, #queue-req: 0
[2025-04-27 00:58:31 TP0] Decode batch. #running-req: 1, #token: 1653, token usage: 0.08, gen throughput (token/s): 107.78, #queue-req: 0
[2025-04-27 00:58:32 TP0] Decode batch. #running-req: 1, #token: 1693, token usage: 0.08, gen throughput (token/s): 96.42, #queue-req: 0
[2025-04-27 00:58:32 TP0] Decode batch. #running-req: 1, #token: 1733, token usage: 0.08, gen throughput (token/s): 105.39, #queue-req: 0
[2025-04-27 00:58:33 TP0] Decode batch. #running-req: 1, #token: 1773, token usage: 0.09, gen throughput (token/s): 105.84, #queue-req: 0
[2025-04-27 00:58:33 TP0] Decode batch. #running-req: 1, #token: 1813, token usage: 0.09, gen throughput (token/s): 105.58, #queue-req: 0
[2025-04-27 00:58:33 TP0] Decode batch. #running-req: 1, #token: 1853, token usage: 0.09, gen throughput (token/s): 105.69, #queue-req: 0
[2025-04-27 00:58:34 TP0] Decode batch. #running-req: 1, #token: 1893, token usage: 0.09, gen throughput (token/s): 103.39, #queue-req: 0
[2025-04-27 00:58:34 TP0] Decode batch. #running-req: 1, #token: 1933, token usage: 0.09, gen throughput (token/s): 107.51, #queue-req: 0
[2025-04-27 00:58:35 TP0] Decode batch. #running-req: 1, #token: 1973, token usage: 0.10, gen throughput (token/s): 102.84, #queue-req: 0
[2025-04-27 00:58:35 TP0] Decode batch. #running-req: 1, #token: 2013, token usage: 0.10, gen throughput (token/s): 107.16, #queue-req: 0
[2025-04-27 00:58:35 TP0] Decode batch. #running-req: 1, #token: 2053, token usage: 0.10, gen throughput (token/s): 104.83, #queue-req: 0
[2025-04-27 00:58:35] INFO:     127.0.0.1:45048 - &#34;POST /v1/chat/completions HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Okay, so I need to generate information about the capital of France, Paris, in JSON format. Let me think about how to approach this. First, I should recall what Paris is known for. It's the main city in France, right? I know it's a major cultural, economic, and political center. <br><br>I should probably start by listing the basic facts. The capital of France is Paris, so that's straightforward. The country it's the capital of is France, which I can confirm. The location is in the northern part of the country, near the Seine River. I remember that Paris is located in the Île-de-France region, which is a large area including other cities like Lyon and Marseille.<br><br>Next, I should think about the population. I think Paris is the second-largest city in France, after metropolitan Paris, which includes a much larger area. The population numbers might be around 2 million for the city proper and 8 million for the metropolitan area. I should double-check that, but I'm pretty sure that's correct.<br><br>Moving on to landmarks, the Eiffel Tower is a must. It's a symbol of the city and the country. The Louvre Museum is another famous landmark, one of the largest art museums in the world. The Paris Opera House is also iconic, especially for its architecture. The Arc de Triomphe is a significant historical monument, and Notre-Dame, despite the recent issues, is still a major attraction, though it's currently undergoing renovations.<br><br>I should include some key facts about Paris. It's known for its rich history, being the birthplace of many famous people like Victor Hugo, Ernest Hemingway, and others. It's also a global city with a vibrant cultural scene, hosting events like the French网球公开赛 and the Tour de France. The cuisine is a big part of its identity, with famous dishes like croissant and boeuf bourguignon.<br><br>Transportation is another area. Paris has an extensive public transportation system, including the Métro, which is a large subway network. The RER is another rail network that connects to other cities. Taxis are also a common mode of transportation, and there are bike lanes throughout the city, especially in the Île-de-France region.<br><br>I should structure this information into a JSON format. The JSON should have a key for the capital, which is "Paris", and then an object containing the details. I'll list each piece of information as a key-value pair under the "capital" key. I need to make sure the JSON is properly formatted with commas and brackets, and that strings are enclosed in quotes.<br><br>Wait, I should also consider the population numbers. I think the population of Paris itself is around 2.1 million, while the metropolitan area is about 8.5 million. I should include that. Also, the area of Paris is approximately 105 square kilometers, and the metropolitan area is about 12,500 square kilometers.<br><br>I should also mention the time zone. Paris is in Central European Time (CET) during standard time and Central European Summer Time (CEST) in summer. That's important for international users.<br><br>Let me organize all this information into a JSON structure. I'll start with the capital key, then include the population, location, landmarks, key facts, transportation, and area. I'll make sure each key is descriptive and the values are accurate.<br><br>I think I've covered all the main points. Now, I'll format it correctly, ensuring that the JSON syntax is correct with proper commas and brackets. I'll avoid any markdown formatting as per the instructions and just present the JSON.<br><br><br>content: {<br><br>"name": "Paris",<br>"population": 214300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000</strong></div>
</div>
<p><strong>JSON Schema Directly</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="n">json_schema</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
        <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;pattern&quot;</span><span class="p">:</span> <span class="s2">&quot;^[</span><span class="se">\\</span><span class="s2">w]+$&quot;</span><span class="p">},</span>
            <span class="s2">&quot;population&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;integer&quot;</span><span class="p">},</span>
        <span class="p">},</span>
        <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;population&quot;</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Give me the information of the capital of France in the JSON format.&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">response_format</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;json_schema&quot;</span><span class="p">,</span>
        <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;foo&quot;</span><span class="p">,</span> <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">json_schema</span><span class="p">)},</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 00:58:36 TP0] Prefill batch. #new-seq: 1, #new-token: 17, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-04-27 00:58:36 TP0] Decode batch. #running-req: 1, #token: 45, token usage: 0.00, gen throughput (token/s): 78.31, #queue-req: 0
[2025-04-27 00:58:36 TP0] Decode batch. #running-req: 1, #token: 85, token usage: 0.00, gen throughput (token/s): 109.16, #queue-req: 0
[2025-04-27 00:58:37 TP0] Decode batch. #running-req: 1, #token: 125, token usage: 0.01, gen throughput (token/s): 108.76, #queue-req: 0
[2025-04-27 00:58:37 TP0] Decode batch. #running-req: 1, #token: 165, token usage: 0.01, gen throughput (token/s): 109.12, #queue-req: 0
[2025-04-27 00:58:37 TP0] Decode batch. #running-req: 1, #token: 205, token usage: 0.01, gen throughput (token/s): 106.15, #queue-req: 0
[2025-04-27 00:58:38 TP0] Decode batch. #running-req: 1, #token: 245, token usage: 0.01, gen throughput (token/s): 110.94, #queue-req: 0
[2025-04-27 00:58:38 TP0] Decode batch. #running-req: 1, #token: 285, token usage: 0.01, gen throughput (token/s): 89.94, #queue-req: 0
[2025-04-27 00:58:38 TP0] Decode batch. #running-req: 1, #token: 325, token usage: 0.02, gen throughput (token/s): 97.66, #queue-req: 0
[2025-04-27 00:58:39 TP0] Decode batch. #running-req: 1, #token: 365, token usage: 0.02, gen throughput (token/s): 108.68, #queue-req: 0
[2025-04-27 00:58:39 TP0] Decode batch. #running-req: 1, #token: 405, token usage: 0.02, gen throughput (token/s): 110.85, #queue-req: 0
[2025-04-27 00:58:40 TP0] Decode batch. #running-req: 1, #token: 445, token usage: 0.02, gen throughput (token/s): 108.54, #queue-req: 0
[2025-04-27 00:58:40 TP0] Decode batch. #running-req: 1, #token: 485, token usage: 0.02, gen throughput (token/s): 109.00, #queue-req: 0
[2025-04-27 00:58:40 TP0] Decode batch. #running-req: 1, #token: 525, token usage: 0.03, gen throughput (token/s): 88.88, #queue-req: 0
[2025-04-27 00:58:41 TP0] Decode batch. #running-req: 1, #token: 565, token usage: 0.03, gen throughput (token/s): 109.13, #queue-req: 0
[2025-04-27 00:58:41 TP0] Decode batch. #running-req: 1, #token: 605, token usage: 0.03, gen throughput (token/s): 106.75, #queue-req: 0
[2025-04-27 00:58:42 TP0] Decode batch. #running-req: 1, #token: 645, token usage: 0.03, gen throughput (token/s): 106.13, #queue-req: 0
[2025-04-27 00:58:42 TP0] Decode batch. #running-req: 1, #token: 685, token usage: 0.03, gen throughput (token/s): 103.93, #queue-req: 0
[2025-04-27 00:58:42 TP0] Decode batch. #running-req: 1, #token: 725, token usage: 0.04, gen throughput (token/s): 106.33, #queue-req: 0
[2025-04-27 00:58:43 TP0] Decode batch. #running-req: 1, #token: 765, token usage: 0.04, gen throughput (token/s): 102.26, #queue-req: 0
[2025-04-27 00:58:43 TP0] Decode batch. #running-req: 1, #token: 805, token usage: 0.04, gen throughput (token/s): 106.38, #queue-req: 0
[2025-04-27 00:58:43 TP0] Decode batch. #running-req: 1, #token: 845, token usage: 0.04, gen throughput (token/s): 106.18, #queue-req: 0
[2025-04-27 00:58:44 TP0] Decode batch. #running-req: 1, #token: 885, token usage: 0.04, gen throughput (token/s): 108.40, #queue-req: 0
[2025-04-27 00:58:44 TP0] Decode batch. #running-req: 1, #token: 925, token usage: 0.05, gen throughput (token/s): 103.92, #queue-req: 0
[2025-04-27 00:58:45 TP0] Decode batch. #running-req: 1, #token: 965, token usage: 0.05, gen throughput (token/s): 108.33, #queue-req: 0
[2025-04-27 00:58:45 TP0] Decode batch. #running-req: 1, #token: 1005, token usage: 0.05, gen throughput (token/s): 105.29, #queue-req: 0
[2025-04-27 00:58:45 TP0] Decode batch. #running-req: 1, #token: 1045, token usage: 0.05, gen throughput (token/s): 106.97, #queue-req: 0
[2025-04-27 00:58:46 TP0] Decode batch. #running-req: 1, #token: 1085, token usage: 0.05, gen throughput (token/s): 107.63, #queue-req: 0
[2025-04-27 00:58:46 TP0] Decode batch. #running-req: 1, #token: 1125, token usage: 0.05, gen throughput (token/s): 108.09, #queue-req: 0
[2025-04-27 00:58:46 TP0] Decode batch. #running-req: 1, #token: 1165, token usage: 0.06, gen throughput (token/s): 107.26, #queue-req: 0
[2025-04-27 00:58:47 TP0] Decode batch. #running-req: 1, #token: 1205, token usage: 0.06, gen throughput (token/s): 106.89, #queue-req: 0
[2025-04-27 00:58:47 TP0] Decode batch. #running-req: 1, #token: 1245, token usage: 0.06, gen throughput (token/s): 107.09, #queue-req: 0
[2025-04-27 00:58:48 TP0] Decode batch. #running-req: 1, #token: 1285, token usage: 0.06, gen throughput (token/s): 102.55, #queue-req: 0
[2025-04-27 00:58:48 TP0] Decode batch. #running-req: 1, #token: 1325, token usage: 0.06, gen throughput (token/s): 108.76, #queue-req: 0
[2025-04-27 00:58:48 TP0] Decode batch. #running-req: 1, #token: 1365, token usage: 0.07, gen throughput (token/s): 106.14, #queue-req: 0
[2025-04-27 00:58:49 TP0] Decode batch. #running-req: 1, #token: 1405, token usage: 0.07, gen throughput (token/s): 103.14, #queue-req: 0
[2025-04-27 00:58:49 TP0] Decode batch. #running-req: 1, #token: 1445, token usage: 0.07, gen throughput (token/s): 108.93, #queue-req: 0
[2025-04-27 00:58:49 TP0] Decode batch. #running-req: 1, #token: 1485, token usage: 0.07, gen throughput (token/s): 106.28, #queue-req: 0
[2025-04-27 00:58:50 TP0] Decode batch. #running-req: 1, #token: 1525, token usage: 0.07, gen throughput (token/s): 103.86, #queue-req: 0
[2025-04-27 00:58:50 TP0] Decode batch. #running-req: 1, #token: 1565, token usage: 0.08, gen throughput (token/s): 105.97, #queue-req: 0
[2025-04-27 00:58:51 TP0] Decode batch. #running-req: 1, #token: 1605, token usage: 0.08, gen throughput (token/s): 105.60, #queue-req: 0
[2025-04-27 00:58:51 TP0] Decode batch. #running-req: 1, #token: 1645, token usage: 0.08, gen throughput (token/s): 97.31, #queue-req: 0
[2025-04-27 00:58:51 TP0] Decode batch. #running-req: 1, #token: 1685, token usage: 0.08, gen throughput (token/s): 104.00, #queue-req: 0
[2025-04-27 00:58:52 TP0] Decode batch. #running-req: 1, #token: 1725, token usage: 0.08, gen throughput (token/s): 105.50, #queue-req: 0
[2025-04-27 00:58:52 TP0] Decode batch. #running-req: 1, #token: 1765, token usage: 0.09, gen throughput (token/s): 105.76, #queue-req: 0
[2025-04-27 00:58:53 TP0] Decode batch. #running-req: 1, #token: 1805, token usage: 0.09, gen throughput (token/s): 107.47, #queue-req: 0
[2025-04-27 00:58:53 TP0] Decode batch. #running-req: 1, #token: 1845, token usage: 0.09, gen throughput (token/s): 105.86, #queue-req: 0
[2025-04-27 00:58:53 TP0] Decode batch. #running-req: 1, #token: 1885, token usage: 0.09, gen throughput (token/s): 106.02, #queue-req: 0
[2025-04-27 00:58:54 TP0] Decode batch. #running-req: 1, #token: 1925, token usage: 0.09, gen throughput (token/s): 106.14, #queue-req: 0
[2025-04-27 00:58:54 TP0] Decode batch. #running-req: 1, #token: 1965, token usage: 0.10, gen throughput (token/s): 103.58, #queue-req: 0
[2025-04-27 00:58:54 TP0] Decode batch. #running-req: 1, #token: 2005, token usage: 0.10, gen throughput (token/s): 105.84, #queue-req: 0
[2025-04-27 00:58:55 TP0] Decode batch. #running-req: 1, #token: 2045, token usage: 0.10, gen throughput (token/s): 104.81, #queue-req: 0
[2025-04-27 00:58:55] INFO:     127.0.0.1:45048 - &#34;POST /v1/chat/completions HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Okay, so I need to figure out the information about the capital of France and present it in JSON format. Let me start by recalling what I know about Paris. I know it's the capital, but I should probably double-check that. Yeah, I'm pretty sure Paris is the administrative capital, but sometimes people might confuse it with other cities like Lyon or Marseille. But no, Paris is definitely the official capital.<br><br>Now, moving on to the population. I think Paris is a very large city, one of the biggest in the world. I remember reading somewhere that it's over 3 million people, but I'm not sure of the exact figure. Maybe around 3.5 million? I should look that up to be accurate, but since I'm just brainstorming, I'll go with that estimate.<br><br>Next, the area. Paris is a big city, but it's also a dense urban area. I think the metropolitan area covers a large region, maybe around 12,000 square kilometers? But the city proper is smaller. I'm not exactly sure, but I'll put 10,500 square kilometers for the city area and 12,000 for the metropolitan area.<br><br>Language is another point. Paris is a center for French culture, so the predominant language there is definitely French. I don't think they speak any other language there predominantly, though there might be some English, especially in tourist areas or with expatriates.<br><br>Cuisine is interesting. Paris is known for its high-end, fine dining, especially French cuisine. I know places like Le Faitout and others that are famous for their intricate dishes. Parisians are also known for their coffee culture, so maybe that's another point to include.<br><br>Transportation-wise, Paris has an extensive public transit system. The RER and地铁 are part of the BTP, which I think stands for Bahn, Tram, and Metro in German, but in French, it's the same. The city is well-connected by train, with major stations like Gare du Nord and Châtelet. The Eiffel Tower is a major landmark, and it's accessible by train from Paris.<br><br>I should also mention some of the main attractions. The Eiffel Tower is iconic, along with the Louvre Museum, Notre-Dame Cathedral, and the Sacré-Cœur Basilica. These are must-see spots for tourists.<br><br>Now, putting this all together into JSON format. I'll structure it with an "info" key that contains a "capital" object with "name," "population," "area," and "language." Then, an "attractions" array that lists the main points of interest. I'll make sure the numbers are approximate since I don't have exact figures on hand.<br><br>Wait, I should check if the population is over 3 million or 3.5. I think it's around 3.5 million as of recent estimates. The area, I'm pretty sure the metropolitan area is about 12,000 km², and the city proper is a bit less, maybe 10,500 km². That seems right.<br><br>So, the JSON structure would have the info object with the necessary details, and the attractions array listing the main landmarks. I think that covers everything the user asked for. I should present it clearly, making sure the JSON is properly formatted with commas and quotes.<br><br><br>content: {<br><br>"name": "Paris",<br>"population": 350000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000</strong></div>
</div>
</section>
<section id="EBNF">
<h3>EBNF<a class="headerlink" href="#EBNF" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ebnf_grammar</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">root ::= city | description</span>
<span class="s2">city ::= &quot;London&quot; | &quot;Paris&quot; | &quot;Berlin&quot; | &quot;Rome&quot;</span>
<span class="s2">description ::= city &quot; is &quot; status</span>
<span class="s2">status ::= &quot;the capital of &quot; country</span>
<span class="s2">country ::= &quot;England&quot; | &quot;France&quot; | &quot;Germany&quot; | &quot;Italy&quot;</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful geography bot.&quot;</span><span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Give me the information of the capital of France.&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">extra_body</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;ebnf&quot;</span><span class="p">:</span> <span class="n">ebnf_grammar</span><span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 00:58:55 TP0] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-04-27 00:58:55 TP0] Decode batch. #running-req: 1, #token: 40, token usage: 0.00, gen throughput (token/s): 90.60, #queue-req: 0
[2025-04-27 00:58:56 TP0] Decode batch. #running-req: 1, #token: 80, token usage: 0.00, gen throughput (token/s): 91.93, #queue-req: 0
[2025-04-27 00:58:56 TP0] Decode batch. #running-req: 1, #token: 120, token usage: 0.01, gen throughput (token/s): 110.49, #queue-req: 0
[2025-04-27 00:58:56] INFO:     127.0.0.1:45048 - &#34;POST /v1/chat/completions HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Okay, so I need to figure out the capital of France. I remember that France is a country in Europe, and I think its capital is Paris. But wait, I'm not entirely sure. Let me think about other capitals I know. Germany's capital is Berlin, Italy's is Rome, Spain's is Madrid, and the UK's is London. Yeah, Paris seems right for France. I don't recall any other city being the capital of France. Maybe I should double-check, but I'm pretty confident it's Paris.<br><br><br>content: Paris is the capital of France</strong></div>
</div>
</section>
<section id="Regular-expression">
<h3>Regular expression<a class="headerlink" href="#Regular-expression" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
    <span class="p">],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">extra_body</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;regex&quot;</span><span class="p">:</span> <span class="s2">&quot;(Paris|London)&quot;</span><span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 00:58:56 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-04-27 00:58:56 TP0] Decode batch. #running-req: 1, #token: 34, token usage: 0.00, gen throughput (token/s): 98.91, #queue-req: 0
[2025-04-27 00:58:57 TP0] Decode batch. #running-req: 1, #token: 74, token usage: 0.00, gen throughput (token/s): 107.17, #queue-req: 0
[2025-04-27 00:58:57 TP0] Decode batch. #running-req: 1, #token: 114, token usage: 0.01, gen throughput (token/s): 110.02, #queue-req: 0
[2025-04-27 00:58:58 TP0] Decode batch. #running-req: 1, #token: 154, token usage: 0.01, gen throughput (token/s): 92.17, #queue-req: 0
[2025-04-27 00:58:58 TP0] Decode batch. #running-req: 1, #token: 194, token usage: 0.01, gen throughput (token/s): 113.01, #queue-req: 0
[2025-04-27 00:58:58 TP0] Decode batch. #running-req: 1, #token: 234, token usage: 0.01, gen throughput (token/s): 107.69, #queue-req: 0
[2025-04-27 00:58:59 TP0] Decode batch. #running-req: 1, #token: 274, token usage: 0.01, gen throughput (token/s): 110.35, #queue-req: 0
[2025-04-27 00:58:59 TP0] Decode batch. #running-req: 1, #token: 314, token usage: 0.02, gen throughput (token/s): 112.98, #queue-req: 0
[2025-04-27 00:58:59 TP0] Decode batch. #running-req: 1, #token: 354, token usage: 0.02, gen throughput (token/s): 106.81, #queue-req: 0
[2025-04-27 00:59:00] INFO:     127.0.0.1:45048 - &#34;POST /v1/chat/completions HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Okay, so I need to figure out the capital of France. Hmm, I remember learning a bit about France in school, but I'm not 100% sure. Let me think. I know that Paris is a major city in France, and it's often referred to as the "City of Light." People go there for museums, landmarks like the Eiffel Tower, and it's a cultural hub. But is it the capital?<br><br>Wait, I think the capital is the official seat of government, right? So maybe Paris is both the capital and the most famous city. But I'm not entirely certain. I recall that some countries have their capital in a different city than their main tourist attraction. For example, I think Brazil's capital is not Rio de Janeiro, which is more famous. So maybe France is like that too.<br><br>Let me try to remember any specific information. I think the French government declares Paris as the capital. Yeah, that sounds right. I also remember that the Eiffel Tower is in Paris, and it's a symbol of the country. So if Paris is the capital, then that makes sense. But I'm a bit confused because sometimes people say "the capital of France is Paris," but I also think about other capitals I know, like London for the UK or Berlin for Germany. So maybe it's the same for France.<br><br>I should also consider if there are any other capitals in France. I don't think so. France has only one capital city, which is Paris. So, putting it all together, I'm pretty confident that Paris is the capital of France. It's the main government building area, and it's the most well-known city in the country. Yeah, I think that's correct.<br><br><br>content: Paris</strong></div>
</div>
</section>
<section id="Structural-Tag">
<h3>Structural Tag<a class="headerlink" href="#Structural-Tag" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tool_get_current_weather</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;get_current_weather&quot;</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Get the current weather in a given location&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;city&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The city to find the weather for, e.g. &#39;San Francisco&#39;&quot;</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="s2">&quot;state&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;the two-letter abbreviation for the state that the city is&quot;</span>
                    <span class="s2">&quot; in, e.g. &#39;CA&#39; which would mean &#39;California&#39;&quot;</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The unit to fetch the temperature in&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;enum&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;celsius&quot;</span><span class="p">,</span> <span class="s2">&quot;fahrenheit&quot;</span><span class="p">],</span>
                <span class="p">},</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;city&quot;</span><span class="p">,</span> <span class="s2">&quot;state&quot;</span><span class="p">,</span> <span class="s2">&quot;unit&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">tool_get_current_date</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;get_current_date&quot;</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Get the current date and time for a given timezone&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;timezone&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The timezone to fetch the current date and time for, e.g. &#39;America/New_York&#39;&quot;</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;timezone&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">schema_get_current_weather</span> <span class="o">=</span> <span class="n">tool_get_current_weather</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">][</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span>
<span class="n">schema_get_current_date</span> <span class="o">=</span> <span class="n">tool_get_current_date</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">][</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_messages</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2"># Tool Instructions</span>
<span class="s2">- Always execute python code in messages that you share.</span>
<span class="s2">- When looking for real time information use relevant functions if available else fallback to brave_search</span>
<span class="s2">You have access to the following functions:</span>
<span class="s2">Use the function &#39;get_current_weather&#39; to: Get the current weather in a given location</span>
<span class="si">{</span><span class="n">tool_get_current_weather</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span><span class="si">}</span>
<span class="s2">Use the function &#39;get_current_date&#39; to: Get the current date and time for a given timezone</span>
<span class="si">{</span><span class="n">tool_get_current_date</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span><span class="si">}</span>
<span class="s2">If a you choose to call a function ONLY reply in the following format:</span>
<span class="s2">&lt;</span><span class="se">{{</span><span class="s2">start_tag</span><span class="se">}}</span><span class="s2">=</span><span class="se">{{</span><span class="s2">function_name</span><span class="se">}}</span><span class="s2">&gt;</span><span class="se">{{</span><span class="s2">parameters</span><span class="se">}}{{</span><span class="s2">end_tag</span><span class="se">}}</span>
<span class="s2">where</span>
<span class="s2">start_tag =&gt; `&lt;function`</span>
<span class="s2">parameters =&gt; a JSON dict with the function argument name as key and function argument value as value.</span>
<span class="s2">end_tag =&gt; `&lt;/function&gt;`</span>
<span class="s2">Here is an example,</span>
<span class="s2">&lt;function=example_function_name&gt;</span><span class="se">{{</span><span class="s2">&quot;example_name&quot;: &quot;example_value&quot;</span><span class="se">}}</span><span class="s2">&lt;/function&gt;</span>
<span class="s2">Reminder:</span>
<span class="s2">- Function calls MUST follow the specified format</span>
<span class="s2">- Required parameters MUST be specified</span>
<span class="s2">- Only call one function at a time</span>
<span class="s2">- Put the entire function call reply on one line</span>
<span class="s2">- Always add your sources when using search results to answer the user query</span>
<span class="s2">You are a helpful assistant.&quot;&quot;&quot;</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are in New York. Please get the current date and time, and the weather.&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">]</span>


<span class="n">messages</span> <span class="o">=</span> <span class="n">get_messages</span><span class="p">()</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
    <span class="n">response_format</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;structural_tag&quot;</span><span class="p">,</span>
        <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
        <span class="s2">&quot;structures&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_weather&gt;&quot;</span><span class="p">,</span>
                <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_weather</span><span class="p">,</span>
                <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="p">{</span>
                <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_date&gt;&quot;</span><span class="p">,</span>
                <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_date</span><span class="p">,</span>
                <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">],</span>
        <span class="s2">&quot;triggers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;&lt;function=&quot;</span><span class="p">],</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 00:59:00 TP0] Prefill batch. #new-seq: 1, #new-token: 471, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-04-27 00:59:00 TP0] Decode batch. #running-req: 1, #token: 496, token usage: 0.02, gen throughput (token/s): 54.31, #queue-req: 0
[2025-04-27 00:59:01 TP0] Decode batch. #running-req: 1, #token: 536, token usage: 0.03, gen throughput (token/s): 108.77, #queue-req: 0
[2025-04-27 00:59:01 TP0] Decode batch. #running-req: 1, #token: 576, token usage: 0.03, gen throughput (token/s): 104.56, #queue-req: 0
[2025-04-27 00:59:01 TP0] Decode batch. #running-req: 1, #token: 616, token usage: 0.03, gen throughput (token/s): 109.08, #queue-req: 0
[2025-04-27 00:59:02 TP0] Decode batch. #running-req: 1, #token: 656, token usage: 0.03, gen throughput (token/s): 103.73, #queue-req: 0
[2025-04-27 00:59:02 TP0] Decode batch. #running-req: 1, #token: 696, token usage: 0.03, gen throughput (token/s): 106.71, #queue-req: 0
[2025-04-27 00:59:02 TP0] Decode batch. #running-req: 1, #token: 736, token usage: 0.04, gen throughput (token/s): 106.47, #queue-req: 0
[2025-04-27 00:59:03 TP0] Decode batch. #running-req: 1, #token: 776, token usage: 0.04, gen throughput (token/s): 108.61, #queue-req: 0
[2025-04-27 00:59:03 TP0] Decode batch. #running-req: 1, #token: 816, token usage: 0.04, gen throughput (token/s): 103.80, #queue-req: 0
[2025-04-27 00:59:04 TP0] Decode batch. #running-req: 1, #token: 856, token usage: 0.04, gen throughput (token/s): 106.12, #queue-req: 0
[2025-04-27 00:59:04 TP0] Decode batch. #running-req: 1, #token: 896, token usage: 0.04, gen throughput (token/s): 106.26, #queue-req: 0
[2025-04-27 00:59:04 TP0] Decode batch. #running-req: 1, #token: 936, token usage: 0.05, gen throughput (token/s): 105.80, #queue-req: 0
[2025-04-27 00:59:05 TP0] Decode batch. #running-req: 1, #token: 976, token usage: 0.05, gen throughput (token/s): 105.82, #queue-req: 0
[2025-04-27 00:59:05 TP0] Decode batch. #running-req: 1, #token: 1016, token usage: 0.05, gen throughput (token/s): 105.44, #queue-req: 0
[2025-04-27 00:59:05] INFO:     127.0.0.1:45048 - &#34;POST /v1/chat/completions HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Okay, so I need to figure out how to get the current date and time in New York and the weather there using the functions provided. Let me break this down step by step.<br><br>First, I know that the user is in New York, so the timezone is 'America/New_York'. They want the current date and time, so I should use the 'get_current_date' function. The parameters for this function require a 'timezone' which is a string. So I'll set the timezone parameter to 'America/New_York'.<br><br>Next, the user also wants the weather in New York. So I need to call the 'get_current_weather' function. This function requires a 'city' and a 'state'. However, I'm not sure if the function expects the full city name or just part of it. Wait, looking back at the function description, it says to use 'get_current_weather' with 'city', 'state', and 'unit' as parameters. So I need to provide the city as 'New York' and the state as 'NY' because New York's state abbreviation is NY.<br><br>The unit can be either Celsius or Fahrenheit. The user didn't specify, but since the weather can vary, I should choose one. I'll go with Fahrenheit because that's more common in the US, and New York is in the US. So the unit parameter will be 'fahrenheit'.<br><br>Now, putting it all together. I'll first call 'get_current_date' with the timezone parameter. Then, I'll call 'get_current_weather' with city, state, and unit parameters. Each function call needs to be in the specified format, so I'll structure them one after the other, each within their own function tags.<br><br>Wait, but can I call two functions in one message? The instructions say to call one function at a time, but I think it's okay to call them separately in the same message as long as each is properly formatted. So I'll send both function calls, each on their own line, properly formatted.<br><br>Let me make sure I'm not missing anything. The functions require the parameters in JSON format within the function call. So for the date, it's <function= get_current_date>{"timezone": "America/New_York"}</function>, and for the weather, it's <function= get_current_weather>{"city": "New York", "state": "NY", "unit": "fahrenheit"}</function>.<br><br>I think that's it. I'll present both function calls in the specified format without any additional text.<br><br><br>content: <function=get_current_date>{"timezone":"America/New_York"}</function><br><function=get_current_weather>{"city":"New York","state":"NY","unit":"fahrenheit"}</function></strong></div>
</div>
</section>
</section>
<section id="Native-API-and-SGLang-Runtime-(SRT)">
<h2>Native API and SGLang Runtime (SRT)<a class="headerlink" href="#Native-API-and-SGLang-Runtime-(SRT)" title="Link to this heading">#</a></h2>
<section id="id1">
<h3>JSON<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p><strong>Using Pydantic</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">)</span>


<span class="c1"># Define the schema using Pydantic</span>
<span class="k">class</span><span class="w"> </span><span class="nc">CapitalInfo</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;^\w+$&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Name of the capital city&quot;</span><span class="p">)</span>
    <span class="n">population</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Population of the capital city&quot;</span><span class="p">)</span>


<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
        <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Here is the information of the capital of France in the JSON format.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
    <span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="c1"># Make API request</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/generate&quot;</span><span class="p">,</span>
    <span class="n">json</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
        <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
            <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">CapitalInfo</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">()),</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>


<span class="n">reasoing_content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;&lt;/think&gt;&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;&lt;/think&gt;&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">print_highlight</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">reasoing_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 00:59:06 TP0] Prefill batch. #new-seq: 1, #new-token: 19, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-04-27 00:59:06 TP0] Decode batch. #running-req: 1, #token: 43, token usage: 0.00, gen throughput (token/s): 50.00, #queue-req: 0
[2025-04-27 00:59:06 TP0] Decode batch. #running-req: 1, #token: 83, token usage: 0.00, gen throughput (token/s): 109.10, #queue-req: 0
[2025-04-27 00:59:07 TP0] Decode batch. #running-req: 1, #token: 123, token usage: 0.01, gen throughput (token/s): 106.15, #queue-req: 0
[2025-04-27 00:59:07 TP0] Decode batch. #running-req: 1, #token: 163, token usage: 0.01, gen throughput (token/s): 109.89, #queue-req: 0
[2025-04-27 00:59:07 TP0] Decode batch. #running-req: 1, #token: 203, token usage: 0.01, gen throughput (token/s): 105.24, #queue-req: 0
[2025-04-27 00:59:08 TP0] Decode batch. #running-req: 1, #token: 243, token usage: 0.01, gen throughput (token/s): 70.86, #queue-req: 0
[2025-04-27 00:59:08 TP0] Decode batch. #running-req: 1, #token: 283, token usage: 0.01, gen throughput (token/s): 67.30, #queue-req: 0
[2025-04-27 00:59:09 TP0] Decode batch. #running-req: 1, #token: 323, token usage: 0.02, gen throughput (token/s): 65.54, #queue-req: 0
[2025-04-27 00:59:10 TP0] Decode batch. #running-req: 1, #token: 363, token usage: 0.02, gen throughput (token/s): 67.19, #queue-req: 0
[2025-04-27 00:59:10 TP0] Decode batch. #running-req: 1, #token: 403, token usage: 0.02, gen throughput (token/s): 65.22, #queue-req: 0
[2025-04-27 00:59:11 TP0] Decode batch. #running-req: 1, #token: 443, token usage: 0.02, gen throughput (token/s): 64.22, #queue-req: 0
[2025-04-27 00:59:12 TP0] Decode batch. #running-req: 1, #token: 483, token usage: 0.02, gen throughput (token/s): 64.14, #queue-req: 0
[2025-04-27 00:59:12 TP0] Decode batch. #running-req: 1, #token: 523, token usage: 0.03, gen throughput (token/s): 64.36, #queue-req: 0
[2025-04-27 00:59:13 TP0] Decode batch. #running-req: 1, #token: 563, token usage: 0.03, gen throughput (token/s): 64.99, #queue-req: 0
[2025-04-27 00:59:13 TP0] Decode batch. #running-req: 1, #token: 603, token usage: 0.03, gen throughput (token/s): 64.16, #queue-req: 0
[2025-04-27 00:59:14 TP0] Decode batch. #running-req: 1, #token: 643, token usage: 0.03, gen throughput (token/s): 64.73, #queue-req: 0
[2025-04-27 00:59:15 TP0] Decode batch. #running-req: 1, #token: 683, token usage: 0.03, gen throughput (token/s): 62.87, #queue-req: 0
[2025-04-27 00:59:15 TP0] Decode batch. #running-req: 1, #token: 723, token usage: 0.04, gen throughput (token/s): 98.97, #queue-req: 0
[2025-04-27 00:59:15 TP0] Decode batch. #running-req: 1, #token: 763, token usage: 0.04, gen throughput (token/s): 105.72, #queue-req: 0
[2025-04-27 00:59:16 TP0] Decode batch. #running-req: 1, #token: 803, token usage: 0.04, gen throughput (token/s): 102.61, #queue-req: 0
[2025-04-27 00:59:16 TP0] Decode batch. #running-req: 1, #token: 843, token usage: 0.04, gen throughput (token/s): 107.43, #queue-req: 0
[2025-04-27 00:59:17 TP0] Decode batch. #running-req: 1, #token: 883, token usage: 0.04, gen throughput (token/s): 102.86, #queue-req: 0
[2025-04-27 00:59:17 TP0] Decode batch. #running-req: 1, #token: 923, token usage: 0.05, gen throughput (token/s): 105.86, #queue-req: 0
[2025-04-27 00:59:17 TP0] Decode batch. #running-req: 1, #token: 963, token usage: 0.05, gen throughput (token/s): 105.49, #queue-req: 0
[2025-04-27 00:59:18 TP0] Decode batch. #running-req: 1, #token: 1003, token usage: 0.05, gen throughput (token/s): 87.23, #queue-req: 0
[2025-04-27 00:59:18 TP0] Decode batch. #running-req: 1, #token: 1043, token usage: 0.05, gen throughput (token/s): 106.84, #queue-req: 0
[2025-04-27 00:59:19 TP0] Decode batch. #running-req: 1, #token: 1083, token usage: 0.05, gen throughput (token/s): 69.77, #queue-req: 0
[2025-04-27 00:59:19 TP0] Decode batch. #running-req: 1, #token: 1123, token usage: 0.05, gen throughput (token/s): 63.32, #queue-req: 0
[2025-04-27 00:59:20 TP0] Decode batch. #running-req: 1, #token: 1163, token usage: 0.06, gen throughput (token/s): 63.31, #queue-req: 0
[2025-04-27 00:59:21 TP0] Decode batch. #running-req: 1, #token: 1203, token usage: 0.06, gen throughput (token/s): 66.07, #queue-req: 0
[2025-04-27 00:59:21 TP0] Decode batch. #running-req: 1, #token: 1243, token usage: 0.06, gen throughput (token/s): 97.95, #queue-req: 0
[2025-04-27 00:59:21 TP0] Decode batch. #running-req: 1, #token: 1283, token usage: 0.06, gen throughput (token/s): 103.13, #queue-req: 0
[2025-04-27 00:59:22 TP0] Decode batch. #running-req: 1, #token: 1323, token usage: 0.06, gen throughput (token/s): 106.47, #queue-req: 0
[2025-04-27 00:59:22 TP0] Decode batch. #running-req: 1, #token: 1363, token usage: 0.07, gen throughput (token/s): 105.28, #queue-req: 0
[2025-04-27 00:59:23 TP0] Decode batch. #running-req: 1, #token: 1403, token usage: 0.07, gen throughput (token/s): 104.38, #queue-req: 0
[2025-04-27 00:59:23 TP0] Decode batch. #running-req: 1, #token: 1443, token usage: 0.07, gen throughput (token/s): 103.60, #queue-req: 0
[2025-04-27 00:59:23 TP0] Decode batch. #running-req: 1, #token: 1483, token usage: 0.07, gen throughput (token/s): 101.20, #queue-req: 0
[2025-04-27 00:59:24 TP0] Decode batch. #running-req: 1, #token: 1523, token usage: 0.07, gen throughput (token/s): 105.18, #queue-req: 0
[2025-04-27 00:59:24 TP0] Decode batch. #running-req: 1, #token: 1563, token usage: 0.08, gen throughput (token/s): 105.11, #queue-req: 0
[2025-04-27 00:59:25 TP0] Decode batch. #running-req: 1, #token: 1603, token usage: 0.08, gen throughput (token/s): 89.82, #queue-req: 0
[2025-04-27 00:59:25 TP0] Decode batch. #running-req: 1, #token: 1643, token usage: 0.08, gen throughput (token/s): 103.04, #queue-req: 0
[2025-04-27 00:59:25 TP0] Decode batch. #running-req: 1, #token: 1683, token usage: 0.08, gen throughput (token/s): 104.63, #queue-req: 0
[2025-04-27 00:59:26 TP0] Decode batch. #running-req: 1, #token: 1723, token usage: 0.08, gen throughput (token/s): 107.75, #queue-req: 0
[2025-04-27 00:59:26 TP0] Decode batch. #running-req: 1, #token: 1763, token usage: 0.09, gen throughput (token/s): 105.49, #queue-req: 0
[2025-04-27 00:59:26 TP0] Decode batch. #running-req: 1, #token: 1803, token usage: 0.09, gen throughput (token/s): 105.74, #queue-req: 0
[2025-04-27 00:59:27 TP0] Decode batch. #running-req: 1, #token: 1843, token usage: 0.09, gen throughput (token/s): 103.51, #queue-req: 0
[2025-04-27 00:59:27 TP0] Decode batch. #running-req: 1, #token: 1883, token usage: 0.09, gen throughput (token/s): 106.16, #queue-req: 0
[2025-04-27 00:59:28 TP0] Decode batch. #running-req: 1, #token: 1923, token usage: 0.09, gen throughput (token/s): 95.98, #queue-req: 0
[2025-04-27 00:59:28 TP0] Decode batch. #running-req: 1, #token: 1963, token usage: 0.10, gen throughput (token/s): 104.42, #queue-req: 0
[2025-04-27 00:59:28 TP0] Decode batch. #running-req: 1, #token: 2003, token usage: 0.10, gen throughput (token/s): 103.11, #queue-req: 0
[2025-04-27 00:59:29 TP0] Decode batch. #running-req: 1, #token: 2043, token usage: 0.10, gen throughput (token/s): 104.86, #queue-req: 0
[2025-04-27 00:59:29] INFO:     127.0.0.1:43704 - &#34;POST /generate HTTP/1.1&#34; 200 OK
{&#39;text&#39;: &#39;Okay, so I need to provide the information about the capital of France in JSON format. Hmm, I\&#39;m not entirely sure about all the details, but I\&#39;ll try to think it through.\n\nFirst, I know that the capital of France is Paris. That\&#39;s pretty much a given, right? But I should double-check that. Maybe I can recall any other capitals I know. London is the capital of the UK, Rome is Italy, and maybe Tokyo is Japan\&#39;s. Yeah, Paris seems correct for France.\n\nNow, moving on to the population. I think Paris is a very large city, but I\&#39;m not sure of the exact number. I remember it\&#39;s over 3 million, but I\&#39;m not certain. Maybe around 3.5 million? I should probably look that up, but since I can\&#39;t right now, I\&#39;ll go with 3,500,000 as an estimate.\n\nNext, the area. Paris is a big city, but I think it\&#39;s not as large as Tokyo or London. Maybe around 10 square kilometers? I\&#39;m not sure, but that seems plausible. I\&#39;ll note that as 10,000,000 square meters.\n\nCoordinates are next. Paris is in France, so the country code is &#34;FR&#34;. The latitude and longitude... I think the approximate coordinates are around 48.8566° N latitude and 2.3522° E longitude. I remember that Paris is in the northern and eastern parts of France, so those should be correct.\n\nOfficial languages. France is a country with a lot of languages, but I think French is the official language. I\&#39;m not sure if they have others, but French is definitely the primary one. Maybe they also have some other languages spoken there, but I\&#39;ll stick with French for now.\n\nOfficial currency is the euro, right? Yeah, I\&#39;m pretty sure that\&#39;s correct. They use the euro as their main currency.\n\nI should also consider if there\&#39;s anything else I might need to include. Maybe the capital\&#39;s nickname? I think Paris is called the &#34;City of Light&#34; or something like that. But the user didn\&#39;t ask for that, so maybe it\&#39;s not necessary.\n\nPutting it all together, I\&#39;ll structure the JSON with the key-value pairs. The keys should be in English, and the values can be numbers, strings, or maybe even objects if needed. Since the population and area are numerical, I\&#39;ll represent them as numbers. The rest can be strings.\n\nWait, but in JSON, numbers don\&#39;t have commas, right? So 3,500,000 should be written as 3500000 without the comma. Same with the area, 10,000,000 square meters becomes 10000000.\n\nLet me make sure I\&#39;m formatting the JSON correctly. The keys should be in double quotes, and the values can be numbers or strings. So the structure would be something like:\n\n{\n  &#34;capital&#34;: &#34;Paris&#34;,\n  &#34;population&#34;: 3500000,\n  &#34;area&#34;: 10000000,\n  &#34;country&#34;: &#34;FR&#34;,\n  &#34;coordinates&#34;: {\n    &#34;latitude&#34;: 48.8566,\n    &#34;longitude&#34;: 2.3522\n  },\n  &#34;languages&#34;: &#34;French&#34;,\n  &#34;currency&#34;: &#34;Euro&#34;\n}\n\nWait, but the coordinates are just two numbers, so maybe I don\&#39;t need a nested object. So it would be:\n\n{\n  &#34;capital&#34;: &#34;Paris&#34;,\n  &#34;population&#34;: 3500000,\n  &#34;area&#34;: 10000000,\n  &#34;country&#34;: &#34;FR&#34;,\n  &#34;coordinates&#34;: {\n    &#34;latitude&#34;: 48.8566,\n    &#34;longitude&#34;: 2.3522\n  },\n  &#34;languages&#34;: &#34;French&#34;,\n  &#34;currency&#34;: &#34;Euro&#34;\n}\n\nThat looks better. I think that\&#39;s all the information I need. I should make sure that the numerical values don\&#39;t have commas and that the strings are in double quotes. Also, the keys should be in lowercase letters as per JSON standards.\n\nI think I\&#39;ve covered everything. Population and area are estimates, but they\&#39;re close enough for a general JSON format. I don\&#39;t think I need to include more details unless specified. So, this should be the correct JSON structure for the information about the capital of France.\n&lt;/think&gt;{\n\n&#34;name&#34;: &#34;Paris&#34;,\n&#34;population&#34;: 3500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000&#39;, &#39;meta_info&#39;: {&#39;id&#39;: &#39;fa9e449eb13448f292ad15d07d487c0f&#39;, &#39;finish_reason&#39;: {&#39;type&#39;: &#39;length&#39;, &#39;length&#39;: 2048}, &#39;prompt_tokens&#39;: 20, &#39;completion_tokens&#39;: 2048, &#39;cached_tokens&#39;: 1, &#39;e2e_latency&#39;: 23.39765429496765}}
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Okay, so I need to provide the information about the capital of France in JSON format. Hmm, I'm not entirely sure about all the details, but I'll try to think it through.<br><br>First, I know that the capital of France is Paris. That's pretty much a given, right? But I should double-check that. Maybe I can recall any other capitals I know. London is the capital of the UK, Rome is Italy, and maybe Tokyo is Japan's. Yeah, Paris seems correct for France.<br><br>Now, moving on to the population. I think Paris is a very large city, but I'm not sure of the exact number. I remember it's over 3 million, but I'm not certain. Maybe around 3.5 million? I should probably look that up, but since I can't right now, I'll go with 3,500,000 as an estimate.<br><br>Next, the area. Paris is a big city, but I think it's not as large as Tokyo or London. Maybe around 10 square kilometers? I'm not sure, but that seems plausible. I'll note that as 10,000,000 square meters.<br><br>Coordinates are next. Paris is in France, so the country code is "FR". The latitude and longitude... I think the approximate coordinates are around 48.8566° N latitude and 2.3522° E longitude. I remember that Paris is in the northern and eastern parts of France, so those should be correct.<br><br>Official languages. France is a country with a lot of languages, but I think French is the official language. I'm not sure if they have others, but French is definitely the primary one. Maybe they also have some other languages spoken there, but I'll stick with French for now.<br><br>Official currency is the euro, right? Yeah, I'm pretty sure that's correct. They use the euro as their main currency.<br><br>I should also consider if there's anything else I might need to include. Maybe the capital's nickname? I think Paris is called the "City of Light" or something like that. But the user didn't ask for that, so maybe it's not necessary.<br><br>Putting it all together, I'll structure the JSON with the key-value pairs. The keys should be in English, and the values can be numbers, strings, or maybe even objects if needed. Since the population and area are numerical, I'll represent them as numbers. The rest can be strings.<br><br>Wait, but in JSON, numbers don't have commas, right? So 3,500,000 should be written as 3500000 without the comma. Same with the area, 10,000,000 square meters becomes 10000000.<br><br>Let me make sure I'm formatting the JSON correctly. The keys should be in double quotes, and the values can be numbers or strings. So the structure would be something like:<br><br>{<br>  "capital": "Paris",<br>  "population": 3500000,<br>  "area": 10000000,<br>  "country": "FR",<br>  "coordinates": {<br>    "latitude": 48.8566,<br>    "longitude": 2.3522<br>  },<br>  "languages": "French",<br>  "currency": "Euro"<br>}<br><br>Wait, but the coordinates are just two numbers, so maybe I don't need a nested object. So it would be:<br><br>{<br>  "capital": "Paris",<br>  "population": 3500000,<br>  "area": 10000000,<br>  "country": "FR",<br>  "coordinates": {<br>    "latitude": 48.8566,<br>    "longitude": 2.3522<br>  },<br>  "languages": "French",<br>  "currency": "Euro"<br>}<br><br>That looks better. I think that's all the information I need. I should make sure that the numerical values don't have commas and that the strings are in double quotes. Also, the keys should be in lowercase letters as per JSON standards.<br><br>I think I've covered everything. Population and area are estimates, but they're close enough for a general JSON format. I don't think I need to include more details unless specified. So, this should be the correct JSON structure for the information about the capital of France.<br><br><br>content: {<br><br>"name": "Paris",<br>"population": 3500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000</strong></div>
</div>
<p><strong>JSON Schema Directly</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">json_schema</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
        <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;pattern&quot;</span><span class="p">:</span> <span class="s2">&quot;^[</span><span class="se">\\</span><span class="s2">w]+$&quot;</span><span class="p">},</span>
            <span class="s2">&quot;population&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;integer&quot;</span><span class="p">},</span>
        <span class="p">},</span>
        <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;population&quot;</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># JSON</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/generate&quot;</span><span class="p">,</span>
    <span class="n">json</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
        <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
            <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="n">json_schema</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 00:59:29 TP0] Prefill batch. #new-seq: 1, #new-token: 3, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-04-27 00:59:29 TP0] Decode batch. #running-req: 1, #token: 20, token usage: 0.00, gen throughput (token/s): 101.00, #queue-req: 0
[2025-04-27 00:59:30 TP0] Decode batch. #running-req: 1, #token: 60, token usage: 0.00, gen throughput (token/s): 109.45, #queue-req: 0
[2025-04-27 00:59:30 TP0] Decode batch. #running-req: 1, #token: 100, token usage: 0.00, gen throughput (token/s): 111.94, #queue-req: 0
[2025-04-27 00:59:30 TP0] Decode batch. #running-req: 1, #token: 140, token usage: 0.01, gen throughput (token/s): 108.04, #queue-req: 0
[2025-04-27 00:59:31 TP0] Decode batch. #running-req: 1, #token: 180, token usage: 0.01, gen throughput (token/s): 104.64, #queue-req: 0
[2025-04-27 00:59:31 TP0] Decode batch. #running-req: 1, #token: 220, token usage: 0.01, gen throughput (token/s): 105.53, #queue-req: 0
[2025-04-27 00:59:31 TP0] Decode batch. #running-req: 1, #token: 260, token usage: 0.01, gen throughput (token/s): 105.03, #queue-req: 0
[2025-04-27 00:59:32 TP0] Decode batch. #running-req: 1, #token: 300, token usage: 0.01, gen throughput (token/s): 106.77, #queue-req: 0
[2025-04-27 00:59:32 TP0] Decode batch. #running-req: 1, #token: 340, token usage: 0.02, gen throughput (token/s): 105.35, #queue-req: 0
[2025-04-27 00:59:33 TP0] Decode batch. #running-req: 1, #token: 380, token usage: 0.02, gen throughput (token/s): 97.06, #queue-req: 0
[2025-04-27 00:59:33 TP0] Decode batch. #running-req: 1, #token: 420, token usage: 0.02, gen throughput (token/s): 104.41, #queue-req: 0
[2025-04-27 00:59:33 TP0] Decode batch. #running-req: 1, #token: 460, token usage: 0.02, gen throughput (token/s): 107.41, #queue-req: 0
[2025-04-27 00:59:34 TP0] Decode batch. #running-req: 1, #token: 500, token usage: 0.02, gen throughput (token/s): 105.77, #queue-req: 0
[2025-04-27 00:59:34 TP0] Decode batch. #running-req: 1, #token: 540, token usage: 0.03, gen throughput (token/s): 106.92, #queue-req: 0
[2025-04-27 00:59:34 TP0] Decode batch. #running-req: 1, #token: 580, token usage: 0.03, gen throughput (token/s): 107.28, #queue-req: 0
[2025-04-27 00:59:35 TP0] Decode batch. #running-req: 1, #token: 620, token usage: 0.03, gen throughput (token/s): 105.97, #queue-req: 0
[2025-04-27 00:59:35 TP0] Decode batch. #running-req: 1, #token: 660, token usage: 0.03, gen throughput (token/s): 106.13, #queue-req: 0
[2025-04-27 00:59:36 TP0] Decode batch. #running-req: 1, #token: 700, token usage: 0.03, gen throughput (token/s): 106.02, #queue-req: 0
[2025-04-27 00:59:36 TP0] Decode batch. #running-req: 1, #token: 740, token usage: 0.04, gen throughput (token/s): 109.37, #queue-req: 0
[2025-04-27 00:59:36 TP0] Decode batch. #running-req: 1, #token: 780, token usage: 0.04, gen throughput (token/s): 103.98, #queue-req: 0
[2025-04-27 00:59:37] INFO:     127.0.0.1:39814 - &#34;POST /generate HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>{'text': 'Okay, so I need to figure out how to solve this problem. Hmm, the problem is about finding the derivative of a function, right? Let me see. The function is f(x) = 3x^2 + 2x - 5. I remember from class that to find the derivative, I need to use the power rule. \n\nAlright, the power rule says that if I have a function like x^n, its derivative is n*x^(n-1). So, applying that to each term of the function should give me the derivative. Let\'s break it down term by term.\n\nFirst term: 3x^2. The exponent is 2, so I bring that down as a coefficient, multiply it by 3, which gives me 6. Then, I reduce the exponent by 1, so it becomes x^(2-1) = x^1, which is just x. So, the derivative of 3x^2 is 6x.\n\nSecond term: 2x. The exponent here is 1 because x is the same as x^1. Applying the power rule, I bring down the 1 as a coefficient, multiply it by 2, which gives me 2. Then, reduce the exponent by 1, so it becomes x^(1-1) = x^0, which is 1. So, the derivative of 2x is 2.\n\nThird term: -5. This is a constant term. I remember that the derivative of a constant is zero because there\'s no change as x changes. So, the derivative of -5 is 0.\n\nNow, putting it all together, the derivative of f(x) should be 6x + 2. Wait, let me double-check. The first term\'s derivative is 6x, the second is 2, and the third is 0. So, yes, adding them up gives 6x + 2.\n\nI think that\'s it. But just to be sure, maybe I should plug in a value for x and see if the derivative makes sense. Let\'s say x = 1. The original function f(1) = 3(1)^2 + 2(1) - 5 = 3 + 2 - 5 = 0. The derivative at x=1 is 6(1) + 2 = 8. So, at the point (1,0), the slope of the tangent line should be 8. That seems reasonable.\n\nAnother check: x = 0. f(0) = 3(0)^2 + 2(0) -5 = -5. The derivative at x=0 is 6(0) + 2 = 2. So, the slope at (0,-5) is 2. That also makes sense because the function is a parabola opening upwards, so the slope at the vertex (which is at x = -b/(2a) = -2/(6) = -1/3) should be zero. Wait, but at x=0, it\'s 2. Hmm, maybe I should calculate the slope at x = -1/3. Let\'s see, f\'(-1/3) = 6*(-1/3) + 2 = -2 + 2 = 0. Yes, that\'s correct. So, the derivative at x=0 is 2, which is positive, meaning the function is increasing there, which aligns with the parabola\'s shape.\n\nI think I\'m confident now. The derivative is 6x + 2.\n</think>{\n\n"name": "StepbyStepSolution",\n"population": 1000000000\n\n\n  \t\n\t\t\t\n \t\t}', 'meta_info': {'id': '664583e97def4c23901a2401b3958092', 'finish_reason': {'type': 'stop', 'matched': 151643}, 'prompt_tokens': 5, 'completion_tokens': 790, 'cached_tokens': 2, 'e2e_latency': 7.466338157653809}}</strong></div>
</div>
</section>
<section id="id2">
<h3>EBNF<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/generate&quot;</span><span class="p">,</span>
    <span class="n">json</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;Give me the information of the capital of France.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;n&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s2">&quot;ebnf&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;root ::= city | description</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s1">&#39;city ::= &quot;London&quot; | &quot;Paris&quot; | &quot;Berlin&quot; | &quot;Rome&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;description ::= city &quot; is &quot; status</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;status ::= &quot;the capital of &quot; country</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;country ::= &quot;England&quot; | &quot;France&quot; | &quot;Germany&quot; | &quot;Italy&quot;&#39;</span>
            <span class="p">),</span>
        <span class="p">},</span>
        <span class="s2">&quot;stream&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;return_logprob&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 00:59:37 TP0] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-04-27 00:59:37 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 20, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-04-27 00:59:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 10, token usage: 0.00, #running-req: 2, #queue-req: 0
[2025-04-27 00:59:37 TP0] Decode batch. #running-req: 3, #token: 83, token usage: 0.00, gen throughput (token/s): 138.57, #queue-req: 0
[2025-04-27 00:59:37 TP0] Decode batch. #running-req: 3, #token: 203, token usage: 0.01, gen throughput (token/s): 281.01, #queue-req: 0
[2025-04-27 00:59:38 TP0] Decode batch. #running-req: 3, #token: 323, token usage: 0.02, gen throughput (token/s): 302.50, #queue-req: 0
[2025-04-27 00:59:38 TP0] Decode batch. #running-req: 3, #token: 443, token usage: 0.02, gen throughput (token/s): 292.92, #queue-req: 0
[2025-04-27 00:59:39 TP0] Decode batch. #running-req: 3, #token: 563, token usage: 0.03, gen throughput (token/s): 295.46, #queue-req: 0
[2025-04-27 00:59:39 TP0] Decode batch. #running-req: 1, #token: 235, token usage: 0.01, gen throughput (token/s): 186.39, #queue-req: 0
[2025-04-27 00:59:39] INFO:     127.0.0.1:59726 - &#34;POST /generate HTTP/1.1&#34; 200 OK
[{&#39;text&#39;: &#34;\nThe capital of France is Paris.\n\nThat&#39;s all the information I have.\n\nOkay, so I need to figure out the capital of France. I know that Paris is the capital, but I&#39;m not entirely sure. Let me think about why I think that. I&#39;ve heard it mentioned a lot, especially in movies and TV shows. People often go there for business or tourism. Also, I remember learning in school that Paris is a major city in France, known for landmarks like the Eiffel Tower and the Louvre Museum. Those places are famous worldwide, which makes me think that Paris is indeed the capital. Maybe I can cross-check this with some other sources or my notes. Wait, I don&#39;t have any other information right now, but based on what I know, Paris is the capital of France. I don&#39;t recall any other major city in France being referred to as the capital. So, I&#39;m pretty confident that Paris is correct.\n&lt;/think&gt;Paris is the capital of France&#34;, &#39;meta_info&#39;: {&#39;id&#39;: &#39;c5b32d48994846768b95a2a6f07389df&#39;, &#39;finish_reason&#39;: {&#39;type&#39;: &#39;stop&#39;, &#39;matched&#39;: 151643}, &#39;prompt_tokens&#39;: 11, &#39;completion_tokens&#39;: 201, &#39;cached_tokens&#39;: 10, &#39;e2e_latency&#39;: 2.2752318382263184}}, {&#39;text&#39;: &#34;\nThe capital of France is Paris.\n\nThat&#39;s all the information I have.\n\nOkay, so I need to figure out the capital of France. I know that Paris is the capital, but I&#39;m not entirely sure. Let me think about why I think that. I&#39;ve heard it mentioned a lot, especially in movies and TV shows. People often go there for business or tourism. Also, I remember learning in school that Paris is a major city in France, known for landmarks like the Eiffel Tower and the Louvre Museum. Those places are famous worldwide, which makes me think that Paris is indeed the capital. Maybe I can cross-check this with some other sources or my notes. Wait, I don&#39;t have any other information right now, but based on what I know, Paris is the capital of France. I don&#39;t recall any other major city in France being referred to as the capital. So, I&#39;m pretty confident that Paris is correct.\n&lt;/think&gt;Paris is the capital of France&#34;, &#39;meta_info&#39;: {&#39;id&#39;: &#39;71fce5a113614289b62bcead9a2d6b86&#39;, &#39;finish_reason&#39;: {&#39;type&#39;: &#39;stop&#39;, &#39;matched&#39;: 151643}, &#39;prompt_tokens&#39;: 11, &#39;completion_tokens&#39;: 201, &#39;cached_tokens&#39;: 10, &#39;e2e_latency&#39;: 2.2752368450164795}}, {&#39;text&#39;: &#34;\nThe capital of France is Paris.\n\nThe user has provided the correct answer, but I need to analyze it to understand the thought process and identify any potential mistakes or areas for improvement.\n\nFirst, I should acknowledge the correct answer. Paris is indeed the capital of France.\n\nNext, I should consider why the user provided this answer. It might be a straightforward response, possibly from a student or someone with basic knowledge.\n\nI should think about what the user might not know. Maybe they don&#39;t know why Paris is the capital or if there have been changes in the capital over time.\n\nAdditionally, I could provide more context, such as when Paris became the capital, its significance, or notable landmarks in the city.\n\nI should also consider if the user might have doubts, like questioning whether Paris is still the capital or if there are other capitals nearby that could be confused.\n\nTo improve the answer, I could add more details to enhance understanding, such as historical background or cultural significance.\n\nI should also be cautious about any potential misinformation, but since the answer is correct, I don&#39;t need to address errors here.\n\nOverall, the thought process involves confirming the answer, expanding on related information, and considering the user&#39;s possible needs beyond the basic question.\n&lt;/think&gt;Paris is the capital of France&#34;, &#39;meta_info&#39;: {&#39;id&#39;: &#39;11159c5e07964aeeb56e05095fae393f&#39;, &#39;finish_reason&#39;: {&#39;type&#39;: &#39;stop&#39;, &#39;matched&#39;: 151643}, &#39;prompt_tokens&#39;: 11, &#39;completion_tokens&#39;: 257, &#39;cached_tokens&#39;: 10, &#39;e2e_latency&#39;: 2.803006410598755}}]
</pre></div></div>
</div>
</section>
<section id="id3">
<h3>Regular expression<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/generate&quot;</span><span class="p">,</span>
    <span class="n">json</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital of&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
            <span class="s2">&quot;regex&quot;</span><span class="p">:</span> <span class="s2">&quot;(France|England)&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 00:59:39 TP0] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-04-27 00:59:39 TP0] Decode batch. #running-req: 1, #token: 13, token usage: 0.00, gen throughput (token/s): 104.19, #queue-req: 0
[2025-04-27 00:59:40 TP0] Decode batch. #running-req: 1, #token: 53, token usage: 0.00, gen throughput (token/s): 106.54, #queue-req: 0
[2025-04-27 00:59:40 TP0] Decode batch. #running-req: 1, #token: 93, token usage: 0.00, gen throughput (token/s): 108.93, #queue-req: 0
[2025-04-27 00:59:41 TP0] Decode batch. #running-req: 1, #token: 133, token usage: 0.01, gen throughput (token/s): 108.86, #queue-req: 0
[2025-04-27 00:59:41 TP0] Decode batch. #running-req: 1, #token: 173, token usage: 0.01, gen throughput (token/s): 108.92, #queue-req: 0
[2025-04-27 00:59:41 TP0] Decode batch. #running-req: 1, #token: 213, token usage: 0.01, gen throughput (token/s): 111.57, #queue-req: 0
[2025-04-27 00:59:42 TP0] Decode batch. #running-req: 1, #token: 253, token usage: 0.01, gen throughput (token/s): 104.36, #queue-req: 0
[2025-04-27 00:59:42 TP0] Decode batch. #running-req: 1, #token: 293, token usage: 0.01, gen throughput (token/s): 109.11, #queue-req: 0
[2025-04-27 00:59:42 TP0] Decode batch. #running-req: 1, #token: 333, token usage: 0.02, gen throughput (token/s): 108.78, #queue-req: 0
[2025-04-27 00:59:43 TP0] Decode batch. #running-req: 1, #token: 373, token usage: 0.02, gen throughput (token/s): 108.73, #queue-req: 0
[2025-04-27 00:59:43 TP0] Decode batch. #running-req: 1, #token: 413, token usage: 0.02, gen throughput (token/s): 110.13, #queue-req: 0
[2025-04-27 00:59:43 TP0] Decode batch. #running-req: 1, #token: 453, token usage: 0.02, gen throughput (token/s): 109.17, #queue-req: 0
[2025-04-27 00:59:44 TP0] Decode batch. #running-req: 1, #token: 493, token usage: 0.02, gen throughput (token/s): 105.66, #queue-req: 0
[2025-04-27 00:59:44 TP0] Decode batch. #running-req: 1, #token: 533, token usage: 0.03, gen throughput (token/s): 104.62, #queue-req: 0
[2025-04-27 00:59:45 TP0] Decode batch. #running-req: 1, #token: 573, token usage: 0.03, gen throughput (token/s): 103.25, #queue-req: 0
[2025-04-27 00:59:45 TP0] Decode batch. #running-req: 1, #token: 613, token usage: 0.03, gen throughput (token/s): 105.73, #queue-req: 0
[2025-04-27 00:59:45 TP0] Decode batch. #running-req: 1, #token: 653, token usage: 0.03, gen throughput (token/s): 106.07, #queue-req: 0
[2025-04-27 00:59:46 TP0] Decode batch. #running-req: 1, #token: 693, token usage: 0.03, gen throughput (token/s): 97.87, #queue-req: 0
[2025-04-27 00:59:46 TP0] Decode batch. #running-req: 1, #token: 733, token usage: 0.04, gen throughput (token/s): 107.81, #queue-req: 0
[2025-04-27 00:59:47 TP0] Decode batch. #running-req: 1, #token: 773, token usage: 0.04, gen throughput (token/s): 104.95, #queue-req: 0
[2025-04-27 00:59:47 TP0] Decode batch. #running-req: 1, #token: 813, token usage: 0.04, gen throughput (token/s): 104.71, #queue-req: 0
[2025-04-27 00:59:47 TP0] Decode batch. #running-req: 1, #token: 853, token usage: 0.04, gen throughput (token/s): 104.97, #queue-req: 0
[2025-04-27 00:59:48 TP0] Decode batch. #running-req: 1, #token: 893, token usage: 0.04, gen throughput (token/s): 105.08, #queue-req: 0
[2025-04-27 00:59:48 TP0] Decode batch. #running-req: 1, #token: 933, token usage: 0.05, gen throughput (token/s): 104.14, #queue-req: 0
[2025-04-27 00:59:48 TP0] Decode batch. #running-req: 1, #token: 973, token usage: 0.05, gen throughput (token/s): 104.06, #queue-req: 0
[2025-04-27 00:59:49 TP0] Decode batch. #running-req: 1, #token: 1013, token usage: 0.05, gen throughput (token/s): 102.64, #queue-req: 0
[2025-04-27 00:59:49 TP0] Decode batch. #running-req: 1, #token: 1053, token usage: 0.05, gen throughput (token/s): 105.18, #queue-req: 0
[2025-04-27 00:59:50 TP0] Decode batch. #running-req: 1, #token: 1093, token usage: 0.05, gen throughput (token/s): 105.29, #queue-req: 0
[2025-04-27 00:59:50 TP0] Decode batch. #running-req: 1, #token: 1133, token usage: 0.06, gen throughput (token/s): 108.49, #queue-req: 0
[2025-04-27 00:59:50 TP0] Decode batch. #running-req: 1, #token: 1173, token usage: 0.06, gen throughput (token/s): 102.65, #queue-req: 0
[2025-04-27 00:59:51 TP0] Decode batch. #running-req: 1, #token: 1213, token usage: 0.06, gen throughput (token/s): 107.07, #queue-req: 0
[2025-04-27 00:59:51 TP0] Decode batch. #running-req: 1, #token: 1253, token usage: 0.06, gen throughput (token/s): 102.43, #queue-req: 0
[2025-04-27 00:59:51 TP0] Decode batch. #running-req: 1, #token: 1293, token usage: 0.06, gen throughput (token/s): 106.40, #queue-req: 0
[2025-04-27 00:59:52 TP0] Decode batch. #running-req: 1, #token: 1333, token usage: 0.07, gen throughput (token/s): 108.31, #queue-req: 0
[2025-04-27 00:59:52 TP0] Decode batch. #running-req: 1, #token: 1373, token usage: 0.07, gen throughput (token/s): 98.24, #queue-req: 0
[2025-04-27 00:59:53 TP0] Decode batch. #running-req: 1, #token: 1413, token usage: 0.07, gen throughput (token/s): 91.21, #queue-req: 0
[2025-04-27 00:59:53 TP0] Decode batch. #running-req: 1, #token: 1453, token usage: 0.07, gen throughput (token/s): 75.57, #queue-req: 0
[2025-04-27 00:59:54 TP0] Decode batch. #running-req: 1, #token: 1493, token usage: 0.07, gen throughput (token/s): 100.92, #queue-req: 0
[2025-04-27 00:59:54 TP0] Decode batch. #running-req: 1, #token: 1533, token usage: 0.07, gen throughput (token/s): 86.96, #queue-req: 0
[2025-04-27 00:59:55 TP0] Decode batch. #running-req: 1, #token: 1573, token usage: 0.08, gen throughput (token/s): 92.70, #queue-req: 0
[2025-04-27 00:59:55 TP0] Decode batch. #running-req: 1, #token: 1613, token usage: 0.08, gen throughput (token/s): 95.87, #queue-req: 0
[2025-04-27 00:59:55 TP0] Decode batch. #running-req: 1, #token: 1653, token usage: 0.08, gen throughput (token/s): 98.59, #queue-req: 0
[2025-04-27 00:59:56 TP0] Decode batch. #running-req: 1, #token: 1693, token usage: 0.08, gen throughput (token/s): 93.23, #queue-req: 0
[2025-04-27 00:59:56 TP0] Decode batch. #running-req: 1, #token: 1733, token usage: 0.08, gen throughput (token/s): 89.41, #queue-req: 0
[2025-04-27 00:59:57 TP0] Decode batch. #running-req: 1, #token: 1773, token usage: 0.09, gen throughput (token/s): 98.65, #queue-req: 0
[2025-04-27 00:59:57 TP0] Decode batch. #running-req: 1, #token: 1813, token usage: 0.09, gen throughput (token/s): 94.04, #queue-req: 0
[2025-04-27 00:59:57 TP0] Decode batch. #running-req: 1, #token: 1853, token usage: 0.09, gen throughput (token/s): 94.70, #queue-req: 0
[2025-04-27 00:59:58 TP0] Decode batch. #running-req: 1, #token: 1893, token usage: 0.09, gen throughput (token/s): 101.14, #queue-req: 0
[2025-04-27 00:59:58 TP0] Decode batch. #running-req: 1, #token: 1933, token usage: 0.09, gen throughput (token/s): 99.92, #queue-req: 0
[2025-04-27 00:59:59 TP0] Decode batch. #running-req: 1, #token: 1973, token usage: 0.10, gen throughput (token/s): 93.48, #queue-req: 0
[2025-04-27 00:59:59 TP0] Decode batch. #running-req: 1, #token: 2013, token usage: 0.10, gen throughput (token/s): 79.78, #queue-req: 0
[2025-04-27 01:00:00 TP0] Decode batch. #running-req: 1, #token: 2053, token usage: 0.10, gen throughput (token/s): 79.54, #queue-req: 0
[2025-04-27 01:00:00] INFO:     127.0.0.1:45370 - &#34;POST /generate HTTP/1.1&#34; 200 OK
{&#39;text&#39;: &#39; France, and the \n\\( n \\)  \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\(&#39;, &#39;meta_info&#39;: {&#39;id&#39;: &#39;ad308dfc9898403d94b939d885e388a5&#39;, &#39;finish_reason&#39;: {&#39;type&#39;: &#39;length&#39;, &#39;length&#39;: 2048}, &#39;prompt_tokens&#39;: 6, &#39;completion_tokens&#39;: 2048, &#39;cached_tokens&#39;: 1, &#39;e2e_latency&#39;: 20.37866497039795}}
</pre></div></div>
</div>
</section>
<section id="id4">
<h3>Structural Tag<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
    <span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
    <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
        <span class="s2">&quot;structural_tag&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;structural_tag&quot;</span><span class="p">,</span>
                <span class="s2">&quot;structures&quot;</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_weather&gt;&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_weather</span><span class="p">,</span>
                        <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
                    <span class="p">},</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_date&gt;&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_date</span><span class="p">,</span>
                        <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
                    <span class="p">},</span>
                <span class="p">],</span>
                <span class="s2">&quot;triggers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;&lt;function=&quot;</span><span class="p">],</span>
            <span class="p">}</span>
        <span class="p">),</span>
    <span class="p">},</span>
<span class="p">}</span>


<span class="c1"># Send POST request to the API endpoint</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/generate&quot;</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span>
<span class="n">print_highlight</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 01:00:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 19, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-04-27 01:00:00 TP0] Decode batch. #running-req: 1, #token: 59, token usage: 0.00, gen throughput (token/s): 77.26, #queue-req: 0
[2025-04-27 01:00:01 TP0] Decode batch. #running-req: 1, #token: 99, token usage: 0.00, gen throughput (token/s): 101.02, #queue-req: 0
[2025-04-27 01:00:01 TP0] Decode batch. #running-req: 1, #token: 139, token usage: 0.01, gen throughput (token/s): 103.15, #queue-req: 0
[2025-04-27 01:00:01 TP0] Decode batch. #running-req: 1, #token: 179, token usage: 0.01, gen throughput (token/s): 106.10, #queue-req: 0
[2025-04-27 01:00:02 TP0] Decode batch. #running-req: 1, #token: 219, token usage: 0.01, gen throughput (token/s): 99.97, #queue-req: 0
[2025-04-27 01:00:02 TP0] Decode batch. #running-req: 1, #token: 259, token usage: 0.01, gen throughput (token/s): 106.61, #queue-req: 0
[2025-04-27 01:00:03 TP0] Decode batch. #running-req: 1, #token: 299, token usage: 0.01, gen throughput (token/s): 103.49, #queue-req: 0
[2025-04-27 01:00:03 TP0] Decode batch. #running-req: 1, #token: 339, token usage: 0.02, gen throughput (token/s): 104.51, #queue-req: 0
[2025-04-27 01:00:03 TP0] Decode batch. #running-req: 1, #token: 379, token usage: 0.02, gen throughput (token/s): 106.50, #queue-req: 0
[2025-04-27 01:00:04 TP0] Decode batch. #running-req: 1, #token: 419, token usage: 0.02, gen throughput (token/s): 105.64, #queue-req: 0
[2025-04-27 01:00:04 TP0] Decode batch. #running-req: 1, #token: 459, token usage: 0.02, gen throughput (token/s): 102.46, #queue-req: 0
[2025-04-27 01:00:04 TP0] Decode batch. #running-req: 1, #token: 499, token usage: 0.02, gen throughput (token/s): 104.08, #queue-req: 0
[2025-04-27 01:00:05 TP0] Decode batch. #running-req: 1, #token: 539, token usage: 0.03, gen throughput (token/s): 105.97, #queue-req: 0
[2025-04-27 01:00:05 TP0] Decode batch. #running-req: 1, #token: 579, token usage: 0.03, gen throughput (token/s): 104.99, #queue-req: 0
[2025-04-27 01:00:06 TP0] Decode batch. #running-req: 1, #token: 619, token usage: 0.03, gen throughput (token/s): 105.49, #queue-req: 0
[2025-04-27 01:00:06 TP0] Decode batch. #running-req: 1, #token: 659, token usage: 0.03, gen throughput (token/s): 102.86, #queue-req: 0
[2025-04-27 01:00:06 TP0] Decode batch. #running-req: 1, #token: 699, token usage: 0.03, gen throughput (token/s): 107.56, #queue-req: 0
[2025-04-27 01:00:07 TP0] Decode batch. #running-req: 1, #token: 739, token usage: 0.04, gen throughput (token/s): 103.52, #queue-req: 0
[2025-04-27 01:00:07 TP0] Decode batch. #running-req: 1, #token: 779, token usage: 0.04, gen throughput (token/s): 105.99, #queue-req: 0
[2025-04-27 01:00:07 TP0] Decode batch. #running-req: 1, #token: 819, token usage: 0.04, gen throughput (token/s): 107.09, #queue-req: 0
[2025-04-27 01:00:08 TP0] Decode batch. #running-req: 1, #token: 859, token usage: 0.04, gen throughput (token/s): 102.56, #queue-req: 0
[2025-04-27 01:00:08 TP0] Decode batch. #running-req: 1, #token: 899, token usage: 0.04, gen throughput (token/s): 104.04, #queue-req: 0
[2025-04-27 01:00:09 TP0] Decode batch. #running-req: 1, #token: 939, token usage: 0.05, gen throughput (token/s): 107.93, #queue-req: 0
[2025-04-27 01:00:09 TP0] Decode batch. #running-req: 1, #token: 979, token usage: 0.05, gen throughput (token/s): 105.39, #queue-req: 0
[2025-04-27 01:00:09 TP0] Decode batch. #running-req: 1, #token: 1019, token usage: 0.05, gen throughput (token/s): 104.84, #queue-req: 0
[2025-04-27 01:00:10 TP0] Decode batch. #running-req: 1, #token: 1059, token usage: 0.05, gen throughput (token/s): 105.14, #queue-req: 0
[2025-04-27 01:00:10 TP0] Decode batch. #running-req: 1, #token: 1099, token usage: 0.05, gen throughput (token/s): 105.35, #queue-req: 0
[2025-04-27 01:00:11 TP0] Decode batch. #running-req: 1, #token: 1139, token usage: 0.06, gen throughput (token/s): 102.54, #queue-req: 0
[2025-04-27 01:00:11 TP0] Decode batch. #running-req: 1, #token: 1179, token usage: 0.06, gen throughput (token/s): 105.50, #queue-req: 0
[2025-04-27 01:00:11 TP0] Decode batch. #running-req: 1, #token: 1219, token usage: 0.06, gen throughput (token/s): 105.69, #queue-req: 0
[2025-04-27 01:00:12 TP0] Decode batch. #running-req: 1, #token: 1259, token usage: 0.06, gen throughput (token/s): 104.94, #queue-req: 0
[2025-04-27 01:00:12 TP0] Decode batch. #running-req: 1, #token: 1299, token usage: 0.06, gen throughput (token/s): 105.09, #queue-req: 0
[2025-04-27 01:00:12 TP0] Decode batch. #running-req: 1, #token: 1339, token usage: 0.07, gen throughput (token/s): 105.81, #queue-req: 0
[2025-04-27 01:00:13 TP0] Decode batch. #running-req: 1, #token: 1379, token usage: 0.07, gen throughput (token/s): 105.24, #queue-req: 0
[2025-04-27 01:00:13 TP0] Decode batch. #running-req: 1, #token: 1419, token usage: 0.07, gen throughput (token/s): 105.50, #queue-req: 0
[2025-04-27 01:00:14 TP0] Decode batch. #running-req: 1, #token: 1459, token usage: 0.07, gen throughput (token/s): 105.16, #queue-req: 0
[2025-04-27 01:00:14 TP0] Decode batch. #running-req: 1, #token: 1499, token usage: 0.07, gen throughput (token/s): 107.82, #queue-req: 0
[2025-04-27 01:00:14 TP0] Decode batch. #running-req: 1, #token: 1539, token usage: 0.08, gen throughput (token/s): 103.24, #queue-req: 0
[2025-04-27 01:00:15 TP0] Decode batch. #running-req: 1, #token: 1579, token usage: 0.08, gen throughput (token/s): 106.87, #queue-req: 0
[2025-04-27 01:00:15 TP0] Decode batch. #running-req: 1, #token: 1619, token usage: 0.08, gen throughput (token/s): 105.78, #queue-req: 0
[2025-04-27 01:00:15 TP0] Decode batch. #running-req: 1, #token: 1659, token usage: 0.08, gen throughput (token/s): 105.32, #queue-req: 0
[2025-04-27 01:00:16 TP0] Decode batch. #running-req: 1, #token: 1699, token usage: 0.08, gen throughput (token/s): 103.27, #queue-req: 0
[2025-04-27 01:00:16 TP0] Decode batch. #running-req: 1, #token: 1739, token usage: 0.08, gen throughput (token/s): 105.72, #queue-req: 0
[2025-04-27 01:00:16] INFO:     127.0.0.1:36750 - &#34;POST /generate HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>{'text': 'Alright, so the user asked for the information of the capital of France in JSON format. First, I need to make sure I understand what they\'re looking for. The capital of France is definitely Paris, no doubt about that.\n\nOkay, so I should gather all the relevant facts about Paris. Let me start by recalling some key points. Paris is the administrative capital, but sometimes people confuse it with the political capital. I should clarify that.\n\nNext, dates are important. I need the historical and official establishment dates. Paris was founded back in 753 by Paris II the Great. Then, it became an실 capital after the Battle of Crécy in 1345. Officially, it was made the capital in 18th century reforms when it became the center of the French Republic. Moving on, the area and population are crucial. Paris is pretty vast, so I should note its administrative area, population figure, and the approximate percentage of the total population.\n\nGeography is another key section. Paris is located in the northern part of France, specifically the Seine department, which is near the Seine River. It\'s a major city with landmarks like the Eiffel Tower and the Louvre Museum. Including latitude and longitude will give it more credibility.\n\nMoving on to transportation, Paris has an extensive public transit system. I remember the RATP operates the metro, and there are also buses, trams, and trolleys. Maybe also something about the regional train network, like SNCF. I should include routes those services take, like the RER for rapid lines.\n\n tiết_VARIABLES like GDR (Grand Jeune-D Parade) and other cultural highlights would add depth. I\'ll make sure to list subcontractors like Eiffel Tower Management and Louvre Armor if they run any services there. Also, points about the Paris Agreement, which although in administration, it\'s relevant in terms of environmental collaborations.\n\nNow, think about the user\'s scenario. They might be looking for a structured data format for integration into another system, maybe for a database or application. They could be a developer or someone working with data dumps. So, ensuring the JSON format is correct and comprehensive is key.\n\nI should also consider the possibility of the user needing this information for a school project, a travel guide, or perhaps a city guide website. In each case, the JSON should be accurate and cover all necessary details, so it\'s useful regardless of the context.\n\nNeed to verify all the facts. For example, the population figure as of 2023 is around 2.18 million. The administrative area is indeed around 403 square kilometers. Population density can be calculated as 2.18 million divided by 403 km², which is roughly 5.4 million per km². That\'s a high density, reflecting Paris\'s status as a metropolis.\n\nTransport lines: the SNCF\'s Line 1 is the Châtelet-Les Halles metro line, which is a good example. Including that shows a specific aspect of the transportation system. The GDR was their former name, so I should clarify that.\n\nIn the cultural section, including landmarks gives a visual representation of the city. For future reference, mentioning the Paris Agreement shows an awareness of current issues, which adds context beyond just the administrative aspects.\n\nFinally, formatting-wise, ensuring that the JSON syntax is correct—proper commas, quotation marks, no trailing commas, etc. That\'s important for any data exchange or programming integration.\n\nI think that\'s a solid outline. Now, putting it all together in the JSON structure, making sure each section is clear and the data accurate. I\'ll also add minimal comments if possible to explain the inclusion of certain sections, but keep it straightforward.\n</think>\n\nSure! Here is the information of the capital of France (Paris) in JSON format:\n\n```json\n{\n  "name": "Paris",\n  "country": "France",\n  "established": 753,\n  "founded": 753,\n  "capital": "Paris",\n  "administrative_capital": "Paris",\n  "official_capital": "Paris",\n  "political_capital": "Paris",\n  "historical_name": {\n    "roman": "Rome",\n    "latin": "Roma"\n  },\n  "official_establishment_date": "1345",\n  "official_reception_date": "18th century (1792)",\n  "area": {\n    "administrative_area": "403 km²",\n    "approximate land area": "1,475 km²",\n    "statistics": "Urban area: 475 km² (2015)"\n  },\n  "population": {\n    "as_of": "2023",\n    "population": "2,182,301",\n    "density": "5,400/m² (2015)",\n    "land_area": "1,475 km² (2015)"\n  },\n  "coordinates": {\n    "latitude": "48.8584",\n    "longitude": "-2.3522"\n  },\n  "geography": {\n    "location": "Northern France, Seine department"\n  },\n  "landmarks": {\n    "elevation": "57 m above sea level",\n    "famous_landmarks": [\n      "Eiffel Tower",\n      "Louvre Museum",\n      "Notre-Dame Cathedral",\n      "Château de monastir"\n    ],\n    "f well-known_buildings": [\n      " Prononcer \'Le Marais\'",\n      "Le Potier",\n      "Le Quartier Latin"\n    ]\n  },\n  "transport": {\n    "public_transport": {\n      "operator": "RATP",\n      "lines": [\n        "Bcá Le Cl Changchun",\n        "La Corniche",\n        "Mairie-Bienvenüe"\n      ],\n      "services": "subway, bus, tramway, RER"\n    },\n    "local_transport": {\n      "bus": "SNCF",\n      "trolley": "RER",\n      "subway": "RN友情"\n    }\n  },\n  "Culture": {\n    "cultural_heritage": [\n      "Palais Royal",\n      "Central Documentation伞 er",\n      "Grand Palace",\n      "Musee Rodin"\n    ],\n    "significant_institutions": [\n      "Palais royale",\n      "Musée Rodin",\n      "Musee d\'Orsay",\n      "Musee列车 normal saint Saens"\n    ],\n    "unique_landmarks": [\n      "Le Marais",\n      "Le Potier",\n      "Le Quartier Latin"\n    ]\n  },\n  "Social_infrastructure": {\n    "-/ hospitals": ["CHU de Nanterre", "CHU de Seine-Saint-Denis"],\n    "colleges": ["Collège La_mode particulier"],\n    "kindergartens": ["Collège𝜆 Eiffel"],\n    "housing": ["Palais de Tokyo"],\n    " automotive": ["Esplanade des Corremandes"]\n  },\n  "Environmental": {\n    "governmental Dissertation: "https://www.french-republic.net/en扩建",\n    "UN`: "30511",\n    "WCO`: "30511"\n  },\n  "Other information": {\n    "trails": " Île de la Cité",\n    "airport": {\n      "airspace": " CDG",\n      "runs": ["CDG", "Le Mont Justin", "CDG", "Le Mont Justin"]\n    }\n  },\n  "Additions": {\n    "Paris Agreement": "2015",\n    "Saint-Hermann-Antiquoi S Ct剝� 军事基地 ensure",\n    "Eiffel Tower Management Service": "Mairie of the City of Paris",\n    "Louvre Museum Armor Service": "lvre Armor Consolidated bv",\n    "SNCF Paris Elections": "1978",\n    "GDR (Grand Jeune-D Parade)": "1959"\n  }\n}\n```\n\nThis JSON includes information about Paris, such as its historical and administrative details, population, geography, transportation, culture, and other relevant facts.', 'meta_info': {'id': '21520e4b8d124456a9717c5c61a2da34', 'finish_reason': {'type': 'stop', 'matched': 151643}, 'prompt_tokens': 20, 'completion_tokens': 1745, 'cached_tokens': 19, 'e2e_latency': 16.760796070098877}}</strong></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">terminate_process</span><span class="p">(</span><span class="n">server_process</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-04-27 01:00:16] Child process unexpectedly failed with an exit code 9. pid=2273879
</pre></div></div>
</div>
</section>
</section>
<section id="Offline-Engine-API">
<h2>Offline Engine API<a class="headerlink" href="#Offline-Engine-API" title="Link to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sglang</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sgl</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">sgl</span><span class="o">.</span><span class="n">Engine</span><span class="p">(</span>
    <span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">reasoning_parser</span><span class="o">=</span><span class="s2">&quot;deepseek-r1&quot;</span><span class="p">,</span>
    <span class="n">grammar_backend</span><span class="o">=</span><span class="s2">&quot;xgrammar&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00&lt;?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01&lt;00:01,  1.35s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02&lt;00:00,  1.29s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02&lt;00:00,  1.30s/it]

</pre></div></div>
</div>
<section id="id5">
<h3>JSON<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p><strong>Using Pydantic</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>


<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Give me the information of the capital of China in the JSON format.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of France in the JSON format.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of Ireland in the JSON format.&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="c1"># Define the schema using Pydantic</span>
<span class="k">class</span><span class="w"> </span><span class="nc">CapitalInfo</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;^\w+$&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Name of the capital city&quot;</span><span class="p">)</span>
    <span class="n">population</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Population of the capital city&quot;</span><span class="p">)</span>


<span class="n">sampling_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
    <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">CapitalInfo</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">()),</span>
<span class="p">}</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===============================&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n</span><span class="s2">Generated text: </span><span class="si">{</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
===============================
Prompt: Give me the information of the capital of China in the JSON format.
Generated text:
Sure, here&#39;s the information about the capital of China, Beijing, in JSON format:

```json
{
  &#34;name&#34;: &#34;Beijing&#34;,
  &#34;capital&#34;: &#34;Yes&#34;,
  &#34;population&#34;: &#34;Over 30 million&#34;,
  &#34;founded&#34;: &#34;1248&#34;,
  &#34;Nickname&#34;: &#34;The Heaven on Earth&#34;,
  &#34;Location&#34;: &#34;Northern China&#34;,
  &#34;OfficialLanguages&#34;: [
    &#34;Mandarin Chinese&#34;,
    &#34;Bingyuan Chinese&#34;,
    &#34;Tibetan&#34;,
    &#34;Hui&#34;,
    &#34;Mongolian&#34;,
    &#34;Yugoslav&#34;,
    &#34;Other&#34;
  ],
  &#34;KeySights&#34;: [
    &#34;The Great Wall&#34;,
    &#34;Tiananmen Square&#34;,
    &#34;Forbidden City&#34;,
    &#34;Beijing Museum&#34;,
    &#34;Yuanmingyuan&#34;
  ],
  &#34;Climate&#34;: &#34;Temperate&#34;
}
```

Let me know if you need any other information!
===============================
Prompt: Give me the information of the capital of France in the JSON format.
Generated text:
Sure! Here&#39;s the information about the capital of France, Paris, in JSON format:

```json
{
  &#34;name&#34;: &#34;Paris&#34;,
  &#34;country&#34;: &#34;France&#34;,
  &#34;coordinates&#34;: {
    &#34;latitude&#34;: 48.8566,
    &#34;longitude&#34;: 2.3522
  },
  &#34;founded&#34;: &#34;1340&#34;,
  &#34;population&#34;: &#34;9.7 million&#34;,
  &#34;area&#34;: &#34;105.5 square kilometers&#34;,
  &#34;features&#34;: {
    &#34;bridges&#34;: &#34;The Eiffel Tower, Notre-Dame, and the Seine River&#34;,
    &#34;landmarks&#34;: &#34;The Louvre Museum, Montmartre, and the Champs-Élysées&#34;
  },
  &#34;elevation&#34;: &#34;2 meters&#34;,
  &#34;time_zone&#34;: &#34;Central European Time (CET)&#34;
}
```

Let me know if you need any other information!
===============================
Prompt: Give me the information of the capital of Ireland in the JSON format.
Generated text:
Sure, here&#39;s the information about the capital of Ireland in JSON format:

```json
{
  &#34;capital&#34;: &#34;Dublin&#34;,
  &#34;official_name&#34;: &#34;Dublin City&#34;,
  &#34;region&#34;: &#34;Dublin&#34;,
  &#34;coordinates&#34;: {
    &#34;latitude&#34;: 53.3489,
    &#34;longitude&#34;: -6.2009
  },
  &#34;founded&#34;: &#34;1543&#34;,
  &#34;population&#34;: 1,234,567,
  &#34;area&#34;: {
    &#34;total&#34;: 123.45,
    &#34;land&#34;: 112.34,
    &#34;water&#34;: 11.11
  },
  &#34;climate&#34;: &#34; temperate&#34;,
  &#34;key_features&#34;: [
    &#34;City Walls&#34;,
    &#34;Trinity College&#34;,
    &#34;Leaving Certificate&#34;,
    &#34;St. Stephen&#39;s Cathedral&#34;,
    &#34;Glynn Bridge&#34;
  ],
  &#34;tourism&#34;: [
    &#34;The GAA&#34;,
    &#34;The National Library of Ireland&#34;,
    &#34;The SSE St. Patrick&#39;s Cathedral&#34;,
    &#34;The Phoenix Park&#34;,
    &#34;The Book of Kells&#34;
  ]
}
```

Let me know if you need any adjustments!
</pre></div></div>
</div>
<p><strong>JSON Schema Directly</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Give me the information of the capital of China in the JSON format.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of France in the JSON format.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of Ireland in the JSON format.&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">json_schema</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
        <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;pattern&quot;</span><span class="p">:</span> <span class="s2">&quot;^[</span><span class="se">\\</span><span class="s2">w]+$&quot;</span><span class="p">},</span>
            <span class="s2">&quot;population&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;integer&quot;</span><span class="p">},</span>
        <span class="p">},</span>
        <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;population&quot;</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">sampling_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span> <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="n">json_schema</span><span class="p">}</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===============================&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n</span><span class="s2">Generated text: </span><span class="si">{</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
===============================
Prompt: Give me the information of the capital of China in the JSON format.
Generated text:
Sure! Here&#39;s the information about the capital of China, Beijing, in JSON format:

```json
{
  &#34;name&#34;: &#34;Beijing&#34;,
  &#34;capital&#34;: &#34;Yes&#34;,
  &#34;population&#34;: &#34;Over 30 million&#34;,
  &#34;founded&#34;: &#34;1248&#34;,
  &#34;Nickname&#34;: &#34;The Heaven on Earth&#34;,
  &#34;Location&#34;: &#34;Northern China&#34;,
  &#34;OfficialLanguages&#34;: [
    &#34;Mandarin Chinese&#34;,
    &#34;Bingyuan Chinese&#34;,
    &#34;Tibetan&#34;,
    &#34;Hui&#34;,
    &#34;Mongolian&#34;,
    &#34;Yugoslav&#34;,
    &#34;Other&#34;
  ],
  &#34;KeySights&#34;: [
    &#34;The Great Wall&#34;,
    &#34;Forbidden City&#34;,
    &#34;Tiananmen Square&#34;,
    &#34;Beijing Museum&#34;,
    &#34;Yuanmingyuan&#34;
  ],
  &#34;Climate&#34;: &#34;Temperate&#34;
}
```

Let me know if you need any other information!
===============================
Prompt: Give me the information of the capital of France in the JSON format.
Generated text:
Sure! Here&#39;s the information about the capital of France, Paris, in JSON format:

```json
{
  &#34;name&#34;: &#34;Paris&#34;,
  &#34;country&#34;: &#34;France&#34;,
  &#34;coordinates&#34;: {
    &#34;latitude&#34;: 48.8566,
    &#34;longitude&#34;: 2.3522
  },
  &#34;founded&#34;: &#34;1340&#34;,
  &#34;population&#34;: &#34;9.7 million&#34;,
  &#34;area&#34;: &#34;105.5 square kilometers&#34;,
  &#34;WX&#34;: {
    &#34;averageTemperature&#34;: &#34;12°C&#34;,
    &#34;precipitation&#34;: &#34;540 mm/year&#34;
  },
  &#34;landmarks&#34;: [
    {
      &#34;name&#34;: &#34;Eiffel Tower&#34;,
      &#34;location&#34;: &#34;City of Light&#34;,
      &#34;height&#34;: &#34;330 meters&#34;
    },
    {
      &#34;name&#34;: &#34;Notre-Dame Cathedral&#34;,
      &#34;location&#34;: &#34;Center of Paris&#34;,
      &#34;height&#34;: &#34;415 meters&#34;
    }
  ],
  &#34;Transport&#34;: {
    &#34;publicTransport&#34;: &#34;Boulevards, trams, and subways&#34;,
    &#34;airport&#34;: &#34;Paris International Airport&#34;,
    &#34;railway&#34;: &#34;Le巴黎-Charles de Gaulle&#34;
  }
}
```

Let me know if you need any other information!
===============================
Prompt: Give me the information of the capital of Ireland in the JSON format.
Generated text:
Sure, here&#39;s the information about the capital of Ireland in JSON format:

```json
{
  &#34;capital&#34;: &#34;Dublin&#34;,
  &#34;official_name&#34;: &#34;Dublin City&#34;,
  &#34;region&#34;: &#34;Dublin&#34;,
  &#34;coordinates&#34;: {
    &#34;latitude&#34;: 53.3489,
    &#34;longitude&#34;: -6.2009
  },
  &#34;founded&#34;: &#34;1241&#34;,
  &#34;population&#34;: 1,234,567,
  &#34;area&#34;: {
    &#34;total&#34;: 123.45,
    &#34;land&#34;: 112.34,
    &#34;water&#34;: 11.11
  },
  &#34;climate&#34;: &#34; temperate&#34;,
  &#34;key_features&#34;: [
    &#34;City Walls&#34;,
    &#34;Trinity College&#34;,
    &#34;Leaving Certificate&#34;,
    &#34;St. Stephen&#39;s Cathedral&#34;,
    &#34;Glynn Bridge&#34;
  ],
  &#34;tourism&#34;: [
    &#34;The GAA&#34;,
    &#34;The National Library of Ireland&#34;,
    &#34;The University of Dublin&#34;,
    &#34;The Phoenix Park&#34;,
    &#34;The SSE St. Patrick&#39;s Cathedral Quarter&#34;
  ]
}
```

Let me know if you need any adjustments!
</pre></div></div>
</div>
</section>
<section id="id6">
<h3>EBNF<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Give me the information of the capital of France.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of Germany.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of Italy.&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">sampling_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
    <span class="s2">&quot;ebnf&quot;</span><span class="p">:</span> <span class="p">(</span>
        <span class="s2">&quot;root ::= city | description</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="s1">&#39;city ::= &quot;London&quot; | &quot;Paris&quot; | &quot;Berlin&quot; | &quot;Rome&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="s1">&#39;description ::= city &quot; is &quot; status</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="s1">&#39;status ::= &quot;the capital of &quot; country</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="s1">&#39;country ::= &quot;England&quot; | &quot;France&quot; | &quot;Germany&quot; | &quot;Italy&quot;&#39;</span>
    <span class="p">),</span>
<span class="p">}</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===============================&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n</span><span class="s2">Generated text: </span><span class="si">{</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
===============================
Prompt: Give me the information of the capital of France.
Generated text:
The capital of France is Paris. Below, I have provided the information about Paris. If you have any questions, please feel free to ask.

** Paris Overview:**
- **Historical Significance:** Paris is one of the oldest cities in Europe, with a history dating back over 2,000 years.
- **Administrative Center:** It serves as the administrative center of France.
- **Cultural Hub:** Paris is renowned for its rich cultural heritage, including museums like the Louvre and the acidity of its cuisine.
- **Transportation:** The city is well-connected by metro, buses, and trams.


===============================
Prompt: Give me the information of the capital of Germany.
Generated text:  the capital of Germany is?

The capital of Germany is Berlin.
&lt;/think&gt;Berlin is the capital of Germany
===============================
Prompt: Give me the information of the capital of Italy.
Generated text:
The capital of Italy is Rome.

The capital of Italy is Rome.

The capital of Italy is Rome.

The capital of Italy is Rome.

The capital of Italy is Rome.

The capital of Italy is Rome.

The capital of Italy is Rome.

The capital of Italy is Rome.
&lt;/think&gt;Rome is the capital of Italy
</pre></div></div>
</div>
</section>
<section id="id7">
<h3>Regular expression<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Please provide information about London as a major global city:&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Please provide information about Paris as a major global city:&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">sampling_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span> <span class="s2">&quot;regex&quot;</span><span class="p">:</span> <span class="s2">&quot;(France|England)&quot;</span><span class="p">}</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===============================&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n</span><span class="s2">Generated text: </span><span class="si">{</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
===============================
Prompt: Please provide information about London as a major global city:
Generated text:  include population, location, nickname, major landmarks, economic status, cultural status, transportation, and architecture.

6.2.2:11

Then, using the information above, answer the following question: The question is: &#34;What is the population of London? Approximately how many people live there?&#34;

To answer this, you must use the data from the provided information. You must express the number in digits and in words, and provide a brief explanation of how you arrived at the number.

To make it more interesting, you can add a bit of humor or creativity in the explanation, but it must still be based on the provided information
===============================
Prompt: Please provide information about Paris as a major global city:
Generated text:  its location, population, economic status, and cultural significance. and also, it is important to include how Paris is connected to the rest of France and Europe.

Additionally, please include a detailed breakdown of Paris&#39;s economy, including key sectors like tourism, fashion, and technology. For each of these sectors, provide specific examples and a brief description of their impact on the city and the global economy.

Moreover, include a section on the cultural significance of Paris, focusing on major museums, landmarks, and cultural events. Again, provide specific examples and explain their global influence.

Finally, write a conclusion summarizing the key points about Paris as a major
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
    <span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="p">]</span>


<span class="n">sampling_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
    <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="s2">&quot;structural_tag&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;structural_tag&quot;</span><span class="p">,</span>
            <span class="s2">&quot;structures&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_weather&gt;&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_weather</span><span class="p">,</span>
                    <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="p">{</span>
                    <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_date&gt;&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_date</span><span class="p">,</span>
                    <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">],</span>
            <span class="s2">&quot;triggers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;&lt;function=&quot;</span><span class="p">],</span>
        <span class="p">}</span>
    <span class="p">),</span>
<span class="p">}</span>


<span class="c1"># Send POST request to the API endpoint</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===============================&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n</span><span class="s2">Generated text: </span><span class="si">{</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
===============================
Prompt: &lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;Here is the information of the capital of France in the JSON format.
&lt;｜Assistant｜&gt;&lt;think&gt;

Generated text: Okay, so I need to figure out the capital of France and present it in JSON format. Hmm, I know that Paris is the capital, but let me think if there&#39;s any chance it might change. I&#39;ve heard that sometimes capitals can move, but as far as I know, Paris has been the capital for a long time. Maybe I should double-check that. Oh, right, Paris is the administrative capital, but sometimes they talk about the political or cultural capital too. But I think in most contexts, especially official, Paris is still the capital.

Now, putting that into JSON. JSON uses key-value pairs, so I&#39;ll have a key like &#34;capital&#34; with the value &#34;Paris&#34;. Since there&#39;s only one capital, I don&#39;t think I need a list or anything more complicated. So the structure would be a dictionary with &#34;capital&#34; pointing to &#34;Paris&#34;.
&lt;/think&gt;

```json
{
  &#34;capital&#34;: &#34;Paris&#34;
}
```
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</pre></div>
</div>
</div>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="separate_reasoning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Reasoning Parser</p>
      </div>
    </a>
    <a class="right-next"
       href="custom_chat_template.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Custom Chat Template</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Supported-Models">Supported Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Usage">Usage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#OpenAI-Compatible-API">OpenAI Compatible API</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#JSON">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#EBNF">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Regular-expression">Regular expression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Structural-Tag">Structural Tag</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Native-API-and-SGLang-Runtime-(SRT)">Native API and SGLang Runtime (SRT)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Regular expression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Structural Tag</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Offline-Engine-API">Offline Engine API</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Regular expression</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By SGLang Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023-2025, SGLang.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Apr 27, 2025.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  
    <!-- RunLLM Widget Script -->
    <script type="module" id="runllm-widget-script" src="https://widget.runllm.com" crossorigin="true" version="stable" runllm-keyboard-shortcut="Mod+j" runllm-name="SGLang Chatbot" runllm-position="BOTTOM_RIGHT" runllm-assistant-id="629" async></script>
    
</body>
</html>